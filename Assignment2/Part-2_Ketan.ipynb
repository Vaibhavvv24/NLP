{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316566,"sourceType":"datasetVersion","datasetId":4245661}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv')\n\n# Display basic information and first few rows\nprint(df.info())\nprint(df.head())\n\n# Focus on the relevant columns (Text and Sentiment)\ndf = df[['Text', 'Sentiment']]\n\n# Check for missing values\nprint(\"Missing values:\")\nprint(df.isnull().sum())\n\n# Drop rows with missing values (if any)\ndf.dropna(inplace=True)\n\n\n# Text Cleaning Functions\ndef clean_text(text):\n    text = text.lower()  # Lowercase\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n    return text\n\n# Apply text cleaning\ndf['Cleaned_Text'] = df['Text'].apply(clean_text)\n\n# Check the cleaned output\nprint(df.head())\n\n# Analyze the cleaned data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:38:09.786366Z","iopub.execute_input":"2025-03-11T14:38:09.786795Z","iopub.status.idle":"2025-03-11T14:38:09.837555Z","shell.execute_reply.started":"2025-03-11T14:38:09.786760Z","shell.execute_reply":"2025-03-11T14:38:09.836414Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 732 entries, 0 to 731\nData columns (total 15 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Unnamed: 0.1  732 non-null    int64  \n 1   Unnamed: 0    732 non-null    int64  \n 2   Text          732 non-null    object \n 3   Sentiment     732 non-null    object \n 4   Timestamp     732 non-null    object \n 5   User          732 non-null    object \n 6   Platform      732 non-null    object \n 7   Hashtags      732 non-null    object \n 8   Retweets      732 non-null    float64\n 9   Likes         732 non-null    float64\n 10  Country       732 non-null    object \n 11  Year          732 non-null    int64  \n 12  Month         732 non-null    int64  \n 13  Day           732 non-null    int64  \n 14  Hour          732 non-null    int64  \ndtypes: float64(2), int64(6), object(7)\nmemory usage: 85.9+ KB\nNone\n   Unnamed: 0.1  Unnamed: 0  \\\n0             0           0   \n1             1           1   \n2             2           2   \n3             3           3   \n4             4           4   \n\n                                                Text    Sentiment  \\\n0   Enjoying a beautiful day at the park!        ...   Positive     \n1   Traffic was terrible this morning.           ...   Negative     \n2   Just finished an amazing workout! 💪          ...   Positive     \n3   Excited about the upcoming weekend getaway!  ...   Positive     \n4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n\n             Timestamp            User     Platform  \\\n0  2023-01-15 12:30:00   User123          Twitter     \n1  2023-01-15 08:45:00   CommuterX        Twitter     \n2  2023-01-15 15:45:00   FitnessFan      Instagram    \n3  2023-01-15 18:20:00   AdventureX       Facebook    \n4  2023-01-15 19:55:00   ChefCook        Instagram    \n\n                                     Hashtags  Retweets  Likes       Country  \\\n0   #Nature #Park                                  15.0   30.0     USA         \n1   #Traffic #Morning                               5.0   10.0     Canada      \n2   #Fitness #Workout                              20.0   40.0   USA           \n3   #Travel #Adventure                              8.0   15.0     UK          \n4   #Cooking #Food                                 12.0   25.0    Australia    \n\n   Year  Month  Day  Hour  \n0  2023      1   15    12  \n1  2023      1   15     8  \n2  2023      1   15    15  \n3  2023      1   15    18  \n4  2023      1   15    19  \nMissing values:\nText         0\nSentiment    0\ndtype: int64\n                                                Text    Sentiment  \\\n0   Enjoying a beautiful day at the park!        ...   Positive     \n1   Traffic was terrible this morning.           ...   Negative     \n2   Just finished an amazing workout! 💪          ...   Positive     \n3   Excited about the upcoming weekend getaway!  ...   Positive     \n4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n\n                                 Cleaned_Text  \n0        enjoying a beautiful day at the park  \n1           traffic was terrible this morning  \n2            just finished an amazing workout  \n3  excited about the upcoming weekend getaway  \n4  trying out a new recipe for dinner tonight  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df['Sentiment'] = df['Sentiment'].str.strip()\ndf['Sentiment'] = df['Sentiment'].str.lower()\nreplace_dict = {\n    'positive': 'happy', 'joy': 'happy', 'serenity': 'happy', 'euphoria': 'happy',\n    'elation': 'happy', 'happiness': 'happy', 'playful': 'happy', 'amusement': 'happy',\n    'despair': 'sad', 'grief': 'sad', 'regret': 'sad', 'melancholy': 'sad',\n    'negative': 'sad', 'bad': 'sad', 'loneliness': 'sad', 'desolation': 'sad',\n    'excitement': 'excited', 'thrill': 'excited', 'adventure': 'excited',\n    'enthusiasm': 'excited', 'inspired': 'excited', 'inspiration': 'excited', 'arousal': 'excited',\n    'hate': 'angry', 'disgust': 'angry', 'bitterness': 'angry', 'betrayal': 'angry',\n    'frustration': 'angry', 'frustrated': 'angry', 'anger': 'angry',\n    'pride': 'proud', 'admiration': 'proud', 'awe': 'proud', 'reverence': 'proud',\n    'contentment': 'content', 'acceptance': 'content', 'fulfillment': 'content',\n    'calmness': 'content', 'satisfaction': 'content',\n    'indifference': 'neutral', 'numbness': 'neutral', 'ambivalence': 'neutral',\n    'hope': 'hopeful', 'determination': 'hopeful', 'resilience': 'hopeful', 'empowerment': 'hopeful',\n    'shame': 'embarassed', 'embarassment': 'embarassed',\n    'gratitude': 'grateful',\n    'compassionate': 'compassion', 'tenderness': 'compassion', 'empathetic': 'compassion'\n}\n\ndf['Sentiment'] = df['Sentiment'].replace(replace_dict)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:38:14.415917Z","iopub.execute_input":"2025-03-11T14:38:14.416246Z","iopub.status.idle":"2025-03-11T14:38:14.433966Z","shell.execute_reply.started":"2025-03-11T14:38:14.416222Z","shell.execute_reply":"2025-03-11T14:38:14.432367Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(\"Unique Sentiments:\", df['Sentiment'].value_counts())\nprint(\"Sample Cleaned Text:\", df['Cleaned_Text'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:38:18.413360Z","iopub.execute_input":"2025-03-11T14:38:18.413729Z","iopub.status.idle":"2025-03-11T14:38:18.422546Z","shell.execute_reply.started":"2025-03-11T14:38:18.413698Z","shell.execute_reply":"2025-03-11T14:38:18.421353Z"}},"outputs":[{"name":"stdout","text":"Unique Sentiments: Sentiment\nhappy             146\nexcited            66\nsad                64\ncontent            38\nneutral            36\n                 ... \nemotionalstorm      1\nsuffering           1\nmarvel              1\nspark               1\nfreedom             1\nName: count, Length: 144, dtype: int64\nSample Cleaned Text: 0          enjoying a beautiful day at the park\n1             traffic was terrible this morning\n2              just finished an amazing workout\n3    excited about the upcoming weekend getaway\n4    trying out a new recipe for dinner tonight\nName: Cleaned_Text, dtype: object\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.utils import resample\n\n# Combine rare classes (less than 10 samples) into 'Other'\nrare_threshold = 10\nsentiment_counts = df['Sentiment'].value_counts()\n\n# # Map rare classes to 'Other'\nrare_classes = sentiment_counts[sentiment_counts < rare_threshold].index\ndf['Sentiment'] = df['Sentiment'].apply(lambda x: 'Other' if x in rare_classes else x)\n\n# # Check updated class distribution\n# print(\"Updated class distribution:\\n\", df['Sentiment'].value_counts())\n\n# # Set target size as the mean of frequent classes\n# target_size = int(df['Sentiment'].value_counts().mean())\n\n# # Balance the dataset\n# balanced_df = pd.concat([\n#     resample(sentiment_df, \n#              replace=True if len(sentiment_df) < target_size else False,\n#              n_samples=target_size, \n#              random_state=42)\n#     for sentiment, sentiment_df in df.groupby('Sentiment')\n# ])\n\n# # Shuffle the dataset\n# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# # Check new class distribution\n# print(\"Balanced class distribution:\\n\", balanced_df['Sentiment'].value_counts())\n\n# # Save the balanced dataset\n# balanced_df.to_csv('balanced_sentimentdataset.csv', index=False)\nprint(\"Unique Sentiments:\", df['Sentiment'].value_counts())\n# print(\"Balanced dataset created and saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:38:54.597973Z","iopub.execute_input":"2025-03-11T14:38:54.598287Z","iopub.status.idle":"2025-03-11T14:38:54.609649Z","shell.execute_reply.started":"2025-03-11T14:38:54.598264Z","shell.execute_reply":"2025-03-11T14:38:54.608535Z"}},"outputs":[{"name":"stdout","text":"Unique Sentiments: Sentiment\nOther         228\nhappy         146\nexcited        66\nsad            64\ncontent        38\nneutral        36\nangry          34\nproud          28\nhopeful        28\ngrateful       22\ncuriosity      16\ncompassion     15\nnostalgia      11\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf['Sentiment_encoded'] = label_encoder.fit_transform(df['Sentiment'])\n\n# Display label mapping\nlabel_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\nprint(\"Label Mapping:\", label_mapping)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:40:02.505229Z","iopub.execute_input":"2025-03-11T14:40:02.505569Z","iopub.status.idle":"2025-03-11T14:40:02.513095Z","shell.execute_reply.started":"2025-03-11T14:40:02.505543Z","shell.execute_reply":"2025-03-11T14:40:02.511854Z"}},"outputs":[{"name":"stdout","text":"Label Mapping: {'Other': 0, 'angry': 1, 'compassion': 2, 'content': 3, 'curiosity': 4, 'excited': 5, 'grateful': 6, 'happy': 7, 'hopeful': 8, 'neutral': 9, 'nostalgia': 10, 'proud': 11, 'sad': 12}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Drop rows with missing text or sentiment\ndf.dropna(subset=['Text', 'Sentiment'], inplace=True)\n\n# Verify the dataset\nprint(df.info())\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T14:41:10.839365Z","iopub.execute_input":"2025-03-11T14:41:10.839694Z","iopub.status.idle":"2025-03-11T14:41:10.857313Z","shell.execute_reply.started":"2025-03-11T14:41:10.839667Z","shell.execute_reply":"2025-03-11T14:41:10.856256Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 732 entries, 0 to 731\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   Text               732 non-null    object\n 1   Sentiment          732 non-null    object\n 2   Cleaned_Text       732 non-null    object\n 3   Sentiment_encoded  732 non-null    int64 \ndtypes: int64(1), object(3)\nmemory usage: 23.0+ KB\nNone\n                                                Text Sentiment  \\\n0   Enjoying a beautiful day at the park!        ...     happy   \n1   Traffic was terrible this morning.           ...       sad   \n2   Just finished an amazing workout! 💪          ...     happy   \n3   Excited about the upcoming weekend getaway!  ...     happy   \n4   Trying out a new recipe for dinner tonight.  ...   neutral   \n\n                                 Cleaned_Text  Sentiment_encoded  \n0        enjoying a beautiful day at the park                  7  \n1           traffic was terrible this morning                 12  \n2            just finished an amazing workout                  7  \n3  excited about the upcoming weekend getaway                  7  \n4  trying out a new recipe for dinner tonight                  9  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n# Check for null values\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(\n    df['Cleaned_Text'],            # Input features (cleaned text)\n    df['Sentiment_encoded'],       # Target (encoded sentiment)\n    test_size=0.2,                 # 80/20 split\n    random_state=42,               # Reproducibility\n    stratify=df['Sentiment_encoded'] # Maintain class balance\n)\n\nprint(f\"Training Samples: {len(X_train)}, Testing Samples: {len(X_test)}\")\n#Initialize TF-IDF Vectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(\n    max_features=50000,          # Allow up to 10k words for richer features\n    stop_words='english',         # Remove common stop words\n    ngram_range=(1, 2),           # Capture both unigrams and bigrams\n    min_df=2,                     # Ignore words that appear in less than 2 documents\n    max_df=0.85,                  # Ignore words that appear in more than 85% of documents\n    sublinear_tf=True             # Apply logarithmic frequency scaling\n)\n\n# Transform the dataset\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\nprint(\"Shape of TF-IDF (Train):\", X_train_tfidf.shape)\nprint(\"Shape of TF-IDF (Test):\", X_test_tfidf.shape)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:21:25.129667Z","iopub.execute_input":"2025-03-11T16:21:25.130173Z","iopub.status.idle":"2025-03-11T16:21:25.211589Z","shell.execute_reply.started":"2025-03-11T16:21:25.130140Z","shell.execute_reply":"2025-03-11T16:21:25.210273Z"}},"outputs":[{"name":"stdout","text":"Training Samples: 585, Testing Samples: 147\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"# Preview TF-IDF matrices and encoded labels\nprint(X_train_tfidf[:3].toarray())\nprint(y_train[:3])\n\n# Inspect the TF-IDF feature names (optional)\nprint(tfidf_vectorizer.get_feature_names_out()[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:09:02.124562Z","iopub.execute_input":"2025-03-11T15:09:02.124952Z","iopub.status.idle":"2025-03-11T15:09:02.134795Z","shell.execute_reply.started":"2025-03-11T15:09:02.124919Z","shell.execute_reply":"2025-03-11T15:09:02.133644Z"}},"outputs":[{"name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n284    2\n386    6\n396    0\nName: Sentiment_encoded, dtype: int64\n['abstract' 'abstract art' 'abyss' 'academic' 'acceptance' 'accidentally'\n 'accomplished' 'accomplishment' 'achieve' 'achieved']\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, Dropout\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.callbacks import EarlyStopping\n\n# # Define the MLP model\n# mlp_model = Sequential()\n\n# # Input layer (input shape should match the TF-IDF output shape)\n# mlp_model.add(Dense(1024, input_shape=(X_train_tfidf.shape[1],), activation='relu'))\n\n# # Hidden layers with dropout\n# mlp_model.add(Dense(512, activation='relu'))\n# mlp_model.add(Dropout(0.3))\n\n# mlp_model.add(Dense(256, activation='relu'))\n# mlp_model.add(Dropout(0.3))\n\n# # Output layer (for multi-class classification)\n# num_classes = len(np.unique(y_train))\n# mlp_model.add(Dense(num_classes, activation='softmax'))\n\n# # Compile the model\n# mlp_model.compile(optimizer=Adam(learning_rate=0.0005), \n#                   loss='sparse_categorical_crossentropy', \n#                   metrics=['accuracy'])\n\n# # Model summary\n# mlp_model.summary()\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Define the improved MLP model\nmlp_model = Sequential()\n\n# Input layer with Batch Normalization\nmlp_model.add(Dense(2048, input_shape=(X_train_tfidf.shape[1],), activation='relu'))\nmlp_model.add(BatchNormalization())\nmlp_model.add(Dropout(0.4))\n\n# Additional Hidden layers\nmlp_model.add(Dense(1024, activation='relu'))\nmlp_model.add(BatchNormalization())\nmlp_model.add(Dropout(0.4))\n\nmlp_model.add(Dense(512, activation='relu'))\nmlp_model.add(BatchNormalization())\nmlp_model.add(Dropout(0.3))\n\nmlp_model.add(Dense(256, activation='relu'))\nmlp_model.add(BatchNormalization())\nmlp_model.add(Dropout(0.3))\n\n# Output layer\nnum_classes = len(np.unique(y_train))\nmlp_model.add(Dense(num_classes, activation='softmax'))\n\n# Learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n\n# Compile the model\nmlp_model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\nmlp_model.summary()\n\n# Train the model\nhistory = mlp_model.fit(X_train_tfidf, y_train,\n                        validation_data=(X_test_tfidf, y_test),\n                        epochs=200,\n                        batch_size=64)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:13:34.686984Z","iopub.execute_input":"2025-03-11T15:13:34.687322Z","iopub.status.idle":"2025-03-11T15:15:58.979508Z","shell.execute_reply.started":"2025-03-11T15:13:34.687296Z","shell.execute_reply":"2025-03-11T15:15:58.978372Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_16\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │       \u001b[38;5;34m2,408,448\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │           \u001b[38;5;34m8,192\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m2,098,176\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_33               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_34               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  │           \u001b[38;5;34m3,341\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,408,448</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_33               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_34               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,181,453\u001b[0m (19.77 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,181,453</span> (19.77 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,173,773\u001b[0m (19.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,173,773</span> (19.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,680\u001b[0m (30.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> (30.00 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.0913 - loss: 3.3657 - val_accuracy: 0.3197 - val_loss: 2.4876\nEpoch 2/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.3981 - loss: 1.9156 - val_accuracy: 0.3197 - val_loss: 2.4232\nEpoch 3/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6924 - loss: 1.0216 - val_accuracy: 0.3129 - val_loss: 2.3488\nEpoch 4/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8542 - loss: 0.5057 - val_accuracy: 0.3265 - val_loss: 2.2851\nEpoch 5/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9361 - loss: 0.3045 - val_accuracy: 0.3265 - val_loss: 2.2406\nEpoch 6/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9450 - loss: 0.2267 - val_accuracy: 0.3197 - val_loss: 2.1996\nEpoch 7/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9727 - loss: 0.1230 - val_accuracy: 0.3197 - val_loss: 2.1641\nEpoch 8/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9770 - loss: 0.1040 - val_accuracy: 0.3265 - val_loss: 2.1304\nEpoch 9/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9904 - loss: 0.0665 - val_accuracy: 0.3265 - val_loss: 2.0931\nEpoch 10/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9851 - loss: 0.0711 - val_accuracy: 0.3197 - val_loss: 2.0603\nEpoch 11/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9957 - loss: 0.0451 - val_accuracy: 0.3197 - val_loss: 2.0363\nEpoch 12/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9941 - loss: 0.0437 - val_accuracy: 0.3197 - val_loss: 2.0229\nEpoch 13/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9916 - loss: 0.0414 - val_accuracy: 0.3061 - val_loss: 2.0167\nEpoch 14/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9891 - loss: 0.0449 - val_accuracy: 0.3197 - val_loss: 1.9989\nEpoch 15/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9860 - loss: 0.0507 - val_accuracy: 0.3265 - val_loss: 1.9926\nEpoch 16/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9872 - loss: 0.0442 - val_accuracy: 0.3537 - val_loss: 1.9593\nEpoch 17/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9977 - loss: 0.0371 - val_accuracy: 0.3605 - val_loss: 1.9540\nEpoch 18/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9919 - loss: 0.0630 - val_accuracy: 0.3605 - val_loss: 1.9948\nEpoch 19/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9912 - loss: 0.0439 - val_accuracy: 0.3605 - val_loss: 1.9825\nEpoch 20/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9951 - loss: 0.0371 - val_accuracy: 0.3605 - val_loss: 1.9741\nEpoch 21/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9972 - loss: 0.0216 - val_accuracy: 0.3605 - val_loss: 2.0106\nEpoch 22/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9927 - loss: 0.0319 - val_accuracy: 0.3605 - val_loss: 2.0460\nEpoch 23/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9974 - loss: 0.0234 - val_accuracy: 0.3537 - val_loss: 2.0487\nEpoch 24/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9983 - loss: 0.0175 - val_accuracy: 0.3673 - val_loss: 1.9782\nEpoch 25/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9972 - loss: 0.0246 - val_accuracy: 0.3878 - val_loss: 1.8678\nEpoch 26/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9923 - loss: 0.0255 - val_accuracy: 0.3469 - val_loss: 2.0248\nEpoch 27/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9821 - loss: 0.0455 - val_accuracy: 0.3537 - val_loss: 1.8989\nEpoch 28/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9931 - loss: 0.0195 - val_accuracy: 0.3741 - val_loss: 1.8966\nEpoch 29/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9949 - loss: 0.0347 - val_accuracy: 0.3810 - val_loss: 2.0137\nEpoch 30/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9925 - loss: 0.0197 - val_accuracy: 0.3537 - val_loss: 2.0842\nEpoch 31/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9873 - loss: 0.0328 - val_accuracy: 0.3605 - val_loss: 2.0230\nEpoch 32/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9935 - loss: 0.0260 - val_accuracy: 0.3810 - val_loss: 2.0512\nEpoch 33/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.3810 - val_loss: 2.0464\nEpoch 34/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9946 - loss: 0.0246 - val_accuracy: 0.3741 - val_loss: 2.1897\nEpoch 35/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9986 - loss: 0.0121 - val_accuracy: 0.3741 - val_loss: 2.2140\nEpoch 36/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9969 - loss: 0.0140 - val_accuracy: 0.4150 - val_loss: 2.1215\nEpoch 37/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9866 - loss: 0.0478 - val_accuracy: 0.4218 - val_loss: 2.1712\nEpoch 38/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9813 - loss: 0.0978 - val_accuracy: 0.4286 - val_loss: 2.1300\nEpoch 39/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9811 - loss: 0.0373 - val_accuracy: 0.4762 - val_loss: 1.9486\nEpoch 40/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9941 - loss: 0.0271 - val_accuracy: 0.4966 - val_loss: 1.9418\nEpoch 41/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9918 - loss: 0.0489 - val_accuracy: 0.5102 - val_loss: 1.9443\nEpoch 42/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9980 - loss: 0.0124 - val_accuracy: 0.5170 - val_loss: 2.0241\nEpoch 43/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9986 - loss: 0.0147 - val_accuracy: 0.5306 - val_loss: 2.0268\nEpoch 44/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9928 - loss: 0.0134 - val_accuracy: 0.5374 - val_loss: 2.0354\nEpoch 45/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9990 - loss: 0.0120 - val_accuracy: 0.5374 - val_loss: 2.0648\nEpoch 46/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9967 - loss: 0.0248 - val_accuracy: 0.5170 - val_loss: 2.1534\nEpoch 47/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9942 - loss: 0.0411 - val_accuracy: 0.4694 - val_loss: 2.4850\nEpoch 48/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9913 - loss: 0.0718 - val_accuracy: 0.4830 - val_loss: 2.4736\nEpoch 49/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9958 - loss: 0.0164 - val_accuracy: 0.4966 - val_loss: 2.3725\nEpoch 50/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9945 - loss: 0.0307 - val_accuracy: 0.5578 - val_loss: 2.3077\nEpoch 51/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9903 - loss: 0.0237 - val_accuracy: 0.5170 - val_loss: 2.5244\nEpoch 52/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9891 - loss: 0.0401 - val_accuracy: 0.5306 - val_loss: 2.7259\nEpoch 53/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9920 - loss: 0.0217 - val_accuracy: 0.5238 - val_loss: 2.5770\nEpoch 54/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9959 - loss: 0.0207 - val_accuracy: 0.5170 - val_loss: 2.4813\nEpoch 55/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9870 - loss: 0.0373 - val_accuracy: 0.5238 - val_loss: 2.4708\nEpoch 56/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9830 - loss: 0.0462 - val_accuracy: 0.5442 - val_loss: 2.6498\nEpoch 57/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9932 - loss: 0.0357 - val_accuracy: 0.5578 - val_loss: 2.9455\nEpoch 58/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9914 - loss: 0.0342 - val_accuracy: 0.5306 - val_loss: 3.1286\nEpoch 59/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9823 - loss: 0.0389 - val_accuracy: 0.5238 - val_loss: 3.0695\nEpoch 60/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9945 - loss: 0.0427 - val_accuracy: 0.5374 - val_loss: 3.0313\nEpoch 61/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9997 - loss: 0.0088 - val_accuracy: 0.5510 - val_loss: 3.0701\nEpoch 62/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9995 - loss: 0.0150 - val_accuracy: 0.5646 - val_loss: 3.1778\nEpoch 63/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9941 - loss: 0.0229 - val_accuracy: 0.5510 - val_loss: 3.1426\nEpoch 64/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9919 - loss: 0.0248 - val_accuracy: 0.5578 - val_loss: 3.1765\nEpoch 65/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9947 - loss: 0.0226 - val_accuracy: 0.5238 - val_loss: 3.3411\nEpoch 66/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9930 - loss: 0.0311 - val_accuracy: 0.5374 - val_loss: 3.0973\nEpoch 67/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9848 - loss: 0.0359 - val_accuracy: 0.5306 - val_loss: 3.1743\nEpoch 68/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9924 - loss: 0.0247 - val_accuracy: 0.5374 - val_loss: 3.2698\nEpoch 69/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9890 - loss: 0.0305 - val_accuracy: 0.5442 - val_loss: 3.2771\nEpoch 70/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9975 - loss: 0.0112 - val_accuracy: 0.5714 - val_loss: 3.2683\nEpoch 71/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9931 - loss: 0.0172 - val_accuracy: 0.5714 - val_loss: 3.2364\nEpoch 72/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9924 - loss: 0.0168 - val_accuracy: 0.5714 - val_loss: 3.2495\nEpoch 73/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9964 - loss: 0.0143 - val_accuracy: 0.5714 - val_loss: 3.2539\nEpoch 74/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9986 - loss: 0.0080 - val_accuracy: 0.5714 - val_loss: 3.2271\nEpoch 75/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9989 - loss: 0.0091 - val_accuracy: 0.5646 - val_loss: 3.1085\nEpoch 76/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9973 - loss: 0.0123 - val_accuracy: 0.5578 - val_loss: 3.1460\nEpoch 77/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9869 - loss: 0.0363 - val_accuracy: 0.5374 - val_loss: 3.3396\nEpoch 78/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9940 - loss: 0.0175 - val_accuracy: 0.5306 - val_loss: 3.5327\nEpoch 79/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9924 - loss: 0.0234 - val_accuracy: 0.5374 - val_loss: 3.6486\nEpoch 80/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9929 - loss: 0.0213 - val_accuracy: 0.5510 - val_loss: 3.8739\nEpoch 81/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9910 - loss: 0.0423 - val_accuracy: 0.5306 - val_loss: 3.9112\nEpoch 82/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9918 - loss: 0.0203 - val_accuracy: 0.5374 - val_loss: 3.8738\nEpoch 83/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9955 - loss: 0.0211 - val_accuracy: 0.5442 - val_loss: 3.8101\nEpoch 84/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9958 - loss: 0.0402 - val_accuracy: 0.5510 - val_loss: 3.6340\nEpoch 85/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9939 - loss: 0.0521 - val_accuracy: 0.5510 - val_loss: 3.5514\nEpoch 86/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.5442 - val_loss: 3.5212\nEpoch 87/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9994 - loss: 0.0114 - val_accuracy: 0.5374 - val_loss: 3.5758\nEpoch 88/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9972 - loss: 0.0288 - val_accuracy: 0.5374 - val_loss: 3.6859\nEpoch 89/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9972 - loss: 0.0171 - val_accuracy: 0.5374 - val_loss: 3.6724\nEpoch 90/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9955 - loss: 0.0224 - val_accuracy: 0.5442 - val_loss: 3.6606\nEpoch 91/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9958 - loss: 0.0101 - val_accuracy: 0.5374 - val_loss: 3.5666\nEpoch 92/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9936 - loss: 0.0198 - val_accuracy: 0.5442 - val_loss: 3.3715\nEpoch 93/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9935 - loss: 0.0174 - val_accuracy: 0.5510 - val_loss: 3.3917\nEpoch 94/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9968 - loss: 0.0177 - val_accuracy: 0.5170 - val_loss: 3.3896\nEpoch 95/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9937 - loss: 0.0227 - val_accuracy: 0.5170 - val_loss: 3.4165\nEpoch 96/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9971 - loss: 0.0129 - val_accuracy: 0.5374 - val_loss: 3.4551\nEpoch 97/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9975 - loss: 0.0097 - val_accuracy: 0.5374 - val_loss: 3.4503\nEpoch 98/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9957 - loss: 0.0070 - val_accuracy: 0.5374 - val_loss: 3.4386\nEpoch 99/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.5374 - val_loss: 3.4314\nEpoch 100/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0081 - val_accuracy: 0.5306 - val_loss: 3.3822\nEpoch 101/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.5374 - val_loss: 3.3154\nEpoch 102/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.5374 - val_loss: 3.2854\nEpoch 103/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9964 - loss: 0.0076 - val_accuracy: 0.5374 - val_loss: 3.3080\nEpoch 104/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.5306 - val_loss: 3.4881\nEpoch 105/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9957 - loss: 0.0169 - val_accuracy: 0.5238 - val_loss: 3.5092\nEpoch 106/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9997 - loss: 0.0045 - val_accuracy: 0.5238 - val_loss: 3.4593\nEpoch 107/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9970 - loss: 0.0097 - val_accuracy: 0.5374 - val_loss: 3.3821\nEpoch 108/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9902 - loss: 0.1175 - val_accuracy: 0.5374 - val_loss: 3.3674\nEpoch 109/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9943 - loss: 0.0198 - val_accuracy: 0.5578 - val_loss: 3.4461\nEpoch 110/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9994 - loss: 0.0109 - val_accuracy: 0.5578 - val_loss: 3.4040\nEpoch 111/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9967 - loss: 0.0087 - val_accuracy: 0.5578 - val_loss: 3.4258\nEpoch 112/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9925 - loss: 0.0128 - val_accuracy: 0.5578 - val_loss: 3.4391\nEpoch 113/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9982 - loss: 0.0127 - val_accuracy: 0.5510 - val_loss: 3.3359\nEpoch 114/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9894 - loss: 0.0255 - val_accuracy: 0.5374 - val_loss: 3.6020\nEpoch 115/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9894 - loss: 0.0372 - val_accuracy: 0.5442 - val_loss: 3.6872\nEpoch 116/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9972 - loss: 0.0101 - val_accuracy: 0.5306 - val_loss: 3.7664\nEpoch 117/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9906 - loss: 0.0903 - val_accuracy: 0.5646 - val_loss: 3.4382\nEpoch 118/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9925 - loss: 0.0387 - val_accuracy: 0.5714 - val_loss: 3.2943\nEpoch 119/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9840 - loss: 0.0396 - val_accuracy: 0.5850 - val_loss: 3.2321\nEpoch 120/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9878 - loss: 0.0380 - val_accuracy: 0.5646 - val_loss: 3.1746\nEpoch 121/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9888 - loss: 0.0313 - val_accuracy: 0.5646 - val_loss: 3.1844\nEpoch 122/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.5578 - val_loss: 3.2373\nEpoch 123/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9914 - loss: 0.0241 - val_accuracy: 0.5510 - val_loss: 3.2674\nEpoch 124/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9956 - loss: 0.0136 - val_accuracy: 0.5442 - val_loss: 3.2476\nEpoch 125/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9961 - loss: 0.0129 - val_accuracy: 0.5578 - val_loss: 3.2768\nEpoch 126/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9995 - loss: 0.0112 - val_accuracy: 0.5578 - val_loss: 3.2971\nEpoch 127/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9995 - loss: 0.0086 - val_accuracy: 0.5646 - val_loss: 3.3172\nEpoch 128/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.5578 - val_loss: 3.3034\nEpoch 129/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9997 - loss: 0.0054 - val_accuracy: 0.5578 - val_loss: 3.3819\nEpoch 130/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9986 - loss: 0.0064 - val_accuracy: 0.5646 - val_loss: 3.4260\nEpoch 131/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9966 - loss: 0.0078 - val_accuracy: 0.5646 - val_loss: 3.3317\nEpoch 132/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9986 - loss: 0.0122 - val_accuracy: 0.5578 - val_loss: 3.2754\nEpoch 133/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.5646 - val_loss: 3.2651\nEpoch 134/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9959 - loss: 0.0102 - val_accuracy: 0.5510 - val_loss: 3.3708\nEpoch 135/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9972 - loss: 0.0115 - val_accuracy: 0.5510 - val_loss: 3.3988\nEpoch 136/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.5374 - val_loss: 3.4373\nEpoch 137/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9972 - loss: 0.0065 - val_accuracy: 0.5510 - val_loss: 3.4344\nEpoch 138/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9952 - loss: 0.0167 - val_accuracy: 0.5510 - val_loss: 3.4306\nEpoch 139/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.5578 - val_loss: 3.3873\nEpoch 140/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.5510 - val_loss: 3.2478\nEpoch 141/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9947 - loss: 0.0492 - val_accuracy: 0.5510 - val_loss: 3.2692\nEpoch 142/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0110 - val_accuracy: 0.5374 - val_loss: 3.5611\nEpoch 143/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9873 - loss: 0.0304 - val_accuracy: 0.5238 - val_loss: 3.6312\nEpoch 144/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9942 - loss: 0.0310 - val_accuracy: 0.5306 - val_loss: 3.6840\nEpoch 145/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9903 - loss: 0.0305 - val_accuracy: 0.5374 - val_loss: 3.6053\nEpoch 146/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9939 - loss: 0.0155 - val_accuracy: 0.5442 - val_loss: 3.5097\nEpoch 147/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.5442 - val_loss: 3.4661\nEpoch 148/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9929 - loss: 0.0158 - val_accuracy: 0.5510 - val_loss: 3.4772\nEpoch 149/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 0.5646 - val_loss: 3.4654\nEpoch 150/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.5578 - val_loss: 3.4435\nEpoch 151/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.5578 - val_loss: 3.3590\nEpoch 152/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9957 - loss: 0.0126 - val_accuracy: 0.5578 - val_loss: 3.2152\nEpoch 153/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9968 - loss: 0.0201 - val_accuracy: 0.5442 - val_loss: 3.2965\nEpoch 154/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9875 - loss: 0.0278 - val_accuracy: 0.5442 - val_loss: 3.2205\nEpoch 155/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9841 - loss: 0.0414 - val_accuracy: 0.5510 - val_loss: 3.2092\nEpoch 156/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9971 - loss: 0.0080 - val_accuracy: 0.5578 - val_loss: 3.3043\nEpoch 157/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9937 - loss: 0.0243 - val_accuracy: 0.5578 - val_loss: 3.3718\nEpoch 158/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9968 - loss: 0.0172 - val_accuracy: 0.5442 - val_loss: 3.4901\nEpoch 159/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9944 - loss: 0.0345 - val_accuracy: 0.5714 - val_loss: 3.5920\nEpoch 160/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9918 - loss: 0.0251 - val_accuracy: 0.5782 - val_loss: 3.6137\nEpoch 161/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9950 - loss: 0.0165 - val_accuracy: 0.5918 - val_loss: 3.5438\nEpoch 162/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 0.5918 - val_loss: 3.4974\nEpoch 163/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9940 - loss: 0.0157 - val_accuracy: 0.5918 - val_loss: 3.4502\nEpoch 164/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.5714 - val_loss: 3.4258\nEpoch 165/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.5918 - val_loss: 3.4155\nEpoch 166/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9978 - loss: 0.0045 - val_accuracy: 0.5714 - val_loss: 3.5069\nEpoch 167/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9997 - loss: 0.0052 - val_accuracy: 0.5782 - val_loss: 3.6245\nEpoch 168/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9942 - loss: 0.0146 - val_accuracy: 0.5714 - val_loss: 3.6033\nEpoch 169/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9935 - loss: 0.0288 - val_accuracy: 0.5782 - val_loss: 3.5114\nEpoch 170/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9956 - loss: 0.0098 - val_accuracy: 0.5782 - val_loss: 3.4199\nEpoch 171/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.5714 - val_loss: 3.3465\nEpoch 172/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9926 - loss: 0.0133 - val_accuracy: 0.5646 - val_loss: 3.2990\nEpoch 173/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9972 - loss: 0.0082 - val_accuracy: 0.5578 - val_loss: 3.3134\nEpoch 174/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.5578 - val_loss: 3.3402\nEpoch 175/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5714 - val_loss: 3.3465\nEpoch 176/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5714 - val_loss: 3.3400\nEpoch 177/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5714 - val_loss: 3.4401\nEpoch 178/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9987 - loss: 0.0123 - val_accuracy: 0.5782 - val_loss: 3.5405\nEpoch 179/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9939 - loss: 0.0225 - val_accuracy: 0.5782 - val_loss: 3.5357\nEpoch 180/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.5714 - val_loss: 3.4793\nEpoch 181/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9969 - loss: 0.0050 - val_accuracy: 0.5850 - val_loss: 3.4437\nEpoch 182/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5850 - val_loss: 3.4311\nEpoch 183/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.5986 - val_loss: 3.3910\nEpoch 184/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.5918 - val_loss: 3.2978\nEpoch 185/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9951 - loss: 0.0110 - val_accuracy: 0.5918 - val_loss: 3.3102\nEpoch 186/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.5782 - val_loss: 3.4061\nEpoch 187/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9968 - loss: 0.0139 - val_accuracy: 0.5850 - val_loss: 3.4471\nEpoch 188/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9978 - loss: 0.0148 - val_accuracy: 0.5986 - val_loss: 3.2678\nEpoch 189/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9896 - loss: 0.0370 - val_accuracy: 0.6054 - val_loss: 3.2795\nEpoch 190/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9973 - loss: 0.0109 - val_accuracy: 0.6054 - val_loss: 3.3132\nEpoch 191/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.5986 - val_loss: 3.3319\nEpoch 192/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.0088 - val_accuracy: 0.5986 - val_loss: 3.3341\nEpoch 193/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.5986 - val_loss: 3.3075\nEpoch 194/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9868 - loss: 0.0262 - val_accuracy: 0.5918 - val_loss: 3.2911\nEpoch 195/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5918 - val_loss: 3.3097\nEpoch 196/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9995 - loss: 0.0052 - val_accuracy: 0.5918 - val_loss: 3.3236\nEpoch 197/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9978 - loss: 0.0134 - val_accuracy: 0.5918 - val_loss: 3.3460\nEpoch 198/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5918 - val_loss: 3.3539\nEpoch 199/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.5918 - val_loss: 3.4558\nEpoch 200/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.5850 - val_loss: 3.4808\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Early stopping to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model\nhistory = mlp_model.fit(\n    X_train_tfidf, y_train,\n    epochs=50,\n    batch_size=32,\n    validation_split=0.2,\n    callbacks=[early_stopping],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:00:00.865460Z","iopub.execute_input":"2025-03-11T15:00:00.865938Z","iopub.status.idle":"2025-03-11T15:00:07.976801Z","shell.execute_reply.started":"2025-03-11T15:00:00.865901Z","shell.execute_reply":"2025-03-11T15:00:07.975695Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.2066 - loss: 2.5073 - val_accuracy: 0.3846 - val_loss: 2.1914\nEpoch 2/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3096 - loss: 2.1652 - val_accuracy: 0.3761 - val_loss: 2.0058\nEpoch 3/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3307 - loss: 1.9857 - val_accuracy: 0.3846 - val_loss: 1.9574\nEpoch 4/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4027 - loss: 1.8064 - val_accuracy: 0.4701 - val_loss: 1.8581\nEpoch 5/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5381 - loss: 1.3840 - val_accuracy: 0.4786 - val_loss: 1.7581\nEpoch 6/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6397 - loss: 1.1507 - val_accuracy: 0.5385 - val_loss: 1.6294\nEpoch 7/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7576 - loss: 0.8686 - val_accuracy: 0.5470 - val_loss: 1.5339\nEpoch 8/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9161 - loss: 0.5603 - val_accuracy: 0.5641 - val_loss: 1.5052\nEpoch 9/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9842 - loss: 0.2690 - val_accuracy: 0.5812 - val_loss: 1.4120\nEpoch 10/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9798 - loss: 0.1333 - val_accuracy: 0.6068 - val_loss: 1.5340\nEpoch 11/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9895 - loss: 0.0758 - val_accuracy: 0.6068 - val_loss: 1.5084\nEpoch 12/50\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0496 - val_accuracy: 0.6325 - val_loss: 1.5410\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Evaluate on the test set\ny_pred = np.argmax(mlp_model.predict(X_test_tfidf), axis=1)\n\n# Performance metrics\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:40:21.094829Z","iopub.execute_input":"2025-03-11T15:40:21.095221Z","iopub.status.idle":"2025-03-11T15:40:21.363267Z","shell.execute_reply.started":"2025-03-11T15:40:21.095188Z","shell.execute_reply":"2025-03-11T15:40:21.361963Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\nAccuracy: 0.5850340136054422\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.57      0.63      0.60        46\n           1       0.57      0.57      0.57         7\n           2       1.00      0.67      0.80         3\n           3       1.00      0.50      0.67         8\n           4       1.00      0.33      0.50         3\n           5       0.75      0.69      0.72        13\n           6       1.00      0.25      0.40         4\n           7       0.41      0.62      0.49        29\n           8       0.71      0.83      0.77         6\n           9       0.50      0.14      0.22         7\n          10       0.50      1.00      0.67         2\n          11       0.75      0.50      0.60         6\n          12       0.88      0.54      0.67        13\n\n    accuracy                           0.59       147\n   macro avg       0.74      0.56      0.59       147\nweighted avg       0.64      0.59      0.58       147\n\n\nConfusion Matrix:\n [[29  2  0  0  0  1  0 12  1  0  1  0  0]\n [ 1  4  0  0  0  0  0  1  0  0  0  1  0]\n [ 0  0  2  0  0  0  0  0  0  0  0  0  1]\n [ 1  0  0  4  0  0  0  3  0  0  0  0  0]\n [ 1  0  0  0  1  0  0  1  0  0  0  0  0]\n [ 1  0  0  0  0  9  0  3  0  0  0  0  0]\n [ 2  0  0  0  0  0  1  1  0  0  0  0  0]\n [ 6  0  0  0  0  2  0 18  1  1  1  0  0]\n [ 1  0  0  0  0  0  0  0  5  0  0  0  0]\n [ 3  0  0  0  0  0  0  3  0  1  0  0  0]\n [ 0  0  0  0  0  0  0  0  0  0  2  0  0]\n [ 2  0  0  0  0  0  0  1  0  0  0  3  0]\n [ 4  1  0  0  0  0  0  1  0  0  0  0  7]]\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Define the model\nmlp_model_leakyrelu = Sequential()\n\n# Input layer\nmlp_model_leakyrelu.add(Dense(2048, input_shape=(X_train_tfidf.shape[1],)))\nmlp_model_leakyrelu.add(LeakyReLU(alpha=0.1))\nmlp_model_leakyrelu.add(BatchNormalization())\nmlp_model_leakyrelu.add(Dropout(0.2))\n\n# Hidden layers\nfor units in [1024, 512, 256]:\n    mlp_model_leakyrelu.add(Dense(units))\n    mlp_model_leakyrelu.add(LeakyReLU(alpha=0.1))\n    mlp_model_leakyrelu.add(BatchNormalization())\n    mlp_model_leakyrelu.add(Dropout(0.3))\n\n# Output layer\nnum_classes = len(np.unique(y_train))\nmlp_model_leakyrelu.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmlp_model_leakyrelu.compile(optimizer=Adam(learning_rate=0.001),\n                            loss='sparse_categorical_crossentropy',\n                            metrics=['accuracy'])\n\n# Learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n\n# Train the model\nhistory_leakyrelu = mlp_model_leakyrelu.fit(X_train_tfidf, y_train,\n                                            validation_data=(X_test_tfidf, y_test),\n                                            epochs=100,\n                                            batch_size=64,\n                                            callbacks=[lr_scheduler])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:47:37.842774Z","iopub.execute_input":"2025-03-11T15:47:37.843186Z","iopub.status.idle":"2025-03-11T15:50:15.638029Z","shell.execute_reply.started":"2025-03-11T15:47:37.843153Z","shell.execute_reply":"2025-03-11T15:50:15.636688Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.1074 - loss: 3.3793 - val_accuracy: 0.3197 - val_loss: 2.5010 - learning_rate: 0.0010\nEpoch 2/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6001 - loss: 1.2550 - val_accuracy: 0.3129 - val_loss: 2.4218 - learning_rate: 0.0010\nEpoch 3/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8162 - loss: 0.6112 - val_accuracy: 0.3197 - val_loss: 2.3368 - learning_rate: 0.0010\nEpoch 4/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9235 - loss: 0.2792 - val_accuracy: 0.3197 - val_loss: 2.2618 - learning_rate: 0.0010\nEpoch 5/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9559 - loss: 0.1921 - val_accuracy: 0.3129 - val_loss: 2.1961 - learning_rate: 0.0010\nEpoch 6/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9770 - loss: 0.1407 - val_accuracy: 0.3265 - val_loss: 2.1398 - learning_rate: 0.0010\nEpoch 7/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9802 - loss: 0.1020 - val_accuracy: 0.3197 - val_loss: 2.1015 - learning_rate: 0.0010\nEpoch 8/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9744 - loss: 0.0919 - val_accuracy: 0.3197 - val_loss: 2.0738 - learning_rate: 0.0010\nEpoch 9/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9925 - loss: 0.0603 - val_accuracy: 0.3537 - val_loss: 2.0539 - learning_rate: 0.0010\nEpoch 10/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9964 - loss: 0.0431 - val_accuracy: 0.3469 - val_loss: 2.0511 - learning_rate: 0.0010\nEpoch 11/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9930 - loss: 0.0476 - val_accuracy: 0.3741 - val_loss: 2.0642 - learning_rate: 0.0010\nEpoch 12/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9885 - loss: 0.0387\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9875 - loss: 0.0430 - val_accuracy: 0.3673 - val_loss: 2.0738 - learning_rate: 0.0010\nEpoch 13/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9800 - loss: 0.0627 - val_accuracy: 0.3469 - val_loss: 2.0759 - learning_rate: 5.0000e-04\nEpoch 14/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9938 - loss: 0.0495\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9940 - loss: 0.0471 - val_accuracy: 0.3537 - val_loss: 2.0743 - learning_rate: 5.0000e-04\nEpoch 15/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9962 - loss: 0.0288 - val_accuracy: 0.3537 - val_loss: 2.0741 - learning_rate: 2.5000e-04\nEpoch 16/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9957 - loss: 0.0258\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9953 - loss: 0.0271 - val_accuracy: 0.3537 - val_loss: 2.0722 - learning_rate: 2.5000e-04\nEpoch 17/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9994 - loss: 0.0161 - val_accuracy: 0.3537 - val_loss: 2.0686 - learning_rate: 1.2500e-04\nEpoch 18/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9968 - loss: 0.0140\nEpoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9971 - loss: 0.0142 - val_accuracy: 0.3537 - val_loss: 2.0655 - learning_rate: 1.2500e-04\nEpoch 19/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9957 - loss: 0.0198 - val_accuracy: 0.3537 - val_loss: 2.0578 - learning_rate: 6.2500e-05\nEpoch 20/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0141\nEpoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9978 - loss: 0.0145 - val_accuracy: 0.3537 - val_loss: 2.0524 - learning_rate: 6.2500e-05\nEpoch 21/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9976 - loss: 0.0174 - val_accuracy: 0.3537 - val_loss: 2.0460 - learning_rate: 3.1250e-05\nEpoch 22/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9921 - loss: 0.0247 - val_accuracy: 0.3537 - val_loss: 2.0343 - learning_rate: 3.1250e-05\nEpoch 23/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.3605 - val_loss: 2.0248 - learning_rate: 3.1250e-05\nEpoch 24/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9957 - loss: 0.0197 - val_accuracy: 0.3537 - val_loss: 2.0125 - learning_rate: 3.1250e-05\nEpoch 25/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9980 - loss: 0.0201 - val_accuracy: 0.3537 - val_loss: 2.0070 - learning_rate: 3.1250e-05\nEpoch 26/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9977 - loss: 0.0186 - val_accuracy: 0.3537 - val_loss: 1.9939 - learning_rate: 3.1250e-05\nEpoch 27/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9954 - loss: 0.0297 - val_accuracy: 0.3469 - val_loss: 1.9783 - learning_rate: 3.1250e-05\nEpoch 28/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9986 - loss: 0.0191 - val_accuracy: 0.3401 - val_loss: 1.9656 - learning_rate: 3.1250e-05\nEpoch 29/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9954 - loss: 0.0254 - val_accuracy: 0.3401 - val_loss: 1.9523 - learning_rate: 3.1250e-05\nEpoch 30/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9967 - loss: 0.0177 - val_accuracy: 0.3469 - val_loss: 1.9364 - learning_rate: 3.1250e-05\nEpoch 31/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.3673 - val_loss: 1.9232 - learning_rate: 3.1250e-05\nEpoch 32/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9971 - loss: 0.0166 - val_accuracy: 0.3673 - val_loss: 1.9082 - learning_rate: 3.1250e-05\nEpoch 33/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9964 - loss: 0.0296 - val_accuracy: 0.3810 - val_loss: 1.8925 - learning_rate: 3.1250e-05\nEpoch 34/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9970 - loss: 0.0175 - val_accuracy: 0.3878 - val_loss: 1.8798 - learning_rate: 3.1250e-05\nEpoch 35/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9992 - loss: 0.0160 - val_accuracy: 0.4082 - val_loss: 1.8641 - learning_rate: 3.1250e-05\nEpoch 36/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9984 - loss: 0.0122 - val_accuracy: 0.4082 - val_loss: 1.8479 - learning_rate: 3.1250e-05\nEpoch 37/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.4150 - val_loss: 1.8274 - learning_rate: 3.1250e-05\nEpoch 38/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9972 - loss: 0.0175 - val_accuracy: 0.4286 - val_loss: 1.8083 - learning_rate: 3.1250e-05\nEpoch 39/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9975 - loss: 0.0169 - val_accuracy: 0.4490 - val_loss: 1.7922 - learning_rate: 3.1250e-05\nEpoch 40/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.4626 - val_loss: 1.7774 - learning_rate: 3.1250e-05\nEpoch 41/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9992 - loss: 0.0133 - val_accuracy: 0.4626 - val_loss: 1.7659 - learning_rate: 3.1250e-05\nEpoch 42/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.4626 - val_loss: 1.7541 - learning_rate: 3.1250e-05\nEpoch 43/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9885 - loss: 0.0294 - val_accuracy: 0.4830 - val_loss: 1.7374 - learning_rate: 3.1250e-05\nEpoch 44/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9957 - loss: 0.0167 - val_accuracy: 0.4966 - val_loss: 1.7242 - learning_rate: 3.1250e-05\nEpoch 45/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9900 - loss: 0.0348 - val_accuracy: 0.5102 - val_loss: 1.7140 - learning_rate: 3.1250e-05\nEpoch 46/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.5238 - val_loss: 1.7028 - learning_rate: 3.1250e-05\nEpoch 47/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9986 - loss: 0.0134 - val_accuracy: 0.5238 - val_loss: 1.6934 - learning_rate: 3.1250e-05\nEpoch 48/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9997 - loss: 0.0103 - val_accuracy: 0.5306 - val_loss: 1.6852 - learning_rate: 3.1250e-05\nEpoch 49/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9940 - loss: 0.0191 - val_accuracy: 0.5306 - val_loss: 1.6792 - learning_rate: 3.1250e-05\nEpoch 50/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.5442 - val_loss: 1.6644 - learning_rate: 3.1250e-05\nEpoch 51/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9995 - loss: 0.0172 - val_accuracy: 0.5510 - val_loss: 1.6578 - learning_rate: 3.1250e-05\nEpoch 52/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.5714 - val_loss: 1.6621 - learning_rate: 3.1250e-05\nEpoch 53/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0120\nEpoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5714 - val_loss: 1.6663 - learning_rate: 3.1250e-05\nEpoch 54/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9970 - loss: 0.0161 - val_accuracy: 0.5782 - val_loss: 1.6730 - learning_rate: 1.5625e-05\nEpoch 55/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9981 - loss: 0.0125\nEpoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9980 - loss: 0.0128 - val_accuracy: 0.5782 - val_loss: 1.6813 - learning_rate: 1.5625e-05\nEpoch 56/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9957 - loss: 0.0205 - val_accuracy: 0.5918 - val_loss: 1.6887 - learning_rate: 7.8125e-06\nEpoch 57/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0124\nEpoch 57: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.5850 - val_loss: 1.7002 - learning_rate: 7.8125e-06\nEpoch 58/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9978 - loss: 0.0239 - val_accuracy: 0.5850 - val_loss: 1.7111 - learning_rate: 3.9063e-06\nEpoch 59/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0111\nEpoch 59: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9997 - loss: 0.0118 - val_accuracy: 0.5850 - val_loss: 1.7263 - learning_rate: 3.9063e-06\nEpoch 60/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9997 - loss: 0.0170 - val_accuracy: 0.5850 - val_loss: 1.7416 - learning_rate: 1.9531e-06\nEpoch 61/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9949 - loss: 0.0129\nEpoch 61: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9952 - loss: 0.0130 - val_accuracy: 0.5850 - val_loss: 1.7567 - learning_rate: 1.9531e-06\nEpoch 62/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9994 - loss: 0.0120 - val_accuracy: 0.5850 - val_loss: 1.7753 - learning_rate: 9.7656e-07\nEpoch 63/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9902 - loss: 0.0323\nEpoch 63: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9913 - loss: 0.0300 - val_accuracy: 0.5986 - val_loss: 1.7919 - learning_rate: 9.7656e-07\nEpoch 64/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.5918 - val_loss: 1.8115 - learning_rate: 4.8828e-07\nEpoch 65/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9977 - loss: 0.0159\nEpoch 65: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9978 - loss: 0.0160 - val_accuracy: 0.5918 - val_loss: 1.8332 - learning_rate: 4.8828e-07\nEpoch 66/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5850 - val_loss: 1.8517 - learning_rate: 2.4414e-07\nEpoch 67/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0148\nEpoch 67: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.5918 - val_loss: 1.8704 - learning_rate: 2.4414e-07\nEpoch 68/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9997 - loss: 0.0126 - val_accuracy: 0.5918 - val_loss: 1.8873 - learning_rate: 1.2207e-07\nEpoch 69/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0154\nEpoch 69: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.5918 - val_loss: 1.9055 - learning_rate: 1.2207e-07\nEpoch 70/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.5918 - val_loss: 1.9235 - learning_rate: 6.1035e-08\nEpoch 71/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9951 - loss: 0.0146\nEpoch 71: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.5918 - val_loss: 1.9424 - learning_rate: 6.1035e-08\nEpoch 72/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5918 - val_loss: 1.9609 - learning_rate: 3.0518e-08\nEpoch 73/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9991 - loss: 0.0089\nEpoch 73: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9989 - loss: 0.0094 - val_accuracy: 0.5918 - val_loss: 1.9759 - learning_rate: 3.0518e-08\nEpoch 74/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.5918 - val_loss: 1.9933 - learning_rate: 1.5259e-08\nEpoch 75/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9996 - loss: 0.0179\nEpoch 75: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9994 - loss: 0.0188 - val_accuracy: 0.5918 - val_loss: 2.0100 - learning_rate: 1.5259e-08\nEpoch 76/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.5850 - val_loss: 2.0232 - learning_rate: 7.6294e-09\nEpoch 77/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9968 - loss: 0.0167\nEpoch 77: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9971 - loss: 0.0164 - val_accuracy: 0.5782 - val_loss: 2.0390 - learning_rate: 7.6294e-09\nEpoch 78/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.5918 - val_loss: 2.0512 - learning_rate: 3.8147e-09\nEpoch 79/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9979 - loss: 0.0144\nEpoch 79: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9976 - loss: 0.0148 - val_accuracy: 0.5850 - val_loss: 2.0634 - learning_rate: 3.8147e-09\nEpoch 80/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.5850 - val_loss: 2.0738 - learning_rate: 1.9073e-09\nEpoch 81/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0114\nEpoch 81: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9997 - loss: 0.0123 - val_accuracy: 0.5850 - val_loss: 2.0898 - learning_rate: 1.9073e-09\nEpoch 82/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9972 - loss: 0.0226 - val_accuracy: 0.5850 - val_loss: 2.0999 - learning_rate: 9.5367e-10\nEpoch 83/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9976 - loss: 0.0106\nEpoch 83: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9974 - loss: 0.0110 - val_accuracy: 0.5850 - val_loss: 2.1100 - learning_rate: 9.5367e-10\nEpoch 84/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5850 - val_loss: 2.1210 - learning_rate: 4.7684e-10\nEpoch 85/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9960 - loss: 0.0139\nEpoch 85: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9955 - loss: 0.0149 - val_accuracy: 0.5850 - val_loss: 2.1320 - learning_rate: 4.7684e-10\nEpoch 86/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9986 - loss: 0.0128 - val_accuracy: 0.5850 - val_loss: 2.1382 - learning_rate: 2.3842e-10\nEpoch 87/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0122\nEpoch 87: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.5918 - val_loss: 2.1442 - learning_rate: 2.3842e-10\nEpoch 88/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.5918 - val_loss: 2.1473 - learning_rate: 1.1921e-10\nEpoch 89/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0108\nEpoch 89: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.5850 - val_loss: 2.1574 - learning_rate: 1.1921e-10\nEpoch 90/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.5918 - val_loss: 2.1633 - learning_rate: 5.9605e-11\nEpoch 91/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9989 - loss: 0.0087\nEpoch 91: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9985 - loss: 0.0093 - val_accuracy: 0.5850 - val_loss: 2.1685 - learning_rate: 5.9605e-11\nEpoch 92/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9995 - loss: 0.0140 - val_accuracy: 0.5850 - val_loss: 2.1764 - learning_rate: 2.9802e-11\nEpoch 93/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9983 - loss: 0.0186\nEpoch 93: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9977 - loss: 0.0196 - val_accuracy: 0.5850 - val_loss: 2.1788 - learning_rate: 2.9802e-11\nEpoch 94/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9992 - loss: 0.0122 - val_accuracy: 0.5850 - val_loss: 2.1828 - learning_rate: 1.4901e-11\nEpoch 95/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9993 - loss: 0.0097\nEpoch 95: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9992 - loss: 0.0105 - val_accuracy: 0.5850 - val_loss: 2.1860 - learning_rate: 1.4901e-11\nEpoch 96/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9983 - loss: 0.0110 - val_accuracy: 0.5850 - val_loss: 2.1879 - learning_rate: 7.4506e-12\nEpoch 97/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0159\nEpoch 97: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.5850 - val_loss: 2.1924 - learning_rate: 7.4506e-12\nEpoch 98/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.5850 - val_loss: 2.1958 - learning_rate: 3.7253e-12\nEpoch 99/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9955 - loss: 0.0173\nEpoch 99: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9954 - loss: 0.0177 - val_accuracy: 0.5850 - val_loss: 2.1951 - learning_rate: 3.7253e-12\nEpoch 100/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9983 - loss: 0.0181 - val_accuracy: 0.5850 - val_loss: 2.1984 - learning_rate: 1.8626e-12\nEpoch 101/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9991 - loss: 0.0143\nEpoch 101: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9989 - loss: 0.0143 - val_accuracy: 0.5850 - val_loss: 2.2009 - learning_rate: 1.8626e-12\nEpoch 102/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9957 - loss: 0.0203 - val_accuracy: 0.5850 - val_loss: 2.1993 - learning_rate: 9.3132e-13\nEpoch 103/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0104\nEpoch 103: ReduceLROnPlateau reducing learning rate to 4.656613094254636e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9978 - loss: 0.0105 - val_accuracy: 0.5850 - val_loss: 2.2007 - learning_rate: 9.3132e-13\nEpoch 104/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9957 - loss: 0.0216 - val_accuracy: 0.5850 - val_loss: 2.2021 - learning_rate: 4.6566e-13\nEpoch 105/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0093\nEpoch 105: ReduceLROnPlateau reducing learning rate to 2.328306547127318e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.5850 - val_loss: 2.2038 - learning_rate: 4.6566e-13\nEpoch 106/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9989 - loss: 0.0165 - val_accuracy: 0.5850 - val_loss: 2.2053 - learning_rate: 2.3283e-13\nEpoch 107/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9983 - loss: 0.0131\nEpoch 107: ReduceLROnPlateau reducing learning rate to 1.164153273563659e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9983 - loss: 0.0135 - val_accuracy: 0.5850 - val_loss: 2.2098 - learning_rate: 2.3283e-13\nEpoch 108/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9962 - loss: 0.0231 - val_accuracy: 0.5850 - val_loss: 2.2134 - learning_rate: 1.1642e-13\nEpoch 109/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9983 - loss: 0.0219\nEpoch 109: ReduceLROnPlateau reducing learning rate to 5.820766367818295e-14.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9983 - loss: 0.0214 - val_accuracy: 0.5850 - val_loss: 2.2113 - learning_rate: 1.1642e-13\nEpoch 110/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.5850 - val_loss: 2.2073 - learning_rate: 5.8208e-14\nEpoch 111/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9993 - loss: 0.0099\nEpoch 111: ReduceLROnPlateau reducing learning rate to 2.9103831839091474e-14.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9992 - loss: 0.0102 - val_accuracy: 0.5850 - val_loss: 2.2075 - learning_rate: 5.8208e-14\nEpoch 112/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9978 - loss: 0.0132 - val_accuracy: 0.5850 - val_loss: 2.2104 - learning_rate: 2.9104e-14\nEpoch 113/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9993 - loss: 0.0172\nEpoch 113: ReduceLROnPlateau reducing learning rate to 1.4551915919545737e-14.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9992 - loss: 0.0168 - val_accuracy: 0.5850 - val_loss: 2.2096 - learning_rate: 2.9104e-14\nEpoch 114/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5850 - val_loss: 2.2098 - learning_rate: 1.4552e-14\nEpoch 115/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9977 - loss: 0.0163\nEpoch 115: ReduceLROnPlateau reducing learning rate to 7.275957959772868e-15.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9978 - loss: 0.0163 - val_accuracy: 0.5850 - val_loss: 2.2139 - learning_rate: 1.4552e-14\nEpoch 116/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9963 - loss: 0.0140 - val_accuracy: 0.5850 - val_loss: 2.2128 - learning_rate: 7.2760e-15\nEpoch 117/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9987 - loss: 0.0114\nEpoch 117: ReduceLROnPlateau reducing learning rate to 3.637978979886434e-15.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9986 - loss: 0.0121 - val_accuracy: 0.5850 - val_loss: 2.2122 - learning_rate: 7.2760e-15\nEpoch 118/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9995 - loss: 0.0147 - val_accuracy: 0.5850 - val_loss: 2.2148 - learning_rate: 3.6380e-15\nEpoch 119/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0153\nEpoch 119: ReduceLROnPlateau reducing learning rate to 1.818989489943217e-15.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0149 - val_accuracy: 0.5850 - val_loss: 2.2169 - learning_rate: 3.6380e-15\nEpoch 120/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.5850 - val_loss: 2.2175 - learning_rate: 1.8190e-15\nEpoch 121/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0125\nEpoch 121: ReduceLROnPlateau reducing learning rate to 9.094947449716085e-16.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9997 - loss: 0.0128 - val_accuracy: 0.5850 - val_loss: 2.2158 - learning_rate: 1.8190e-15\nEpoch 122/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9983 - loss: 0.0113 - val_accuracy: 0.5850 - val_loss: 2.2142 - learning_rate: 9.0949e-16\nEpoch 123/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0090\nEpoch 123: ReduceLROnPlateau reducing learning rate to 4.547473724858043e-16.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.5850 - val_loss: 2.2150 - learning_rate: 9.0949e-16\nEpoch 124/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9959 - loss: 0.0209 - val_accuracy: 0.5850 - val_loss: 2.2184 - learning_rate: 4.5475e-16\nEpoch 125/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9951 - loss: 0.0358\nEpoch 125: ReduceLROnPlateau reducing learning rate to 2.2737368624290214e-16.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9957 - loss: 0.0332 - val_accuracy: 0.5850 - val_loss: 2.2181 - learning_rate: 4.5475e-16\nEpoch 126/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9957 - loss: 0.0273 - val_accuracy: 0.5850 - val_loss: 2.2179 - learning_rate: 2.2737e-16\nEpoch 127/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9996 - loss: 0.0097\nEpoch 127: ReduceLROnPlateau reducing learning rate to 1.1368684312145107e-16.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9994 - loss: 0.0106 - val_accuracy: 0.5850 - val_loss: 2.2167 - learning_rate: 2.2737e-16\nEpoch 128/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.5918 - val_loss: 2.2181 - learning_rate: 1.1369e-16\nEpoch 129/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9951 - loss: 0.0274\nEpoch 129: ReduceLROnPlateau reducing learning rate to 5.684342156072553e-17.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9957 - loss: 0.0255 - val_accuracy: 0.5918 - val_loss: 2.2168 - learning_rate: 1.1369e-16\nEpoch 130/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9891 - loss: 0.0200 - val_accuracy: 0.5850 - val_loss: 2.2212 - learning_rate: 5.6843e-17\nEpoch 131/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9968 - loss: 0.0133\nEpoch 131: ReduceLROnPlateau reducing learning rate to 2.842171078036277e-17.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9971 - loss: 0.0132 - val_accuracy: 0.5918 - val_loss: 2.2205 - learning_rate: 5.6843e-17\nEpoch 132/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.5850 - val_loss: 2.2207 - learning_rate: 2.8422e-17\nEpoch 133/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9993 - loss: 0.0171\nEpoch 133: ReduceLROnPlateau reducing learning rate to 1.4210855390181384e-17.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9992 - loss: 0.0173 - val_accuracy: 0.5918 - val_loss: 2.2202 - learning_rate: 2.8422e-17\nEpoch 134/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.5918 - val_loss: 2.2184 - learning_rate: 1.4211e-17\nEpoch 135/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9993 - loss: 0.0088\nEpoch 135: ReduceLROnPlateau reducing learning rate to 7.105427695090692e-18.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9992 - loss: 0.0100 - val_accuracy: 0.5918 - val_loss: 2.2211 - learning_rate: 1.4211e-17\nEpoch 136/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9982 - loss: 0.0124 - val_accuracy: 0.5850 - val_loss: 2.2227 - learning_rate: 7.1054e-18\nEpoch 137/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0167\nEpoch 137: ReduceLROnPlateau reducing learning rate to 3.552713847545346e-18.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.5850 - val_loss: 2.2224 - learning_rate: 7.1054e-18\nEpoch 138/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9995 - loss: 0.0143 - val_accuracy: 0.5850 - val_loss: 2.2216 - learning_rate: 3.5527e-18\nEpoch 139/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9996 - loss: 0.0110\nEpoch 139: ReduceLROnPlateau reducing learning rate to 1.776356923772673e-18.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9994 - loss: 0.0111 - val_accuracy: 0.5850 - val_loss: 2.2218 - learning_rate: 3.5527e-18\nEpoch 140/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9971 - loss: 0.0126 - val_accuracy: 0.5850 - val_loss: 2.2202 - learning_rate: 1.7764e-18\nEpoch 141/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0108\nEpoch 141: ReduceLROnPlateau reducing learning rate to 8.881784618863365e-19.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.5850 - val_loss: 2.2199 - learning_rate: 1.7764e-18\nEpoch 142/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9997 - loss: 0.0148 - val_accuracy: 0.5850 - val_loss: 2.2193 - learning_rate: 8.8818e-19\nEpoch 143/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9991 - loss: 0.0100\nEpoch 143: ReduceLROnPlateau reducing learning rate to 4.440892309431682e-19.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9986 - loss: 0.0110 - val_accuracy: 0.5850 - val_loss: 2.2229 - learning_rate: 8.8818e-19\nEpoch 144/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9971 - loss: 0.0132 - val_accuracy: 0.5850 - val_loss: 2.2256 - learning_rate: 4.4409e-19\nEpoch 145/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9990 - loss: 0.0100\nEpoch 145: ReduceLROnPlateau reducing learning rate to 2.220446154715841e-19.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9989 - loss: 0.0102 - val_accuracy: 0.5850 - val_loss: 2.2210 - learning_rate: 4.4409e-19\nEpoch 146/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9997 - loss: 0.0135 - val_accuracy: 0.5850 - val_loss: 2.2239 - learning_rate: 2.2204e-19\nEpoch 147/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0069\nEpoch 147: ReduceLROnPlateau reducing learning rate to 1.1102230773579206e-19.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.5850 - val_loss: 2.2232 - learning_rate: 2.2204e-19\nEpoch 148/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.5850 - val_loss: 2.2222 - learning_rate: 1.1102e-19\nEpoch 149/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0120\nEpoch 149: ReduceLROnPlateau reducing learning rate to 5.551115386789603e-20.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5850 - val_loss: 2.2203 - learning_rate: 1.1102e-19\nEpoch 150/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9983 - loss: 0.0161 - val_accuracy: 0.5850 - val_loss: 2.2199 - learning_rate: 5.5511e-20\nEpoch 151/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0101\nEpoch 151: ReduceLROnPlateau reducing learning rate to 2.7755576933948015e-20.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.5850 - val_loss: 2.2202 - learning_rate: 5.5511e-20\nEpoch 152/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.5850 - val_loss: 2.2211 - learning_rate: 2.7756e-20\nEpoch 153/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9991 - loss: 0.0155\nEpoch 153: ReduceLROnPlateau reducing learning rate to 1.3877788466974007e-20.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9989 - loss: 0.0157 - val_accuracy: 0.5850 - val_loss: 2.2226 - learning_rate: 2.7756e-20\nEpoch 154/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9997 - loss: 0.0103 - val_accuracy: 0.5850 - val_loss: 2.2239 - learning_rate: 1.3878e-20\nEpoch 155/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0102\nEpoch 155: ReduceLROnPlateau reducing learning rate to 6.938894233487004e-21.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.5850 - val_loss: 2.2225 - learning_rate: 1.3878e-20\nEpoch 156/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9945 - loss: 0.0219 - val_accuracy: 0.5850 - val_loss: 2.2213 - learning_rate: 6.9389e-21\nEpoch 157/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9954 - loss: 0.0227\nEpoch 157: ReduceLROnPlateau reducing learning rate to 3.469447116743502e-21.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9957 - loss: 0.0221 - val_accuracy: 0.5850 - val_loss: 2.2215 - learning_rate: 6.9389e-21\nEpoch 158/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.5850 - val_loss: 2.2259 - learning_rate: 3.4694e-21\nEpoch 159/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0138\nEpoch 159: ReduceLROnPlateau reducing learning rate to 1.734723558371751e-21.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9997 - loss: 0.0142 - val_accuracy: 0.5850 - val_loss: 2.2275 - learning_rate: 3.4694e-21\nEpoch 160/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9983 - loss: 0.0120 - val_accuracy: 0.5850 - val_loss: 2.2250 - learning_rate: 1.7347e-21\nEpoch 161/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9966 - loss: 0.0225\nEpoch 161: ReduceLROnPlateau reducing learning rate to 8.673617791858755e-22.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9965 - loss: 0.0225 - val_accuracy: 0.5850 - val_loss: 2.2227 - learning_rate: 1.7347e-21\nEpoch 162/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5850 - val_loss: 2.2254 - learning_rate: 8.6736e-22\nEpoch 163/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9993 - loss: 0.0078\nEpoch 163: ReduceLROnPlateau reducing learning rate to 4.336808895929377e-22.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9992 - loss: 0.0081 - val_accuracy: 0.5850 - val_loss: 2.2247 - learning_rate: 8.6736e-22\nEpoch 164/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9978 - loss: 0.0127 - val_accuracy: 0.5850 - val_loss: 2.2241 - learning_rate: 4.3368e-22\nEpoch 165/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9984 - loss: 0.0152\nEpoch 165: ReduceLROnPlateau reducing learning rate to 2.1684044479646887e-22.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9981 - loss: 0.0155 - val_accuracy: 0.5850 - val_loss: 2.2247 - learning_rate: 4.3368e-22\nEpoch 166/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.5850 - val_loss: 2.2227 - learning_rate: 2.1684e-22\nEpoch 167/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0113\nEpoch 167: ReduceLROnPlateau reducing learning rate to 1.0842022239823443e-22.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.5850 - val_loss: 2.2216 - learning_rate: 2.1684e-22\nEpoch 168/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.5850 - val_loss: 2.2232 - learning_rate: 1.0842e-22\nEpoch 169/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9993 - loss: 0.0109\nEpoch 169: ReduceLROnPlateau reducing learning rate to 5.421011119911722e-23.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9992 - loss: 0.0112 - val_accuracy: 0.5850 - val_loss: 2.2221 - learning_rate: 1.0842e-22\nEpoch 170/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9992 - loss: 0.0162 - val_accuracy: 0.5850 - val_loss: 2.2192 - learning_rate: 5.4210e-23\nEpoch 171/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0089\nEpoch 171: ReduceLROnPlateau reducing learning rate to 2.710505559955861e-23.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.5850 - val_loss: 2.2197 - learning_rate: 5.4210e-23\nEpoch 172/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9968 - loss: 0.0194 - val_accuracy: 0.5850 - val_loss: 2.2212 - learning_rate: 2.7105e-23\nEpoch 173/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0110\nEpoch 173: ReduceLROnPlateau reducing learning rate to 1.3552527799779304e-23.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0134 - val_accuracy: 0.5850 - val_loss: 2.2269 - learning_rate: 2.7105e-23\nEpoch 174/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9989 - loss: 0.0095 - val_accuracy: 0.5850 - val_loss: 2.2237 - learning_rate: 1.3553e-23\nEpoch 175/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9993 - loss: 0.0161\nEpoch 175: ReduceLROnPlateau reducing learning rate to 6.776263899889652e-24.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9992 - loss: 0.0161 - val_accuracy: 0.5850 - val_loss: 2.2257 - learning_rate: 1.3553e-23\nEpoch 176/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.5850 - val_loss: 2.2269 - learning_rate: 6.7763e-24\nEpoch 177/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9968 - loss: 0.0152\nEpoch 177: ReduceLROnPlateau reducing learning rate to 3.388131949944826e-24.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9971 - loss: 0.0150 - val_accuracy: 0.5850 - val_loss: 2.2254 - learning_rate: 6.7763e-24\nEpoch 178/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9945 - loss: 0.0222 - val_accuracy: 0.5850 - val_loss: 2.2282 - learning_rate: 3.3881e-24\nEpoch 179/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9938 - loss: 0.0190\nEpoch 179: ReduceLROnPlateau reducing learning rate to 1.694065974972413e-24.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9943 - loss: 0.0189 - val_accuracy: 0.5850 - val_loss: 2.2246 - learning_rate: 3.3881e-24\nEpoch 180/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0095 - val_accuracy: 0.5850 - val_loss: 2.2216 - learning_rate: 1.6941e-24\nEpoch 181/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9986 - loss: 0.0123\nEpoch 181: ReduceLROnPlateau reducing learning rate to 8.470329874862065e-25.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9984 - loss: 0.0129 - val_accuracy: 0.5850 - val_loss: 2.2224 - learning_rate: 1.6941e-24\nEpoch 182/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.5850 - val_loss: 2.2271 - learning_rate: 8.4703e-25\nEpoch 183/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0101\nEpoch 183: ReduceLROnPlateau reducing learning rate to 4.2351649374310325e-25.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.5850 - val_loss: 2.2280 - learning_rate: 8.4703e-25\nEpoch 184/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.5850 - val_loss: 2.2295 - learning_rate: 4.2352e-25\nEpoch 185/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0120\nEpoch 185: ReduceLROnPlateau reducing learning rate to 2.1175824687155163e-25.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.5850 - val_loss: 2.2283 - learning_rate: 4.2352e-25\nEpoch 186/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.5850 - val_loss: 2.2286 - learning_rate: 2.1176e-25\nEpoch 187/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0118\nEpoch 187: ReduceLROnPlateau reducing learning rate to 1.0587912343577581e-25.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0146 - val_accuracy: 0.5850 - val_loss: 2.2267 - learning_rate: 2.1176e-25\nEpoch 188/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.5850 - val_loss: 2.2299 - learning_rate: 1.0588e-25\nEpoch 189/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9951 - loss: 0.0311\nEpoch 189: ReduceLROnPlateau reducing learning rate to 5.293956171788791e-26.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9954 - loss: 0.0288 - val_accuracy: 0.5850 - val_loss: 2.2259 - learning_rate: 1.0588e-25\nEpoch 190/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.5850 - val_loss: 2.2217 - learning_rate: 5.2940e-26\nEpoch 191/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0121\nEpoch 191: ReduceLROnPlateau reducing learning rate to 2.6469780858943953e-26.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.5850 - val_loss: 2.2218 - learning_rate: 5.2940e-26\nEpoch 192/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9988 - loss: 0.0122 - val_accuracy: 0.5850 - val_loss: 2.2208 - learning_rate: 2.6470e-26\nEpoch 193/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0137\nEpoch 193: ReduceLROnPlateau reducing learning rate to 1.3234890429471977e-26.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.5850 - val_loss: 2.2217 - learning_rate: 2.6470e-26\nEpoch 194/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9965 - loss: 0.0158 - val_accuracy: 0.5850 - val_loss: 2.2176 - learning_rate: 1.3235e-26\nEpoch 195/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9987 - loss: 0.0165\nEpoch 195: ReduceLROnPlateau reducing learning rate to 6.617445214735988e-27.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9986 - loss: 0.0166 - val_accuracy: 0.5850 - val_loss: 2.2183 - learning_rate: 1.3235e-26\nEpoch 196/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9978 - loss: 0.0142 - val_accuracy: 0.5850 - val_loss: 2.2206 - learning_rate: 6.6174e-27\nEpoch 197/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9930 - loss: 0.0234\nEpoch 197: ReduceLROnPlateau reducing learning rate to 3.308722607367994e-27.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9932 - loss: 0.0231 - val_accuracy: 0.5850 - val_loss: 2.2206 - learning_rate: 6.6174e-27\nEpoch 198/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9957 - loss: 0.0159 - val_accuracy: 0.5850 - val_loss: 2.2244 - learning_rate: 3.3087e-27\nEpoch 199/200\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9944 - loss: 0.0232\nEpoch 199: ReduceLROnPlateau reducing learning rate to 1.654361303683997e-27.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9945 - loss: 0.0229 - val_accuracy: 0.5918 - val_loss: 2.2225 - learning_rate: 3.3087e-27\nEpoch 200/200\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9971 - loss: 0.0153 - val_accuracy: 0.5918 - val_loss: 2.2209 - learning_rate: 1.6544e-27\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"from tensorflow.keras.activations import swish\n\n# Define the model\nmlp_model_swish = Sequential()\n\n# Input layer\nmlp_model_swish.add(Dense(2048, input_shape=(X_train_tfidf.shape[1],), activation=swish))\nmlp_model_swish.add(BatchNormalization())\nmlp_model_swish.add(Dropout(0.4))\n\n# Hidden layers\nfor units in [1024, 512, 256]:\n    mlp_model_swish.add(Dense(units, activation=swish))\n    mlp_model_swish.add(BatchNormalization())\n    mlp_model_swish.add(Dropout(0.3))\n\n# Output layer\nmlp_model_swish.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmlp_model_swish.compile(optimizer=Adam(learning_rate=0.001),\n                        loss='sparse_categorical_crossentropy',\n                        metrics=['accuracy'])\n\n# Train the model\nhistory_swish = mlp_model_swish.fit(X_train_tfidf, y_train,\n                                    validation_data=(X_test_tfidf, y_test),\n                                    epochs=100,\n                                    batch_size=32,\n                                    callbacks=[lr_scheduler])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:50:34.131631Z","iopub.execute_input":"2025-03-11T15:50:34.132021Z","iopub.status.idle":"2025-03-11T15:52:23.828806Z","shell.execute_reply.started":"2025-03-11T15:50:34.131992Z","shell.execute_reply":"2025-03-11T15:52:23.827513Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.1590 - loss: 3.2852 - val_accuracy: 0.3129 - val_loss: 2.4286 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7707 - loss: 0.8610 - val_accuracy: 0.3129 - val_loss: 2.2876 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8927 - loss: 0.4158 - val_accuracy: 0.3129 - val_loss: 2.2052 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9435 - loss: 0.2211 - val_accuracy: 0.3129 - val_loss: 2.1957 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9614 - loss: 0.1224 - val_accuracy: 0.3129 - val_loss: 2.2774 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9801 - loss: 0.0946\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9794 - loss: 0.0961 - val_accuracy: 0.3129 - val_loss: 2.3276 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9774 - loss: 0.0881 - val_accuracy: 0.3129 - val_loss: 2.3574 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9911 - loss: 0.0449\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9911 - loss: 0.0452 - val_accuracy: 0.3129 - val_loss: 2.4050 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9847 - loss: 0.0444 - val_accuracy: 0.3129 - val_loss: 2.4521 - learning_rate: 2.5000e-04\nEpoch 10/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9959 - loss: 0.0317\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9957 - loss: 0.0321 - val_accuracy: 0.3129 - val_loss: 2.4775 - learning_rate: 2.5000e-04\nEpoch 11/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9927 - loss: 0.0362 - val_accuracy: 0.3129 - val_loss: 2.4906 - learning_rate: 1.2500e-04\nEpoch 12/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9943 - loss: 0.0349\nEpoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9941 - loss: 0.0350 - val_accuracy: 0.3129 - val_loss: 2.4912 - learning_rate: 1.2500e-04\nEpoch 13/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9920 - loss: 0.0420 - val_accuracy: 0.3129 - val_loss: 2.4609 - learning_rate: 6.2500e-05\nEpoch 14/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9951 - loss: 0.0361\nEpoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9951 - loss: 0.0365 - val_accuracy: 0.3129 - val_loss: 2.4344 - learning_rate: 6.2500e-05\nEpoch 15/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9958 - loss: 0.0245 - val_accuracy: 0.3129 - val_loss: 2.4084 - learning_rate: 3.1250e-05\nEpoch 16/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9945 - loss: 0.0343\nEpoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9943 - loss: 0.0345 - val_accuracy: 0.3129 - val_loss: 2.3659 - learning_rate: 3.1250e-05\nEpoch 17/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9947 - loss: 0.0445 - val_accuracy: 0.3129 - val_loss: 2.3303 - learning_rate: 1.5625e-05\nEpoch 18/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9931 - loss: 0.0285\nEpoch 18: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9931 - loss: 0.0292 - val_accuracy: 0.3129 - val_loss: 2.3062 - learning_rate: 1.5625e-05\nEpoch 19/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9974 - loss: 0.0237 - val_accuracy: 0.3129 - val_loss: 2.2642 - learning_rate: 7.8125e-06\nEpoch 20/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9998 - loss: 0.0144\nEpoch 20: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9997 - loss: 0.0148 - val_accuracy: 0.3197 - val_loss: 2.2052 - learning_rate: 7.8125e-06\nEpoch 21/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9866 - loss: 0.0391 - val_accuracy: 0.3605 - val_loss: 2.1598 - learning_rate: 3.9063e-06\nEpoch 22/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9890 - loss: 0.0269 - val_accuracy: 0.3741 - val_loss: 2.1107 - learning_rate: 3.9063e-06\nEpoch 23/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9994 - loss: 0.0253 - val_accuracy: 0.4150 - val_loss: 2.0522 - learning_rate: 3.9063e-06\nEpoch 24/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9974 - loss: 0.0246 - val_accuracy: 0.4150 - val_loss: 1.9940 - learning_rate: 3.9063e-06\nEpoch 25/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9974 - loss: 0.0185 - val_accuracy: 0.4286 - val_loss: 1.9439 - learning_rate: 3.9063e-06\nEpoch 26/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9937 - loss: 0.0325 - val_accuracy: 0.4490 - val_loss: 1.9060 - learning_rate: 3.9063e-06\nEpoch 27/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9957 - loss: 0.0253 - val_accuracy: 0.4558 - val_loss: 1.8652 - learning_rate: 3.9063e-06\nEpoch 28/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9947 - loss: 0.0282 - val_accuracy: 0.4694 - val_loss: 1.8354 - learning_rate: 3.9063e-06\nEpoch 29/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9819 - loss: 0.0541 - val_accuracy: 0.4830 - val_loss: 1.8095 - learning_rate: 3.9063e-06\nEpoch 30/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9980 - loss: 0.0241 - val_accuracy: 0.5102 - val_loss: 1.8019 - learning_rate: 3.9063e-06\nEpoch 31/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9881 - loss: 0.0569 - val_accuracy: 0.5238 - val_loss: 1.7943 - learning_rate: 3.9063e-06\nEpoch 32/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9984 - loss: 0.0293 - val_accuracy: 0.5578 - val_loss: 1.8012 - learning_rate: 3.9063e-06\nEpoch 33/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9990 - loss: 0.0179\nEpoch 33: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9989 - loss: 0.0179 - val_accuracy: 0.5782 - val_loss: 1.8115 - learning_rate: 3.9063e-06\nEpoch 34/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.5782 - val_loss: 1.8243 - learning_rate: 1.9531e-06\nEpoch 35/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9968 - loss: 0.0213\nEpoch 35: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9966 - loss: 0.0218 - val_accuracy: 0.5850 - val_loss: 1.8442 - learning_rate: 1.9531e-06\nEpoch 36/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9959 - loss: 0.0236 - val_accuracy: 0.5918 - val_loss: 1.8684 - learning_rate: 9.7656e-07\nEpoch 37/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9942 - loss: 0.0277\nEpoch 37: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9944 - loss: 0.0276 - val_accuracy: 0.5782 - val_loss: 1.8984 - learning_rate: 9.7656e-07\nEpoch 38/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9916 - loss: 0.0263 - val_accuracy: 0.5782 - val_loss: 1.9325 - learning_rate: 4.8828e-07\nEpoch 39/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9958 - loss: 0.0289\nEpoch 39: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9959 - loss: 0.0286 - val_accuracy: 0.5714 - val_loss: 1.9576 - learning_rate: 4.8828e-07\nEpoch 40/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9964 - loss: 0.0274 - val_accuracy: 0.5782 - val_loss: 1.9868 - learning_rate: 2.4414e-07\nEpoch 41/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9938 - loss: 0.0327\nEpoch 41: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9939 - loss: 0.0325 - val_accuracy: 0.5714 - val_loss: 2.0150 - learning_rate: 2.4414e-07\nEpoch 42/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9932 - loss: 0.0310 - val_accuracy: 0.5646 - val_loss: 2.0356 - learning_rate: 1.2207e-07\nEpoch 43/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9987 - loss: 0.0273\nEpoch 43: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9986 - loss: 0.0276 - val_accuracy: 0.5578 - val_loss: 2.0604 - learning_rate: 1.2207e-07\nEpoch 44/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9909 - loss: 0.0397 - val_accuracy: 0.5646 - val_loss: 2.0797 - learning_rate: 6.1035e-08\nEpoch 45/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9879 - loss: 0.0439\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9881 - loss: 0.0434 - val_accuracy: 0.5646 - val_loss: 2.0964 - learning_rate: 6.1035e-08\nEpoch 46/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9893 - loss: 0.0341 - val_accuracy: 0.5646 - val_loss: 2.1086 - learning_rate: 3.0518e-08\nEpoch 47/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9995 - loss: 0.0236\nEpoch 47: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9993 - loss: 0.0236 - val_accuracy: 0.5646 - val_loss: 2.1222 - learning_rate: 3.0518e-08\nEpoch 48/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9938 - loss: 0.0337 - val_accuracy: 0.5578 - val_loss: 2.1387 - learning_rate: 1.5259e-08\nEpoch 49/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9954 - loss: 0.0295\nEpoch 49: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9954 - loss: 0.0293 - val_accuracy: 0.5578 - val_loss: 2.1477 - learning_rate: 1.5259e-08\nEpoch 50/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.5578 - val_loss: 2.1546 - learning_rate: 7.6294e-09\nEpoch 51/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9988 - loss: 0.0225\nEpoch 51: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9987 - loss: 0.0227 - val_accuracy: 0.5510 - val_loss: 2.1619 - learning_rate: 7.6294e-09\nEpoch 52/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9883 - loss: 0.0352 - val_accuracy: 0.5510 - val_loss: 2.1646 - learning_rate: 3.8147e-09\nEpoch 53/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9942 - loss: 0.0494\nEpoch 53: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9944 - loss: 0.0483 - val_accuracy: 0.5510 - val_loss: 2.1656 - learning_rate: 3.8147e-09\nEpoch 54/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9955 - loss: 0.0294 - val_accuracy: 0.5510 - val_loss: 2.1692 - learning_rate: 1.9073e-09\nEpoch 55/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9908 - loss: 0.0315\nEpoch 55: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9909 - loss: 0.0316 - val_accuracy: 0.5510 - val_loss: 2.1750 - learning_rate: 1.9073e-09\nEpoch 56/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9975 - loss: 0.0219 - val_accuracy: 0.5510 - val_loss: 2.1809 - learning_rate: 9.5367e-10\nEpoch 57/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9962 - loss: 0.0269\nEpoch 57: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9960 - loss: 0.0274 - val_accuracy: 0.5510 - val_loss: 2.1846 - learning_rate: 9.5367e-10\nEpoch 58/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9991 - loss: 0.0193 - val_accuracy: 0.5510 - val_loss: 2.1900 - learning_rate: 4.7684e-10\nEpoch 59/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9911 - loss: 0.0259\nEpoch 59: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9910 - loss: 0.0261 - val_accuracy: 0.5510 - val_loss: 2.1896 - learning_rate: 4.7684e-10\nEpoch 60/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9907 - loss: 0.0303 - val_accuracy: 0.5510 - val_loss: 2.1886 - learning_rate: 2.3842e-10\nEpoch 61/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9893 - loss: 0.0336\nEpoch 61: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9894 - loss: 0.0338 - val_accuracy: 0.5510 - val_loss: 2.1913 - learning_rate: 2.3842e-10\nEpoch 62/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9988 - loss: 0.0284 - val_accuracy: 0.5510 - val_loss: 2.1932 - learning_rate: 1.1921e-10\nEpoch 63/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9921 - loss: 0.0277\nEpoch 63: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9919 - loss: 0.0282 - val_accuracy: 0.5510 - val_loss: 2.1920 - learning_rate: 1.1921e-10\nEpoch 64/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9939 - loss: 0.0344 - val_accuracy: 0.5510 - val_loss: 2.1935 - learning_rate: 5.9605e-11\nEpoch 65/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9976 - loss: 0.0168\nEpoch 65: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9976 - loss: 0.0171 - val_accuracy: 0.5510 - val_loss: 2.1945 - learning_rate: 5.9605e-11\nEpoch 66/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9992 - loss: 0.0241 - val_accuracy: 0.5510 - val_loss: 2.1974 - learning_rate: 2.9802e-11\nEpoch 67/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9991 - loss: 0.0168\nEpoch 67: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9988 - loss: 0.0172 - val_accuracy: 0.5510 - val_loss: 2.1983 - learning_rate: 2.9802e-11\nEpoch 68/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9996 - loss: 0.0178 - val_accuracy: 0.5510 - val_loss: 2.1950 - learning_rate: 1.4901e-11\nEpoch 69/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9995 - loss: 0.0210\nEpoch 69: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9994 - loss: 0.0211 - val_accuracy: 0.5510 - val_loss: 2.1925 - learning_rate: 1.4901e-11\nEpoch 70/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9958 - loss: 0.0297 - val_accuracy: 0.5510 - val_loss: 2.1935 - learning_rate: 7.4506e-12\nEpoch 71/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9987 - loss: 0.0234\nEpoch 71: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9985 - loss: 0.0234 - val_accuracy: 0.5510 - val_loss: 2.1921 - learning_rate: 7.4506e-12\nEpoch 72/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9961 - loss: 0.0293 - val_accuracy: 0.5510 - val_loss: 2.1948 - learning_rate: 3.7253e-12\nEpoch 73/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9936 - loss: 0.0309\nEpoch 73: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9932 - loss: 0.0325 - val_accuracy: 0.5510 - val_loss: 2.1962 - learning_rate: 3.7253e-12\nEpoch 74/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9972 - loss: 0.0289 - val_accuracy: 0.5510 - val_loss: 2.1957 - learning_rate: 1.8626e-12\nEpoch 75/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9928 - loss: 0.0319\nEpoch 75: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9929 - loss: 0.0320 - val_accuracy: 0.5510 - val_loss: 2.1959 - learning_rate: 1.8626e-12\nEpoch 76/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9938 - loss: 0.0225 - val_accuracy: 0.5510 - val_loss: 2.1942 - learning_rate: 9.3132e-13\nEpoch 77/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9946 - loss: 0.0270\nEpoch 77: ReduceLROnPlateau reducing learning rate to 4.656613094254636e-13.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9938 - loss: 0.0291 - val_accuracy: 0.5510 - val_loss: 2.1920 - learning_rate: 9.3132e-13\nEpoch 78/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9944 - loss: 0.0243 - val_accuracy: 0.5510 - val_loss: 2.1877 - learning_rate: 4.6566e-13\nEpoch 79/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9950 - loss: 0.0313\nEpoch 79: ReduceLROnPlateau reducing learning rate to 2.328306547127318e-13.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9951 - loss: 0.0311 - val_accuracy: 0.5510 - val_loss: 2.1906 - learning_rate: 4.6566e-13\nEpoch 80/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9919 - loss: 0.0332 - val_accuracy: 0.5510 - val_loss: 2.1917 - learning_rate: 2.3283e-13\nEpoch 81/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9964 - loss: 0.0181\nEpoch 81: ReduceLROnPlateau reducing learning rate to 1.164153273563659e-13.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9962 - loss: 0.0188 - val_accuracy: 0.5510 - val_loss: 2.1946 - learning_rate: 2.3283e-13\nEpoch 82/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0257 - val_accuracy: 0.5510 - val_loss: 2.1908 - learning_rate: 1.1642e-13\nEpoch 83/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9993 - loss: 0.0221\nEpoch 83: ReduceLROnPlateau reducing learning rate to 5.820766367818295e-14.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9992 - loss: 0.0220 - val_accuracy: 0.5510 - val_loss: 2.1894 - learning_rate: 1.1642e-13\nEpoch 84/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9966 - loss: 0.0195 - val_accuracy: 0.5510 - val_loss: 2.1878 - learning_rate: 5.8208e-14\nEpoch 85/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9995 - loss: 0.0210\nEpoch 85: ReduceLROnPlateau reducing learning rate to 2.9103831839091474e-14.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9993 - loss: 0.0209 - val_accuracy: 0.5510 - val_loss: 2.1899 - learning_rate: 5.8208e-14\nEpoch 86/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9962 - loss: 0.0260 - val_accuracy: 0.5510 - val_loss: 2.1932 - learning_rate: 2.9104e-14\nEpoch 87/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9896 - loss: 0.0365\nEpoch 87: ReduceLROnPlateau reducing learning rate to 1.4551915919545737e-14.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9896 - loss: 0.0367 - val_accuracy: 0.5510 - val_loss: 2.1926 - learning_rate: 2.9104e-14\nEpoch 88/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9961 - loss: 0.0292 - val_accuracy: 0.5510 - val_loss: 2.1974 - learning_rate: 1.4552e-14\nEpoch 89/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9995 - loss: 0.0245\nEpoch 89: ReduceLROnPlateau reducing learning rate to 7.275957959772868e-15.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9993 - loss: 0.0245 - val_accuracy: 0.5510 - val_loss: 2.1976 - learning_rate: 1.4552e-14\nEpoch 90/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9890 - loss: 0.0381 - val_accuracy: 0.5510 - val_loss: 2.1988 - learning_rate: 7.2760e-15\nEpoch 91/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9947 - loss: 0.0215\nEpoch 91: ReduceLROnPlateau reducing learning rate to 3.637978979886434e-15.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9946 - loss: 0.0218 - val_accuracy: 0.5510 - val_loss: 2.2004 - learning_rate: 7.2760e-15\nEpoch 92/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9955 - loss: 0.0222 - val_accuracy: 0.5510 - val_loss: 2.2007 - learning_rate: 3.6380e-15\nEpoch 93/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9945 - loss: 0.0330\nEpoch 93: ReduceLROnPlateau reducing learning rate to 1.818989489943217e-15.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9945 - loss: 0.0328 - val_accuracy: 0.5510 - val_loss: 2.1968 - learning_rate: 3.6380e-15\nEpoch 94/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9940 - loss: 0.0235 - val_accuracy: 0.5510 - val_loss: 2.1944 - learning_rate: 1.8190e-15\nEpoch 95/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9964 - loss: 0.0288\nEpoch 95: ReduceLROnPlateau reducing learning rate to 9.094947449716085e-16.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9962 - loss: 0.0293 - val_accuracy: 0.5510 - val_loss: 2.1941 - learning_rate: 1.8190e-15\nEpoch 96/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9928 - loss: 0.0283 - val_accuracy: 0.5510 - val_loss: 2.1939 - learning_rate: 9.0949e-16\nEpoch 97/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9957 - loss: 0.0252\nEpoch 97: ReduceLROnPlateau reducing learning rate to 4.547473724858043e-16.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9958 - loss: 0.0252 - val_accuracy: 0.5510 - val_loss: 2.1947 - learning_rate: 9.0949e-16\nEpoch 98/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9959 - loss: 0.0212 - val_accuracy: 0.5510 - val_loss: 2.1955 - learning_rate: 4.5475e-16\nEpoch 99/100\n\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9931 - loss: 0.0203\nEpoch 99: ReduceLROnPlateau reducing learning rate to 2.2737368624290214e-16.\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9928 - loss: 0.0214 - val_accuracy: 0.5510 - val_loss: 2.1971 - learning_rate: 4.5475e-16\nEpoch 100/100\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9942 - loss: 0.0252 - val_accuracy: 0.5510 - val_loss: 2.1965 - learning_rate: 2.2737e-16\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"pip install tensorflow-addons\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:52:23.831899Z","iopub.execute_input":"2025-03-11T15:52:23.832261Z","iopub.status.idle":"2025-03-11T15:52:30.862092Z","shell.execute_reply.started":"2025-03-11T15:52:23.832230Z","shell.execute_reply":"2025-03-11T15:52:30.860885Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow-addons\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, tensorflow-addons\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.1\n    Uninstalling typeguard-4.4.1:\n      Successfully uninstalled typeguard-4.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ninflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\nydata-profiling 4.12.2 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow_addons.activations import gelu\n\n# Define the model\nmlp_model_gelu = Sequential()\n\n# Input layer\nmlp_model_gelu.add(Dense(2048, input_shape=(X_train_tfidf.shape[1],), activation=gelu))\nmlp_model_gelu.add(BatchNormalization())\nmlp_model_gelu.add(Dropout(0.4))\n\n# Hidden layers\nfor units in [1024, 512, 256]:\n    mlp_model_gelu.add(Dense(units, activation=gelu))\n    mlp_model_gelu.add(BatchNormalization())\n    mlp_model_gelu.add(Dropout(0.3))\n\n# Output layer\nmlp_model_gelu.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmlp_model_gelu.compile(optimizer=Adam(learning_rate=0.0001),\n                       loss='sparse_categorical_crossentropy',\n                       metrics=['accuracy'])\n\n# Train the model\nhistory_gelu = mlp_model_gelu.fit(X_train_tfidf, y_train,\n                                  validation_data=(X_test_tfidf, y_test),\n                                  epochs=100,\n                                  batch_size=64,\n                                  callbacks=[lr_scheduler])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:52:48.542292Z","iopub.execute_input":"2025-03-11T15:52:48.542714Z","iopub.status.idle":"2025-03-11T15:52:48.770911Z","shell.execute_reply.started":"2025-03-11T15:52:48.542678Z","shell.execute_reply":"2025-03-11T15:52:48.768996Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.17.1 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \nYou can find the compatibility matrix in TensorFlow Addon's readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-f74abe536d6f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional activation functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhardshrink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhardshrink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisht\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/activations/gelu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# New versions of Keras require importing from `keras.src` when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# importing internal symbols.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"],"ename":"ModuleNotFoundError","evalue":"No module named 'keras.src.engine'","output_type":"error"}],"execution_count":54},{"cell_type":"code","source":"from tensorflow.keras.layers import ELU\n\n# Define the model\nmlp_model_elu = Sequential()\n\n# Input layer\nmlp_model_elu.add(Dense(2048, input_shape=(X_train_tfidf.shape[1],)))\nmlp_model_elu.add(ELU(alpha=1.0))\nmlp_model_elu.add(BatchNormalization())\nmlp_model_elu.add(Dropout(0.4))\n\n# Hidden layers\nfor units in [1024, 512, 256]:\n    mlp_model_elu.add(Dense(units))\n    mlp_model_elu.add(ELU(alpha=1.0))\n    mlp_model_elu.add(BatchNormalization())\n    mlp_model_elu.add(Dropout(0.3))\n\n# Output layer\nmlp_model_elu.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmlp_model_elu.compile(optimizer=Adam(learning_rate=0.0001),\n                      loss='sparse_categorical_crossentropy',\n                      metrics=['accuracy'])\n\n# Train the model\nhistory_elu = mlp_model_elu.fit(X_train_tfidf, y_train,\n                                validation_data=(X_test_tfidf, y_test),\n                                epochs=100,\n                                batch_size=64,\n                                callbacks=[lr_scheduler])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:53:42.190727Z","iopub.execute_input":"2025-03-11T15:53:42.191115Z","iopub.status.idle":"2025-03-11T15:55:09.276005Z","shell.execute_reply.started":"2025-03-11T15:53:42.191084Z","shell.execute_reply":"2025-03-11T15:55:09.274901Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.0554 - loss: 3.5503 - val_accuracy: 0.2381 - val_loss: 2.5293 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1430 - loss: 3.0140 - val_accuracy: 0.2925 - val_loss: 2.4925 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2546 - loss: 2.5794 - val_accuracy: 0.3197 - val_loss: 2.4623 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.3435 - loss: 2.0895 - val_accuracy: 0.3469 - val_loss: 2.4324 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.3851 - loss: 2.0010 - val_accuracy: 0.3673 - val_loss: 2.3987 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5081 - loss: 1.5564 - val_accuracy: 0.3741 - val_loss: 2.3701 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6102 - loss: 1.2420 - val_accuracy: 0.3673 - val_loss: 2.3343 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6315 - loss: 1.1290 - val_accuracy: 0.3741 - val_loss: 2.2987 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7230 - loss: 0.8892 - val_accuracy: 0.3741 - val_loss: 2.2672 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7835 - loss: 0.7059 - val_accuracy: 0.3673 - val_loss: 2.2318 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7973 - loss: 0.7001 - val_accuracy: 0.3810 - val_loss: 2.2010 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8467 - loss: 0.5527 - val_accuracy: 0.3946 - val_loss: 2.1751 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8815 - loss: 0.4962 - val_accuracy: 0.4014 - val_loss: 2.1489 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8602 - loss: 0.4924 - val_accuracy: 0.4082 - val_loss: 2.1218 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8986 - loss: 0.4453 - val_accuracy: 0.4218 - val_loss: 2.0964 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8955 - loss: 0.3743 - val_accuracy: 0.4286 - val_loss: 2.0706 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9279 - loss: 0.3138 - val_accuracy: 0.4558 - val_loss: 2.0406 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9436 - loss: 0.2662 - val_accuracy: 0.4626 - val_loss: 2.0148 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9423 - loss: 0.2425 - val_accuracy: 0.4626 - val_loss: 1.9899 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9496 - loss: 0.2193 - val_accuracy: 0.4558 - val_loss: 1.9604 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9678 - loss: 0.1936 - val_accuracy: 0.4558 - val_loss: 1.9297 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9490 - loss: 0.2113 - val_accuracy: 0.4762 - val_loss: 1.9041 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9637 - loss: 0.1587 - val_accuracy: 0.4966 - val_loss: 1.8810 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9565 - loss: 0.1818 - val_accuracy: 0.5170 - val_loss: 1.8568 - learning_rate: 1.0000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9749 - loss: 0.1381 - val_accuracy: 0.5170 - val_loss: 1.8316 - learning_rate: 1.0000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9802 - loss: 0.1465 - val_accuracy: 0.5170 - val_loss: 1.8021 - learning_rate: 1.0000e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9812 - loss: 0.1185 - val_accuracy: 0.5306 - val_loss: 1.7765 - learning_rate: 1.0000e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9829 - loss: 0.1051 - val_accuracy: 0.5306 - val_loss: 1.7555 - learning_rate: 1.0000e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9811 - loss: 0.1034 - val_accuracy: 0.5374 - val_loss: 1.7394 - learning_rate: 1.0000e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9865 - loss: 0.0992 - val_accuracy: 0.5442 - val_loss: 1.7245 - learning_rate: 1.0000e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9740 - loss: 0.1127 - val_accuracy: 0.5578 - val_loss: 1.7082 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9764 - loss: 0.1064 - val_accuracy: 0.5510 - val_loss: 1.6939 - learning_rate: 1.0000e-04\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9855 - loss: 0.0900 - val_accuracy: 0.5510 - val_loss: 1.6757 - learning_rate: 1.0000e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9863 - loss: 0.0964 - val_accuracy: 0.5714 - val_loss: 1.6620 - learning_rate: 1.0000e-04\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9821 - loss: 0.0950 - val_accuracy: 0.5782 - val_loss: 1.6521 - learning_rate: 1.0000e-04\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9680 - loss: 0.1002 - val_accuracy: 0.5714 - val_loss: 1.6419 - learning_rate: 1.0000e-04\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9869 - loss: 0.0835 - val_accuracy: 0.5850 - val_loss: 1.6335 - learning_rate: 1.0000e-04\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9808 - loss: 0.0888 - val_accuracy: 0.5850 - val_loss: 1.6338 - learning_rate: 1.0000e-04\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9869 - loss: 0.0649 - val_accuracy: 0.5986 - val_loss: 1.6313 - learning_rate: 1.0000e-04\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9905 - loss: 0.0635 - val_accuracy: 0.6054 - val_loss: 1.6318 - learning_rate: 1.0000e-04\nEpoch 41/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9917 - loss: 0.0633\nEpoch 41: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9914 - loss: 0.0632 - val_accuracy: 0.5986 - val_loss: 1.6321 - learning_rate: 1.0000e-04\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9862 - loss: 0.0510 - val_accuracy: 0.5986 - val_loss: 1.6367 - learning_rate: 5.0000e-05\nEpoch 43/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9828 - loss: 0.0675\nEpoch 43: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9828 - loss: 0.0694 - val_accuracy: 0.5986 - val_loss: 1.6436 - learning_rate: 5.0000e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9894 - loss: 0.0651 - val_accuracy: 0.5850 - val_loss: 1.6522 - learning_rate: 2.5000e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9839 - loss: 0.0744\nEpoch 45: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9835 - loss: 0.0754 - val_accuracy: 0.5850 - val_loss: 1.6631 - learning_rate: 2.5000e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9884 - loss: 0.0678 - val_accuracy: 0.5782 - val_loss: 1.6754 - learning_rate: 1.2500e-05\nEpoch 47/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9863 - loss: 0.0742\nEpoch 47: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9866 - loss: 0.0732 - val_accuracy: 0.5714 - val_loss: 1.6900 - learning_rate: 1.2500e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9967 - loss: 0.0383 - val_accuracy: 0.5714 - val_loss: 1.7044 - learning_rate: 6.2500e-06\nEpoch 49/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9799 - loss: 0.0793\nEpoch 49: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9814 - loss: 0.0758 - val_accuracy: 0.5714 - val_loss: 1.7212 - learning_rate: 6.2500e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9864 - loss: 0.0497 - val_accuracy: 0.5646 - val_loss: 1.7370 - learning_rate: 3.1250e-06\nEpoch 51/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9961 - loss: 0.0541\nEpoch 51: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9953 - loss: 0.0544 - val_accuracy: 0.5578 - val_loss: 1.7555 - learning_rate: 3.1250e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9870 - loss: 0.0648 - val_accuracy: 0.5578 - val_loss: 1.7746 - learning_rate: 1.5625e-06\nEpoch 53/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9973 - loss: 0.0436\nEpoch 53: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9972 - loss: 0.0437 - val_accuracy: 0.5578 - val_loss: 1.7952 - learning_rate: 1.5625e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9975 - loss: 0.0523 - val_accuracy: 0.5578 - val_loss: 1.8166 - learning_rate: 7.8125e-07\nEpoch 55/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9951 - loss: 0.0589\nEpoch 55: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9947 - loss: 0.0591 - val_accuracy: 0.5646 - val_loss: 1.8385 - learning_rate: 7.8125e-07\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9980 - loss: 0.0396 - val_accuracy: 0.5646 - val_loss: 1.8613 - learning_rate: 3.9062e-07\nEpoch 57/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9936 - loss: 0.0575\nEpoch 57: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9938 - loss: 0.0562 - val_accuracy: 0.5646 - val_loss: 1.8832 - learning_rate: 3.9062e-07\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9935 - loss: 0.0469 - val_accuracy: 0.5646 - val_loss: 1.9076 - learning_rate: 1.9531e-07\nEpoch 59/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9927 - loss: 0.0585\nEpoch 59: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9927 - loss: 0.0580 - val_accuracy: 0.5646 - val_loss: 1.9314 - learning_rate: 1.9531e-07\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9879 - loss: 0.0517 - val_accuracy: 0.5646 - val_loss: 1.9556 - learning_rate: 9.7656e-08\nEpoch 61/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9861 - loss: 0.0657\nEpoch 61: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9867 - loss: 0.0644 - val_accuracy: 0.5646 - val_loss: 1.9776 - learning_rate: 9.7656e-08\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9939 - loss: 0.0417 - val_accuracy: 0.5714 - val_loss: 1.9979 - learning_rate: 4.8828e-08\nEpoch 63/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9906 - loss: 0.0538\nEpoch 63: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9904 - loss: 0.0537 - val_accuracy: 0.5714 - val_loss: 2.0202 - learning_rate: 4.8828e-08\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0428 - val_accuracy: 0.5646 - val_loss: 2.0422 - learning_rate: 2.4414e-08\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9971 - loss: 0.0596\nEpoch 65: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9969 - loss: 0.0597 - val_accuracy: 0.5646 - val_loss: 2.0623 - learning_rate: 2.4414e-08\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9926 - loss: 0.0485 - val_accuracy: 0.5646 - val_loss: 2.0841 - learning_rate: 1.2207e-08\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9940 - loss: 0.0463\nEpoch 67: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9940 - loss: 0.0461 - val_accuracy: 0.5646 - val_loss: 2.1063 - learning_rate: 1.2207e-08\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9925 - loss: 0.0412 - val_accuracy: 0.5646 - val_loss: 2.1245 - learning_rate: 6.1035e-09\nEpoch 69/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9919 - loss: 0.0509\nEpoch 69: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9909 - loss: 0.0519 - val_accuracy: 0.5646 - val_loss: 2.1438 - learning_rate: 6.1035e-09\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9924 - loss: 0.0477 - val_accuracy: 0.5646 - val_loss: 2.1590 - learning_rate: 3.0518e-09\nEpoch 71/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9945 - loss: 0.0447\nEpoch 71: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9946 - loss: 0.0454 - val_accuracy: 0.5646 - val_loss: 2.1759 - learning_rate: 3.0518e-09\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9905 - loss: 0.0659 - val_accuracy: 0.5646 - val_loss: 2.1953 - learning_rate: 1.5259e-09\nEpoch 73/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9900 - loss: 0.0445\nEpoch 73: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9900 - loss: 0.0464 - val_accuracy: 0.5646 - val_loss: 2.2060 - learning_rate: 1.5259e-09\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9948 - loss: 0.0521 - val_accuracy: 0.5646 - val_loss: 2.2178 - learning_rate: 7.6294e-10\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9960 - loss: 0.0453\nEpoch 75: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9961 - loss: 0.0455 - val_accuracy: 0.5646 - val_loss: 2.2328 - learning_rate: 7.6294e-10\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9854 - loss: 0.0577 - val_accuracy: 0.5646 - val_loss: 2.2427 - learning_rate: 3.8147e-10\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9906 - loss: 0.0443\nEpoch 77: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-10.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9904 - loss: 0.0448 - val_accuracy: 0.5646 - val_loss: 2.2544 - learning_rate: 3.8147e-10\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9980 - loss: 0.0432 - val_accuracy: 0.5578 - val_loss: 2.2651 - learning_rate: 1.9073e-10\nEpoch 79/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9919 - loss: 0.0447\nEpoch 79: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9906 - loss: 0.0467 - val_accuracy: 0.5578 - val_loss: 2.2744 - learning_rate: 1.9073e-10\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9858 - loss: 0.0542 - val_accuracy: 0.5646 - val_loss: 2.2843 - learning_rate: 9.5367e-11\nEpoch 81/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9985 - loss: 0.0533\nEpoch 81: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9979 - loss: 0.0529 - val_accuracy: 0.5646 - val_loss: 2.2928 - learning_rate: 9.5367e-11\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9832 - loss: 0.0611 - val_accuracy: 0.5714 - val_loss: 2.3051 - learning_rate: 4.7684e-11\nEpoch 83/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9871 - loss: 0.0640\nEpoch 83: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9866 - loss: 0.0649 - val_accuracy: 0.5646 - val_loss: 2.3135 - learning_rate: 4.7684e-11\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9927 - loss: 0.0537 - val_accuracy: 0.5646 - val_loss: 2.3168 - learning_rate: 2.3842e-11\nEpoch 85/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9870 - loss: 0.0621\nEpoch 85: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-11.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9881 - loss: 0.0619 - val_accuracy: 0.5646 - val_loss: 2.3257 - learning_rate: 2.3842e-11\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9895 - loss: 0.0533 - val_accuracy: 0.5714 - val_loss: 2.3304 - learning_rate: 1.1921e-11\nEpoch 87/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9843 - loss: 0.0710\nEpoch 87: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9850 - loss: 0.0706 - val_accuracy: 0.5646 - val_loss: 2.3316 - learning_rate: 1.1921e-11\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9901 - loss: 0.0584 - val_accuracy: 0.5646 - val_loss: 2.3344 - learning_rate: 5.9605e-12\nEpoch 89/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9955 - loss: 0.0573\nEpoch 89: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9948 - loss: 0.0575 - val_accuracy: 0.5646 - val_loss: 2.3373 - learning_rate: 5.9605e-12\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9965 - loss: 0.0569 - val_accuracy: 0.5578 - val_loss: 2.3394 - learning_rate: 2.9802e-12\nEpoch 91/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9949 - loss: 0.0448\nEpoch 91: ReduceLROnPlateau reducing learning rate to 1.4901160817412662e-12.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9946 - loss: 0.0455 - val_accuracy: 0.5578 - val_loss: 2.3422 - learning_rate: 2.9802e-12\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9965 - loss: 0.0382 - val_accuracy: 0.5578 - val_loss: 2.3455 - learning_rate: 1.4901e-12\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9870 - loss: 0.0604\nEpoch 93: ReduceLROnPlateau reducing learning rate to 7.450580408706331e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9868 - loss: 0.0610 - val_accuracy: 0.5578 - val_loss: 2.3497 - learning_rate: 1.4901e-12\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9989 - loss: 0.0410 - val_accuracy: 0.5578 - val_loss: 2.3517 - learning_rate: 7.4506e-13\nEpoch 95/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9889 - loss: 0.0495\nEpoch 95: ReduceLROnPlateau reducing learning rate to 3.7252902043531655e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9884 - loss: 0.0501 - val_accuracy: 0.5578 - val_loss: 2.3533 - learning_rate: 7.4506e-13\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9972 - loss: 0.0427 - val_accuracy: 0.5578 - val_loss: 2.3543 - learning_rate: 3.7253e-13\nEpoch 97/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9901 - loss: 0.0475\nEpoch 97: ReduceLROnPlateau reducing learning rate to 1.8626451021765827e-13.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9901 - loss: 0.0490 - val_accuracy: 0.5578 - val_loss: 2.3608 - learning_rate: 3.7253e-13\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9942 - loss: 0.0461 - val_accuracy: 0.5578 - val_loss: 2.3641 - learning_rate: 1.8626e-13\nEpoch 99/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9920 - loss: 0.0602\nEpoch 99: ReduceLROnPlateau reducing learning rate to 9.313225510882914e-14.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9916 - loss: 0.0604 - val_accuracy: 0.5578 - val_loss: 2.3654 - learning_rate: 1.8626e-13\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9974 - loss: 0.0434 - val_accuracy: 0.5578 - val_loss: 2.3686 - learning_rate: 9.3132e-14\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"results = {\n    'LeakyReLU': mlp_model_leakyrelu.evaluate(X_test_tfidf, y_test),\n    'Swish': mlp_model_swish.evaluate(X_test_tfidf, y_test),\n    # 'GELU': mlp_model_gelu.evaluate(X_test_tfidf, y_test),\n    'ELU': mlp_model_elu.evaluate(X_test_tfidf, y_test),\n}\n\nfor name, (loss, accuracy) in results.items():\n    print(f\"{name} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T15:55:27.663540Z","iopub.execute_input":"2025-03-11T15:55:27.663963Z","iopub.status.idle":"2025-03-11T15:55:28.381559Z","shell.execute_reply.started":"2025-03-11T15:55:27.663929Z","shell.execute_reply":"2025-03-11T15:55:28.380474Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6066 - loss: 2.0767 \n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5556 - loss: 2.0866\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5627 - loss: 2.1701 \nLeakyReLU - Loss: 2.2209, Accuracy: 0.5918\nSwish - Loss: 2.1965, Accuracy: 0.5510\nELU - Loss: 2.3686, Accuracy: 0.5578\n","output_type":"stream"}],"execution_count":58}]}