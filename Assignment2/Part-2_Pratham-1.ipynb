{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316566,"sourceType":"datasetVersion","datasetId":4245661}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Optional: Improves WordNet performance\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:08.730036Z","iopub.execute_input":"2025-03-13T19:44:08.730477Z","iopub.status.idle":"2025-03-13T19:44:08.753985Z","shell.execute_reply.started":"2025-03-13T19:44:08.730444Z","shell.execute_reply":"2025-03-13T19:44:08.752564Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\n","output_type":"stream"}],"execution_count":339},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:08.755410Z","iopub.execute_input":"2025-03-13T19:44:08.755789Z","iopub.status.idle":"2025-03-13T19:44:08.771643Z","shell.execute_reply.started":"2025-03-13T19:44:08.755744Z","shell.execute_reply":"2025-03-13T19:44:08.770667Z"}},"outputs":[],"execution_count":340},{"cell_type":"code","source":"import nltk\nimport subprocess\n\nnltk.download('wordnet', download_dir='/kaggle/working/')\nnltk.download('omw-1.4', download_dir='/kaggle/working/')\n\ncommand = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\nsubprocess.run(command.split())\n\nnltk.data.path.append('/kaggle/working/')\n\nlemmatizer = WordNetLemmatizer()\n\ntrain_df['Sentiment'] = train_df['Sentiment'].astype(str).str.strip().str.lower().apply(lemmatizer.lemmatize)\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:08.774200Z","iopub.execute_input":"2025-03-13T19:44:08.774639Z","iopub.status.idle":"2025-03-13T19:44:08.880583Z","shell.execute_reply.started":"2025-03-13T19:44:08.774605Z","shell.execute_reply":"2025-03-13T19:44:08.879334Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /kaggle/working/...\n[nltk_data]   Package omw-1.4 is already up-to-date!\nSentiment\npositive                45\njoy                     44\nexcitement              37\ncontentment             19\nneutral                 18\ngratitude               18\ncuriosity               16\nserenity                15\nhappy                   14\nnostalgia               11\ndespair                 11\ngrief                    9\nawe                      9\nsad                      9\nhopeful                  9\nloneliness               9\nembarrassed              8\nacceptance               8\nconfusion                8\neuphoria                 7\nelation                  7\nenthusiasm               7\npride                    7\ndetermination            7\nregret                   6\nfrustration              6\nambivalence              6\nmelancholy               6\nnumbness                 6\nplayful                  6\nindifference             6\nbad                      6\nhate                     6\nsurprise                 6\ninspiration              6\nbitterness               5\nfrustrated               5\nbetrayal                 5\nhope                     5\nhappiness                5\ndisgust                  5\ninspired                 5\nempowerment              5\nproud                    4\ngrateful                 4\nthrill                   4\noverwhelmed              4\ncompassionate            4\nreflection               4\nenchantment              4\ndesolation               4\nnegative                 4\nadmiration               4\nboredom                  4\ncalmness                 4\nreverence                4\nfulfillment              4\ncompassion               4\narousal                  4\ntenderness               4\namusement                3\nanticipation             3\nenvious                  3\ndismissive               3\nbitter                   3\nheartbreak               3\nadventure                3\ndevastated               3\nsatisfaction             3\nwonder                   3\naccomplishment           3\ncreativity               3\nharmony                  3\nkind                     3\njealous                  3\nlove                     3\nfearful                  3\nconfident                3\nfree-spirited            3\nresentment               3\nempathetic               3\nshame                    3\njealousy                 3\nsorrow                   2\nexploration              2\ncaptivation              2\ntranquility              2\nradiance                 2\nloss                     2\nmischievous              2\nrejuvenation             2\nresilience               2\nemotion                  2\ndisappointment           2\nisolation                2\ncoziness                 2\nwhimsy                   2\nintimidation             2\ncontemplation            2\nanxiety                  2\nhelplessness             2\nenvy                     2\nanger                    2\nzest                     2\nyearning                 2\napprehensive             2\nfear                     2\nsadness                  2\nenjoyment                2\nadoration                2\naffection                2\ndisappointed             2\nengagement               1\nobstacle                 1\nheartwarming             1\ntriumph                  1\nsuspense                 1\ntouched                  1\nrunway creativity        1\nsympathy                 1\niconic                   1\nconnection               1\nhypnotic                 1\ncolorful                 1\necstasy                  1\ncharm                    1\njourney                  1\npressure                 1\nocean's freedom          1\nrelief                   1\ncreative inspiration     1\ncelestial wonder         1\nnature's beauty          1\nthrilling journey        1\nwinter magic             1\nculinary adventure       1\nmesmerizing              1\nvibrancy                 1\nimagination              1\nenvisioning history      1\njoy in baking            1\nbreakthrough             1\nsolace                   1\ncelebration              1\nmiscalculation           1\nrenewed effort           1\nwhispers of the past     1\nchallenge                1\nmindfulness              1\nenergy                   1\nmelodic                  1\nmotivation               1\nculinaryodyssey          1\nartisticburst            1\nadrenaline               1\ndazzle                   1\nfreedom                  1\ninnerjourney             1\nfestivejoy               1\njoyfulreunion            1\ngrandeur                 1\nblessed                  1\nappreciation             1\nconfidence               1\nwonderment               1\noptimism                 1\npensive                  1\nplayfuljoy               1\nelegance                 1\nimmersion                1\nspark                    1\nmarvel                   1\noverjoyed                1\ndreamchaser              1\nromance                  1\namazement                1\nsuccess                  1\nfriendship               1\nkindness                 1\npositivity               1\nsolitude                 1\nheartache                1\nruin                     1\ndesperation              1\ndarkness                 1\nexhaustion               1\nlostlove                 1\nemotionalstorm           1\nsuffering                1\nbittersweet              1\nintrigue                 1\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":341},{"cell_type":"code","source":"unique_values = set()\nunique_values.update(train_df['Sentiment'])\nunique_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:08.881884Z","iopub.execute_input":"2025-03-13T19:44:08.882295Z","iopub.status.idle":"2025-03-13T19:44:08.890804Z","shell.execute_reply.started":"2025-03-13T19:44:08.882259Z","shell.execute_reply":"2025-03-13T19:44:08.889625Z"}},"outputs":[{"execution_count":342,"output_type":"execute_result","data":{"text/plain":"{'acceptance',\n 'accomplishment',\n 'admiration',\n 'adoration',\n 'adrenaline',\n 'adventure',\n 'affection',\n 'amazement',\n 'ambivalence',\n 'amusement',\n 'anger',\n 'anticipation',\n 'anxiety',\n 'appreciation',\n 'apprehensive',\n 'arousal',\n 'artisticburst',\n 'awe',\n 'bad',\n 'betrayal',\n 'bitter',\n 'bitterness',\n 'bittersweet',\n 'blessed',\n 'boredom',\n 'breakthrough',\n 'calmness',\n 'captivation',\n 'celebration',\n 'celestial wonder',\n 'challenge',\n 'charm',\n 'colorful',\n 'compassion',\n 'compassionate',\n 'confidence',\n 'confident',\n 'confusion',\n 'connection',\n 'contemplation',\n 'contentment',\n 'coziness',\n 'creative inspiration',\n 'creativity',\n 'culinary adventure',\n 'culinaryodyssey',\n 'curiosity',\n 'darkness',\n 'dazzle',\n 'desolation',\n 'despair',\n 'desperation',\n 'determination',\n 'devastated',\n 'disappointed',\n 'disappointment',\n 'disgust',\n 'dismissive',\n 'dreamchaser',\n 'ecstasy',\n 'elation',\n 'elegance',\n 'embarrassed',\n 'emotion',\n 'emotionalstorm',\n 'empathetic',\n 'empowerment',\n 'enchantment',\n 'energy',\n 'engagement',\n 'enjoyment',\n 'enthusiasm',\n 'envious',\n 'envisioning history',\n 'envy',\n 'euphoria',\n 'excitement',\n 'exhaustion',\n 'exploration',\n 'fear',\n 'fearful',\n 'festivejoy',\n 'free-spirited',\n 'freedom',\n 'friendship',\n 'frustrated',\n 'frustration',\n 'fulfillment',\n 'grandeur',\n 'grateful',\n 'gratitude',\n 'grief',\n 'happiness',\n 'happy',\n 'harmony',\n 'hate',\n 'heartache',\n 'heartbreak',\n 'heartwarming',\n 'helplessness',\n 'hope',\n 'hopeful',\n 'hypnotic',\n 'iconic',\n 'imagination',\n 'immersion',\n 'indifference',\n 'innerjourney',\n 'inspiration',\n 'inspired',\n 'intimidation',\n 'intrigue',\n 'isolation',\n 'jealous',\n 'jealousy',\n 'journey',\n 'joy',\n 'joy in baking',\n 'joyfulreunion',\n 'kind',\n 'kindness',\n 'loneliness',\n 'loss',\n 'lostlove',\n 'love',\n 'marvel',\n 'melancholy',\n 'melodic',\n 'mesmerizing',\n 'mindfulness',\n 'miscalculation',\n 'mischievous',\n 'motivation',\n \"nature's beauty\",\n 'negative',\n 'neutral',\n 'nostalgia',\n 'numbness',\n 'obstacle',\n \"ocean's freedom\",\n 'optimism',\n 'overjoyed',\n 'overwhelmed',\n 'pensive',\n 'playful',\n 'playfuljoy',\n 'positive',\n 'positivity',\n 'pressure',\n 'pride',\n 'proud',\n 'radiance',\n 'reflection',\n 'regret',\n 'rejuvenation',\n 'relief',\n 'renewed effort',\n 'resentment',\n 'resilience',\n 'reverence',\n 'romance',\n 'ruin',\n 'runway creativity',\n 'sad',\n 'sadness',\n 'satisfaction',\n 'serenity',\n 'shame',\n 'solace',\n 'solitude',\n 'sorrow',\n 'spark',\n 'success',\n 'suffering',\n 'surprise',\n 'suspense',\n 'sympathy',\n 'tenderness',\n 'thrill',\n 'thrilling journey',\n 'touched',\n 'tranquility',\n 'triumph',\n 'vibrancy',\n 'whimsy',\n 'whispers of the past',\n 'winter magic',\n 'wonder',\n 'wonderment',\n 'yearning',\n 'zest'}"},"metadata":{}}],"execution_count":342},{"cell_type":"code","source":"import spacy\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nnlp = spacy.load(\"en_core_web_md\")\n\nref_words = {\n    \"Positive\": \"positive\",\n    \"Negative\": \"negative\",\n    \"Neutral\": \"neutral\"\n}\n\nref_vectors = {category: nlp(word).vector for category, word in ref_words.items()}\n\ndef assign_sentiment_category(sentiment):\n    word_vector = nlp(sentiment).vector.reshape(1, -1)\n    \n    similarities = {}\n    for category, ref_vec in ref_vectors.items():\n        ref_vec = ref_vec.reshape(1, -1)\n        sim = cosine_similarity(word_vector, ref_vec)[0][0]\n        similarities[category] = sim\n\n    return max(similarities, key=similarities.get)\n\ntrain_df['Sentiment'] = train_df['Sentiment'].apply(assign_sentiment_category)\n\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:08.892076Z","iopub.execute_input":"2025-03-13T19:44:08.892492Z","iopub.status.idle":"2025-03-13T19:44:16.643007Z","shell.execute_reply.started":"2025-03-13T19:44:08.892451Z","shell.execute_reply":"2025-03-13T19:44:16.641734Z"}},"outputs":[{"name":"stdout","text":"Sentiment\nPositive    364\nNegative    290\nNeutral      78\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":343},{"cell_type":"code","source":"!pip install nltk  \n\nimport nltk\nnltk.download('stopwords')  \nfrom nltk.corpus import stopwords\nimport string\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom nltk.stem import PorterStemmer\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer()\n\nemoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"  \n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F700-\\U0001F77F\" \n                           u\"\\U0001F780-\\U0001F7FF\"  \n                           u\"\\U0001F800-\\U0001F8FF\" \n                           u\"\\U0001F900-\\U0001F9FF\" \n                           u\"\\U0001FA00-\\U0001FA6F\" \n                           u\"\\U0001FA70-\\U0001FAFF\" \n                           u\"\\U00002702-\\U000027B0\" \n                           u\"\\U000024C2-\\U0001F251\" \n                           \"]+\", flags=re.UNICODE)\n\ndef split_and_remove_stopwords(text):\n    text = emoji_pattern.sub(r'', text)\n    tokens = text.split()\n\n    filtered_tokens = [\n        stemmer.stem(lemmatizer.lemmatize(word.lower().rstrip(string.punctuation)))\n        for word in tokens if stemmer.stem(word.lower().rstrip(string.punctuation)) not in stop_words\n    ]\n\n    return filtered_tokens\n\ntrain_df['Text'] = train_df['Text'].apply(split_and_remove_stopwords)\n\nprint(train_df['Text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:16.644360Z","iopub.execute_input":"2025-03-13T19:44:16.644702Z","iopub.status.idle":"2025-03-13T19:44:21.630636Z","shell.execute_reply.started":"2025-03-13T19:44:16.644670Z","shell.execute_reply":"2025-03-13T19:44:21.629009Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n0                             [enjoy, beauti, day, park]\n1                      [traffic, wa, terribl, thi, morn]\n2                                [finish, amaz, workout]\n3                       [excit, upcom, weekend, getaway]\n4                     [tri, new, recip, dinner, tonight]\n5                      [feel, grate, littl, thing, life]\n6          [raini, day, call, cozi, blanket, hot, cocoa]\n7                        [new, movi, releas, must-watch]\n8                        [polit, discuss, heat, timelin]\n9                       [miss, summer, vibe, beach, day]\n10                     [publish, new, blog, post, check]\n11                           [feel, bit, weather, today]\n12                          [explor, city', hidden, gem]\n13                           [new, year, new, fit, goal]\n14                         [technolog, chang, way, live]\n15                          [reflect, past, look, ahead]\n16                          [adopt, cute, furri, friend]\n17                   [late-night, game, session, friend]\n18                         [attend, virtual, confer, ai]\n19                        [winter, blue, got, feel, low]\n20                       [sip, coffe, enjoy, good, book]\n21                     [explor, world, virtual, realiti]\n22                     [product, day, tick, to-do, list]\n23                   [finish, challeng, workout, routin]\n24                              [celebr, mileston, work]\n25                              [sunday, brunch, friend]\n26                 [learn, new, languag, person, growth]\n27                             [quiet, even, good, book]\n28                     [reflect, import, mental, health]\n29                                [new, paint, progress]\n30           [weekend, road, trip, explor, scenic, view]\n31                      [enjoy, cup, tea, watch, sunset]\n32                      [code, new, project, enthusiasm]\n33                      [feel, inspir, attend, workshop]\n34                     [winter, sport, day, local, park]\n35                 [qualiti, time, famili, thi, weekend]\n36               [attend, live, music, concert, tonight]\n37                                [practic, mind, medit]\n38                            [tri, new, dessert, recip]\n39                      [excit, upcom, game, tournament]\n40                        [plan, garden, makeov, spring]\n41                  [celebr, friend', birthday, tonight]\n42                      [feel, accomplish, product, day]\n43                              [cozi, even, good, movi]\n44           [explor, local, art, galleri, thi, weekend]\n45                  [new, book, releas, favorit, author]\n46                    [attend, virtual, realiti, meetup]\n47                              [reflect, beauti, natur]\n48                    [cook, special, dinner, love, one]\n49                         [feel, optimist, week, ahead]\n50                 [start, new, fit, challeng, tomorrow]\n51                   [sunday, bike, ride, scenic, trail]\n52            [can't, believ, injustic, happen, societi]\n53             [feel, sens, fear, watch, thriller, movi]\n54              [heartbroken, hear, news, natur, disast]\n55                     [state, world', environ, disgust]\n56             [pure, happi, celebr, love, one', achiev]\n57        [laughter, best, medicine—enjoy, comedi, show]\n58                   [share, love, posit, vibe, everyon]\n59                          [amus, incid, brighten, day]\n60                       [enjoy, quiet, even, book, tea]\n61              [admir, beauti, natur, dure, peac, hike]\n62                       [send, affection, vibe, follow]\n63                   [experienc, awe, breathtak, sunset]\n64                  [disappoint, servic, local, restaur]\n65                    [surpris, gift, friend, made, day]\n66                [find, accept, midst, life', challeng]\n67                           [overflow, ador, ador, pet]\n68               [anticip, thrill, adventur, come, week]\n69               [bitter, experi, turn, valuabl, lesson]\n70                        [find, calm, midst, busi, day]\n71                   [confus, cloud, mind, navig, decis]\n72                          [excit, build, upcom, vacat]\n73              [kind, wit, today, restor, faith, human]\n74                     [pride, achiev, person, mileston]\n75                      [moment, shame, stand, injustic]\n76                         [fume, anger, heat, argument]\n77                          [fear, unknown, keep, night]\n78          [heartfelt, sad, bid, farewel, dear, friend]\n79           [state, corrupt, societi, utterli, disgust]\n80        [overflow, happi, welcom, new, famili, member]\n81     [laughter, key, joy—attend, stand-up, comedi, ...\n82                [send, love, follow, thi, beauti, day]\n83                    [amus, antic, pet—it', pure, amus]\n84          [enjoy, everi, moment, thi, trip—pur, enjoy]\n85                [admir, dedic, volunt, local, chariti]\n86               [send, affection, vibe, friend, famili]\n87                      [awe-struck, beauti, night, sky]\n88         [disappoint, lack, progress, person, project]\n89     [surpris, visit, old, friend, brought, tear, joy]\n90                               [embrac, accept, life']\n91                  [overflow, ador, cute, rescu, puppi]\n92                   [anticip, releas, much-await, movi]\n93              [bitter, experi, custom, servic, depart]\n94               [find, calm, amidst, chao, daili, life]\n95       [confus, reign, tri, make, sens, recent, event]\n96              [excit, build, surpris, birthday, parti]\n97                           [wit, act, kind, made, day]\n98             [pride, complet, challeng, fit, challeng]\n99                      [moment, shame, speak, injustic]\n100                     [reflect, beauti, divers, world]\n101                     [excit, quiet, even, good, book]\n102                     [feel, bitter, unfair, workplac]\n103                       [calm, prevail, practic, mind]\n104              [confus, surround, navig, life', choic]\n105     [excit, weekend, road, trip, explor, new, place]\n106             [kind, wit, today, restor, faith, human]\n107        [pride, accomplish, person, profession, goal]\n108               [shame, true, valu, difficult, situat]\n109             [revisit, old, memori, feel, sens, elat]\n110             [victori, team, brought, euphoria, citi]\n111             [embrac, beauti, natur, moment, content]\n112              [medit, seren, lake, find, inner, peac]\n113                   [overflow, gratitud, life', bless]\n114         [hope, brighter, tomorrow, despit, challeng]\n115                        [empow, make, differ, commun]\n116    [compass, action, support, local, chariti, event]\n117                 [moment, tender, connect, love, one]\n118              [arous, excit, await, special, announc]\n119                     [enthusiast, dive, new, project]\n120                [feel, sens, fulfil, reach, mileston]\n121                    [rever, beauti, histor, landmark]\n122                [elat, surpris, reunion, old, friend]\n123               [euphoria, live, music, concert, star]\n124                    [content, simplic, quiet, sunday]\n125                  [seren, found, page, favorit, book]\n126       [gratitud, support, receiv, dure, tough, time]\n127                        [hope, possibl, new, journey]\n128                     [empower, learn, person, growth]\n129               [compass, toward, need, dure, holiday]\n130                 [tender, warmth, cozi, winter, even]\n131                      [arous, excit, upcom, adventur]\n132                 [enthusiasm, creativ, project, make]\n133         [fulfil, complet, challeng, workout, routin]\n134                   [rever, artistri, display, museum]\n135                         [elat, achiev, person, goal]\n136                    [elat, discov, hidden, gem, citi]\n137                [euphoria, surpris, birthday, celebr]\n138                  [content, simplic, home-cook, meal]\n139                  [seren, found, melodi, peac, piano]\n140                  [gratitud, support, commun, around]\n141                  [hope, prospect, new, busi, ventur]\n142                              [empower, mentor, guid]\n143                  [compass, shown, act, kind, commun]\n144               [tender, heartfelt, messag, love, one]\n145              [arous, excit, befor, much-await, trip]\n146             [enthusiasm, new, artist, project, work]\n147                           [feel, sens, fulfil, help]\n148                  [rever, histor, signific, landmark]\n149                        [elat, achiev, fit, mileston]\n150                 [euphoria, success, product, launch]\n151                         [content, embrac, love, one]\n152                  [seren, found, beauti, sunset, sea]\n153                   [gratitud, small, joy, day, bring]\n154                      [hope, potenti, person, growth]\n155                         [empower, learn, new, skill]\n156                    [compass, volunt, local, chariti]\n157                  [tender, quiet, moment, share, pet]\n158                        [arous, excit, upcom, festiv]\n159             [enthusiasm, diy, home, improv, project]\n160                   [fulfil, complet, challeng, puzzl]\n161                  [rever, wonder, natur, hike, trail]\n162          [elat, surpris, reunion, childhood, friend]\n163                    [suffer, despair, anoth, setback]\n164          [overwhelm, grief, miss, love, one, dearli]\n165                 [loneli, creep, night, grow, colder]\n166                     [jealousi, consum, wit, success]\n167                        [resent, build, past, betray]\n168              [frustrat, mount, obstacl, block, path]\n169           [boredom, set, day, feel, endlessli, dull]\n170        [anxieti, grip, heart, worri, cloud, thought]\n171                     [intimid, unknown, futur, ahead]\n172                     [helpless, sink, challeng, pile]\n173                      [envi, eat, away, see, prosper]\n174             [regret, miss, opportun, haunt, thought]\n175                  [disgust, sight, injustic, cruelti]\n176                 [drown, despair, hope, slip, finger]\n177     [grief, weigh, heavi, tear, constant, companion]\n178          [loneli, crowd, room, silent, cri, connect]\n179                [jealousi, gnaw, confid, toxic, emot]\n180               [resent, fester, poison, relationship]\n181                [frustrat, boil, volcan, erupt, emot]\n182     [boredom, settl, like, dust, life, feel, mundan]\n183    [anxieti, grip, chest, relentless, grip, thought]\n184         [intimid, challeng, ahead, fear, take, hold]\n185              [helpless, engulf, drown, sea, problem]\n186              [envi, poison, thought, covet, success]\n187                  [regret, decis, led, pain, present]\n188                   [disgust, corrupt, stain, societi]\n189                   [sink, despair, day, darker, last]\n190              [grief, overwhelm, storm, emot, within]\n191         [loneli, echo, empti, space, yearn, connect]\n192    [jealousi, poison, thought, resent, brew, within]\n193                 [resent, fester, wound, refus, heal]\n194                [frustrat, escal, thunderstorm, emot]\n195          [boredom, linger, stagnant, pool, indiffer]\n196    [embark, journey, discoveri, fuel, curios, thi...\n197    [lost, vast, sea, inform, indiffer, wave, digi...\n198    [complex, puzzl, life, leaf, state, perpetu, c...\n199    [numb, settl, shield, overwhelm, emot, life, t...\n200    [gaze, sunset, melanchol, long, moment, slip, ...\n201    [revisit, old, photograph, caught, embrac, nos...\n202    [torn, conflict, emot, ambival, paint, decis, ...\n203    [embrac, ebb, flow, life, find, accept, danc, ...\n204    [face, challeng, head-on, determin, fuel, fire...\n205    [seren, found, still, natur, tranquil, retreat...\n206    [curios, lead, rabbit, hole, knowledg, perpetu...\n207    [float, day, air, indiffer, detach, mundan, ha...\n208    [entangl, web, thought, confus, reign, navig, ...\n209    [numb, chao, emot, lock, away, stoic, facad, c...\n210    [melancholi, whisper, breez, silent, convers, ...\n211    [stumbl, upon, old, journal, nostalgia, flood,...\n212    [tapestri, conflict, feel, weav, uncertainti, ...\n213    [embrac, flaw, find, accept, imperfect, journe...\n214    [determin, burn, like, wildfir, overcom, obsta...\n215    [tranquil, moment, ocean, seren, wash, peac, r...\n216    [explor, new, horizon, spark, curios, adventur...\n217    [drift, day, nonchal, demeanor, embrac, art, i...\n218    [wrestl, thought, perplex, mind, lost, labyrin...\n219    [immers, state, emot, numb, shield, storm, dai...\n220    [melanchol, symphoni, play, background, soundt...\n221    [flip, page, old, yearbook, nostalgia, paint, ...\n222    [torn, oppos, emot, ambival, color, decis, sha...\n223    [embrac, life', imperfect, find, accept, journ...\n224    [fieri, determin, burn, within, fuel, vision, ...\n225    [bask, seren, quiet, forest, whisper, natur, b...\n226    [indiffer, nois, world, silent, observ, midst,...\n227    [navig, labyrinth, thought, confus, constant, ...\n228    [impenetr, numb, shield, emot, storm, fortress...\n229    [melancholi, paint, world, hue, nostalgia, can...\n230    [journey, past, flip, page, old, diari, nostal...\n231    [ambival, cloud, decis, caught, crossroad, con...\n232    [embrac, imperfect, find, accept, mosaic, life...\n233    [determin, drive, forc, propel, forward, path,...\n234    [seek, seren, melodi, raindrop, tranquil, esca...\n235    [curios, drive, explor, unknown, seeker, knowl...\n236    [drift, day, air, nonchal, indiffer, trivial, ...\n237    [lost, labyrinth, thought, confus, cast, shado...\n238    [wrap, cloak, emot, numb, shield, storm, life'...\n239    [melancholi, companion, paint, canva, life, br...\n240    [leaf, page, old, photo, album, nostalgia, wea...\n241    [ambival, air, caught, crossroad, conflict, em...\n242    [embrac, beauti, imperfect, find, accept, mosa...\n243    [determin, ablaz, forg, path, challeng, sculpt...\n244    [immers, seren, moonlit, night, quiet, whisper...\n245    [fuel, curios, ventur, unchart, realm, fearles...\n246    [wrap, cloak, emot, numb, shield, storm, life'...\n247    [danc, life, exuber, carefre, spirit, embrac, ...\n248    [bask, golden, glow, content, seren, river, fl...\n249    [gaze, toward, horizon, hope, eye, paint, canv...\n250    [stand, tall, proud, oak, branch, achiev, reac...\n251    [heart, overflow, gratitud, garden, appreci, b...\n252    [extend, hand, empathet, thread, weav, tapestr...\n253    [compassion, cloud, heavi, care, shower, empat...\n254    [play, danc, rain, laughter, whimsic, spirit, ...\n255    [soar, wing, free, spirit, unburden, chain, co...\n256    [bath, glow, inspir, creativ, phoenix, rise, a...\n257    [navig, sea, hope, sail, toward, sunris, possi...\n258    [stride, confid, footprint, self-assured, impr...\n259    [lost, symphoni, night, moonlit, serenad, whis...\n260    [unveil, layer, curios, labyrinth, question, l...\n261    [embrac, autumn, breez, leaf, ambival, danc, w...\n262    [gratitud, guid, star, navig, constel, bless, ...\n263    [zest, heart, sprint, field, enthusiasm, chase...\n264    [compassion, rain, tear, empathi, fall, gentli...\n265    [proudli, scale, peak, achiev, mountain, conqu...\n266    [embrac, hope, dawn, garden, sow, seed, optim,...\n267    [play, escapad, carniv, life, carousel, laught...\n268    [float, cloud, inspir, artist, paint, sky, str...\n269    [navig, river, content, seren, boat, cruis, tr...\n270    [empathi, lantern, wander, dark, alley, sorrow...\n271    [free, spirit, soar, wing, dream, leav, trail,...\n272    [bath, golden, hue, grate, sunset, appreci, ca...\n273    [confid, stride, danc, life, ballroom, self-as...\n274    [hope, whisper, wind, carri, promis, brighter,...\n275    [play, juggl, respons, circu, perform, balanc,...\n276    [whisper, tale, inspir, star, storytel, craft,...\n277    [chart, cours, wave, hope, anticip, sailor, st...\n278    [compassion, rain, tear, empathi, fall, gentli...\n279    [proudli, scale, peak, achiev, mountain, conqu...\n280    [embrac, hope, dawn, garden, sow, seed, optim,...\n281    [play, escapad, carniv, life, carousel, laught...\n282    [float, cloud, inspir, artist, paint, sky, str...\n283    [navig, river, content, seren, boat, cruis, tr...\n284    [empathi, lantern, wander, dark, alley, sorrow...\n285    [free, spirit, soar, wing, dream, leav, trail,...\n286    [bath, golden, hue, grate, sunset, appreci, ca...\n287    [confid, stride, danc, life, ballroom, self-as...\n288    [hope, whisper, wind, carri, promis, brighter,...\n289    [play, juggl, respons, circu, perform, balanc,...\n290    [whisper, tale, inspir, star, storytel, craft,...\n291    [chart, cours, wave, hope, anticip, sailor, st...\n292    [compassion, rain, tear, empathi, fall, gentli...\n293    [proudli, scale, peak, achiev, mountain, conqu...\n294    [embrac, hope, dawn, garden, sow, seed, optim,...\n295    [play, escapad, carniv, life, carousel, laught...\n296    [drown, abyss, despair, heart, shatter, fragme...\n297    [bitter, fester, like, venom, vine, entwin, so...\n298    [wander, desert, loneli, step, heavi, sigh, mi...\n299    [yearn, touch, that', echo, distant, warmth, h...\n300    [eye, wide, open, night, fear, shadow, danc, w...\n301    [apprehens, step, tightrop, uncertainti, balan...\n302    [overwhelm, weight, world, atla, trembl, shoul...\n303    [jealousi, green-ey, monster, lurk, shadow, ca...\n304    [devast, storm, betray, wreckag, trust, scatte...\n305    [frustrat, finger, tap, keyboard, symphoni, an...\n306    [enviou, eye, fixat, gild, prize, heartach, fu...\n307    [dismiss, glanc, fortress, built, indiffer, wa...\n308    [shatter, dream, lie, floor, like, fragment, g...\n309    [loneli, silent, companion, night, onli, echo,...\n310    [fear, whisper, dark, mind, haunt, specter, un...\n311    [bitter, bitter, aftertast, linger, tongu, wor...\n312    [overwhelm, cacophoni, expect, drown, soul, te...\n313    [jealousi, venom, seep, vein, poison, heart, t...\n314    [devast, revel, betray, trust, shatter, like, ...\n315    [frustrat, attempt, mend, broken, connect, thr...\n316    [enviou, gaze, cast, upon, podium, success, bi...\n317    [dismiss, gestur, curtain, drawn, shield, vuln...\n318    [despair, like, heavi, fog, envelop, everi, th...\n319    [bitter, bitter, chill, air, freez, moment, ic...\n320    [loneli, solitari, moon, starless, sky, cast, ...\n321    [yearn, warmth, vanish, sun, heartach, paint, ...\n322    [fear, eye, scan, shadow, prison, night, terro...\n323    [apprehens, whisper, wind, forecast, uncertain...\n324    [overwhelm, maze, expect, minotaur, pressur, l...\n325    [jealousi, fester, wound, pain, intensifi, gla...\n326    [devast, heart, ruin, echo, shatter, dream, re...\n327    [frustrat, attempt, untangl, knot, confus, thr...\n328    [enviou, eye, lock, treasur, chest, opportun, ...\n329    [dismiss, gestur, curtain, drawn, shield, vuln...\n330    [shatter, dream, lie, floor, like, fragment, g...\n331    [loneli, silent, companion, night, onli, echo,...\n332            [awe-struck, breathtak, sunris, mountain]\n333                          [navig, challeng, determin]\n334            [nostalgia, hit, flip, old, photo, album]\n335              [thrill, wit, grandeur, cultur, festiv]\n336           [calm, found, rhythm, raindrop, windowpan]\n337    [overwhelm, support, receiv, dure, person, cha...\n338    [excit, build, countdown, long-await, vacat, b...\n339      [reflect, life', journey, grate, lesson, learn]\n340    [bittersweet, emot, aris, bid, farewel, dear, ...\n341      [curios, spark, explor, mysteri, ancient, ruin]\n342       [admir, intric, detail, handcraft, masterpiec]\n343      [overjoy, warmth, cozi, fireplac, winter, even]\n344     [inspir, strike, observ, color, vibrant, sunset]\n345         [motiv, achiev, fit, goal, invigor, workout]\n346      [gratitud, simpl, joy, found, cup, morn, coffe]\n347        [feel, empow, conquer, challeng, hike, trail]\n348           [amus, antic, play, kitten, dure, playtim]\n349       [contempl, life', mysteri, starri, night, sky]\n350       [joy, reunion, long-lost, friend, year, separ]\n351              [excit, build, prepar, surpris, celebr]\n352    [satisfact, deriv, success, complet, diy, proj...\n353           [feel, bless, support, commun, time, need]\n354       [captiv, seren, tranquil, garden, full, bloom]\n355             [anticip, upcom, adventur, exot, destin]\n356      [reflect, person, growth, achiev, life, experi]\n357    [nostalg, memori, flood, revisit, childhood, f...\n358    [appreci, vibrant, cultur, experienc, dure, tr...\n359      [confid, soar, overcom, public, speak, anxieti]\n360     [content, midst, famili, gather, fill, laughter]\n361    [enthusiasm, learn, new, skill, expand, knowledg]\n362        [surpris, delight, discov, hidden, gem, citi]\n363       [sens, accomplish, complet, challeng, workout]\n364               [wonder, beauti, doubl, rainbow, rain]\n365       [optim, bright, futur, amidst, challeng, time]\n366    [pride, achiev, person, mileston, career, prog...\n367     [happi, bloom, like, flower, garden, sunni, day]\n368         [elat, discov, rare, book, quaint, bookstor]\n369    [curios, piqu, mysteri, ancient, archaeolog, s...\n370      [mesmer, cosmic, danc, firefli, moonlit, night]\n371    [intrigu, symphoni, color, abstract, art, exhi...\n372    [giggl, joy, echo, air, dure, children', playdat]\n373                [envelop, seren, practic, mind, lake]\n374    [chase, dream, like, kite, soar, high, vast, o...\n375    [spellbound, eleg, ballroom, danc, crystal, ch...\n376    [whimsic, delight, world, fairi, tale, magic, ...\n377    [pensiv, contempl, amid, ancient, ruin, forgot...\n378    [embrac, thrill, speed, rollercoaster', exhila...\n379    [harmoni, reson, musician, play, melodi, uniti...\n380    [burst, creativ, quiet, solitud, artist', studio]\n381    [radiant, joy, akin, bloom, flower, sun-kiss, ...\n382          [sens, wonder, vast, cosmo, stargaz, night]\n383         [rejuven, salti, breez, sound, wave, seasid]\n384        [whisper, inspir, rustl, leaf, seren, forest]\n385    [savor, warmth, cup, cocoa, chilli, winter, even]\n386    [heartfelt, gratitud, laughter, share, dure, f...\n387    [embark, culinari, adventur, savor, exot, flav...\n388    [euphoria, flood, final, puzzl, piec, click, p...\n389    [awe-inspir, grandeur, ancient, cathedral', in...\n390        [captiv, ether, beauti, field, fill, firefli]\n391    [immers, enchant, melodi, street, musician', v...\n392         [joy, laughter, reson, live, summer, carniv]\n393    [explor, univers, within, dure, mind, medit, s...\n394     [soar, like, free, spirit, wind, coastal, cliff]\n395       [dazzl, eleg, masquerad, ball', dazzl, costum]\n396      [whimsic, delight, world, whimsic, fairi, tale]\n397      [reflect, contempl, amid, ruin, forgotten, era]\n398    [ride, adrenalin, rush, rollercoaster', wild, ...\n399    [harmoni, reson, musician, play, symphoni, uniti]\n400    [burst, artist, creativ, quietud, artist', stu...\n401    [radiant, joy, akin, blossom, flower, sunlit, ...\n402            [awe-inspir, vast, cosmo, stargaz, night]\n403         [rejuven, salti, breez, sound, wave, seasid]\n404        [whisper, inspir, rustl, leaf, seren, forest]\n405    [savor, warmth, cup, cocoa, chilli, winter, even]\n406    [heartfelt, gratitud, laughter, share, dure, f...\n407    [embark, culinari, odyssey, savor, flavor, aro...\n408    [euphoria, flood, final, puzzl, piec, fit, per...\n409    [awe-struck, grandeur, ancient, cathedral', in...\n410    [curios, awaken, mysteri, ancient, archaeolog,...\n411           [giddi, excit, first, snowflak, danc, sky]\n412    [content, envelop, aroma, freshli, bake, bread...\n413     [inspir, resili, lone, tree, stand, tall, storm]\n414    [lost, page, captiv, novel, transport, anoth, ...\n415    [drench, nostalgia, flip, old, famili, photo, ...\n416    [spark, inspir, ignit, like, shoot, star, nigh...\n417     [imbu, gratitud, simpl, pleasur, warm, cup, tea]\n418    [marvel, kaleidoscop, color, vibrant, street, ...\n419    [awash, seren, sun, set, tranquil, lakesid, re...\n420        [drown, sorrow, memori, lost, love, resurfac]\n421           [numb, set, weight, loneli, grow, heavier]\n422    [tear, fall, like, raindrop, mourn, end, cheri...\n423    [despair, cloud, mind, feel, adrift, endless, ...\n424    [shatter, betray, trust, crumbl, like, fragil,...\n425    [ach, heart, symphoni, pain, play, silenc, sol...\n426    [emot, storm, whirlwind, sad, engulf, everi, t...\n427    [haunt, regret, ghost, past, linger, relentles...\n428     [torn, apart, grief, echo, loss, reverber, soul]\n429    [isol, deepen, emot, winter, warmth, distant, ...\n430    [soul-crush, disappoint, hope, shatter, like, ...\n431    [pain, echo, love, onc, cherish, lost, abyss, ...\n432    [heartach, deepen, solitari, journey, abyss, d...\n433    [melancholi, linger, bittersweet, serenad, qui...\n434    [bitter, like, poison, seep, everi, crevic, wo...\n435    [emot, exhaust, weight, world, crush, weari, s...\n436    [sorrow, echo, symphoni, pain, play, string, l...\n437       [dark, descend, engulf, soul, shadow, despair]\n438    [desper, whisper, silent, plea, glimmer, hope,...\n439    [heart, ruin, remnant, shatter, dream, scatter...\n440    [shatter, echo, shatter, dream, fragment, hope...\n441    [avoid, thorn, regret, walk, barefoot, path, r...\n442    [labyrinth, grief, wall, echo, footstep, lost,...\n443    [soul, adrift, sea, solitud, wave, loneli, cra...\n444    [bitter, betray, tast, linger, stain, palat, t...\n445    [ruin, hope, echo, shatter, dream, whisper, ta...\n446    [sink, like, stone, ocean, heartbreak, rippl, ...\n447    [tear, ink, stain, page, journal, testament, s...\n448    [wasteland, lost, trust, echo, broken, promis,...\n449    [avoid, shard, shatter, dream, walk, tightrop,...\n450    [suffoc, silenc, solitud, echo, laughter, onc,...\n451    [haunt, specter, lost, possibl, ghost, refus, ...\n452    [labyrinth, despair, echo, broken, heart, reve...\n453    [sink, like, autumn, leaf, river, sorrow, carr...\n454    [garden, broken, dream, petal, fall, silent, t...\n455    [tear, currenc, grief, spent, marketplac, lost...\n456    [wander, maze, betray, wall, close, everi, wro...\n457    [soul, weather, storm, heartbreak, seek, refug...\n458    [tapestri, despair, thread, hope, unravel, lea...\n459    [like, wither, rose, garden, love, petal, fall...\n460    [void, heartach, echo, love, song, play, note,...\n461    [nostalgia, bittersweet, danc, moonlit, ballro...\n462    [symphoni, grief, tear, note, compos, melancho...\n463    [betray, venom, serpent, slither, garden, trus...\n464    [sink, quicksand, despair, harder, fight, deep...\n465    [wander, cemeteri, lost, dream, tombston, mark...\n466    [swept, away, river, regret, current, past, re...\n467    [whisper, lost, love, linger, attic, heart, fo...\n468    [galleri, broken, promis, shatter, vow, frame,...\n469       [echo, solitud, silent, convers, soul, shadow]\n470    [danc, sunshin, step, celebr, joy, found, simp...\n471    [laughter, echo, air, choru, happi, lift, spir...\n472    [garden, content, bloom, whisper, tale, inner,...\n473    [chase, dream, vibrant, sky, journey, fuel, ho...\n474    [serenad, star, heart, full, gratitud, melodi,...\n475    [bask, glow, accomplish, mileston, step, stone...\n476    [danc, posit, everi, step, rhythm, uplift, sou...\n477    [overflow, joy, cup, laughter, share, friend, ...\n478    [drape, warmth, kind, quilt, compass, stitch, ...\n479    [garden, friendship, bloom, testament, beauti,...\n480    [embrac, love, heartbeat, melodi, danc, rhythm...\n481    [surround, color, joy, canva, paint, laughter,...\n482    [symphoni, excit, note, burst, energi, ignit, ...\n483    [surpris, gift, wrap, anticip, unfold, moment,...\n484    [lost, maze, curios, twist, turn, unveil, trea...\n485    [float, cloud, gratitud, raindrop, bless, show...\n486    [like, comet, inspir, streak, sky, creativ, le...\n487    [celebr, success, firework, accomplish, light,...\n488    [symphoni, laughter, note, key, unlock, door, ...\n489    [carniv, emot, rollercoast, thrill, send, hear...\n490    [stand, befor, grandeur, eiffel, tower, moment...\n491    [lost, enchant, disneyland, ride, journey, rea...\n492    [explor, wonder, ferrari, world, roar, engin, ...\n493    [amidst, tulip, field, keukenhof, tapestri, co...\n494    [wander, histor, street, kyoto, step, journey,...\n495    [embrac, grand, canyon, nature', masterpiec, m...\n496    [journey, seren, santorini, sunset, paint, sky...\n497    [amaz, architectur, marvel, petra, stone, tell...\n498    [embark, gondola, ride, venic, canal, reflect,...\n499    [summit, machu, picchu, breathtak, panorama, w...\n500    [heart, new, york, citi, time, squar, dazzl, l...\n501    [captiv, histor, charm, colosseum, stone, echo...\n502    [sail, azur, water, maldiv, wave, whisper, ser...\n503    [midst, amazon, rainforest, symphoni, wildlif,...\n504    [walk, great, wall, china, step, testament, an...\n505    [summit, mount, fuji, breathtak, sunris, paint...\n506    [explor, ancient, ruin, angkor, wat, stone, wh...\n507    [ski, slope, swiss, alp, turn, danc, majesti, ...\n508    [tranquil, kyoto', bamboo, forest, whisper, an...\n509    [cruis, fjord, norway, ici, landscap, breathta...\n510    [front, row, adele', concert, note, 'someon, l...\n511    [danc, star, beyoncé', live, show, feel, power...\n512    [crowd, taylor, swift, concert, lyric, 'love, ...\n513    [rock, guitar, solo, queen, tribut, concert, j...\n514    [sway, ed, sheeran', acoust, melodi, seren, ev...\n515    [immers, pulsat, beat, bruno, mar, concert, 'u...\n516    [michael, jackson, tribut, show, moonwalk, hit...\n517    [swing, rhythm, frank, sinatra, tribut, feel, ...\n518    [mosh, pit, metallica, concert, thunder, chord...\n519    [experienc, magic, coldplay, concert, 'fix, be...\n520    [justin, bieber, concert, infecti, beat, 'babi...\n521    [spotlight, ladi, gaga, show, costum, chang, m...\n522    [immers, soul, melodi, adel, tear, flow, freel...\n523    [drench, confetti, kati, perri, concert, kalei...\n524    [audienc, jay-z, perform, lyric, 'empir, state...\n525    [danc, shakira', rhythmic, beat, hip, sway, hy...\n526    [u2, concert, anthem, chord, 'with, without, c...\n527    [rock, gun, n, rose, show, icon, riff, 'sweet,...\n528    [crowd, ariana, grand, concert, high, note, 'i...\n529    [sway, regga, vibe, bob, marley', tribut, conc...\n530    [captiv, spellbind, plot, twist, audienc, appl...\n531    [credit, roll, profound, sens, nostalgia, wash...\n532    [stream, latest, web, seri, viewer, engross, c...\n533    [film, festiv, indi, filmmaker', creation, rec...\n534    [watch, heartwarm, famili, drama, tear, flow, ...\n535    [oscar, actor, gracious, accept, award, radiat...\n536    [discov, hidden, gem, world, documentari, view...\n537    [movi, credit, roll, viewer, experi, mix, awe,...\n538    [binge-watch, thrill, crime, seri, suspens, ke...\n539    [close, scene, unfold, sens, satisfact, wash, ...\n540    [celebr, histor, victori, world, cup, nation, ...\n541    [olymp, athlete', persever, shine, earn, gold,...\n542    [cricket, championship, nail-bit, finish, leaf...\n543    [wit, record-break, marathon, spectat, fill, a...\n544    [tenni, grand, slam, fierc, rivalri, unfold, c...\n545    [cheer, underdog, basketbal, final, crowd, eru...\n546    [golf, tournament, golfer', precis, focu, lead...\n547    [experienc, thrill, high-spe, formula, 1, race...\n548    [cycl, world, championship, climber, conquer, ...\n549    [wit, heartwarm, comeback, hockey, final, fan,...\n550    [seri, defeat, soccer, team, face, disappoint,...\n551    [tenni, tournament, highli, anticip, player, e...\n552    [face, defeat, championship, boxer, reflect, c...\n553    [midst, cycl, race, tire, blowout, lead, frust...\n554    [gymnast', unexpect, fall, dure, routin, spark...\n555    [golf, tournament, miss, crucial, putt, result...\n556    [experienc, seri, loss, basketbal, season, tea...\n557    [despit, meticul, train, swimmer, face, disapp...\n558    [weightlifter', fail, attempt, person, record,...\n559    [midst, soccer, match, unexpect, goal, creat, ...\n560    [seren, beauti, sunset, natur, unfold, canva, ...\n561    [embark, spontan, road, trip, travel, discov, ...\n562    [amidst, bustl, citi, quiet, café, becom, sanc...\n563    [explor, vibrant, street, art, cultur, neighbo...\n564    [world, scienc, breakthrough, discoveri, unfol...\n565    [connect, melodi, live, orchestra, music, enth...\n566    [embrac, aroma, freshli, bake, bread, home, ch...\n567    [wander, histor, museum, histori, enthusiast, ...\n568    [realm, literatur, captiv, novel, transport, r...\n569    [captur, essenc, bustl, market, photograph, fr...\n570    [underneath, citi, light, dancer, express, emo...\n571    [heart, bustl, market, street, food, connoisse...\n572    [first, snowflak, descend, winter, enthusiast,...\n573    [amidst, page, captiv, mysteri, novel, reader,...\n574    [surround, vibrant, color, flower, garden, gar...\n575    [astronomi, observatori, stargaz, marvel, vast...\n576    [engulf, aroma, freshli, brew, coffe, writer, ...\n577    [realm, fashion, design, unveil, collect, tell...\n578    [wave, crash, shore, surfer, embrac, thrill, r...\n579    [explor, histor, architectur, ancient, citi, t...\n580    [success, avoid, eye, contact, crush, hallway,...\n581    [ran, snack, dure, movi, marathon, crisi, leve...\n582    [spent, hour, choos, perfect, filter, selfi, s...\n583    [lost, headphon, vanish, thin, air, #headphone...\n584    [decid, studi, exam, end, make, meme, studi, i...\n585    [got, dress, day, rememb, it', saturday, oop, ...\n586    [surviv, group, project, without, ani, drama, ...\n587    [enter, kitchen, intent, cook, left, bag, chip...\n588    [stare, clock, class, wait, bell, ring, like, ...\n589    [discov, new, book, seri, spent, whole, night,...\n590    [bought, new, video, game, play, hour, forgot,...\n591    [spent, day, binge-watch, new, seri, product, ...\n592    [caught, latest, fashion, trend, plan, shop, s...\n593    [decid, learn, new, instrument, day, one, stil...\n594    [spent, hour, creat, perfect, playlist, everi,...\n595    [success, cook, gourmet, meal, famili, chef, s...\n596    [spontan, book, weekend, getaway, adventur, aw...\n597    [attend, concert, danc, night, away, music, he...\n598    [rediscov, childhood, cartoon, nostalgia-fil, ...\n599    [embark, diy, home, decor, project, let', hope...\n600    [spent, afternoon, museum, pretend, cultur, ar...\n601    [start, blog, random, thought, muse, blog, new...\n602    [relish, peac, afternoon, classic, novel, quie...\n603    [reflect, lifetim, memori, wrinkl, tell, stori...\n604    [explor, world, digit, art, it', never, late, ...\n605    [savor, flavor, home-cook, meal, simpl, joy, h...\n606    [embark, journey, learn, new, languag, mind, s...\n607    [attend, classic, music, concert, feel, timele...\n608    [captur, beauti, natur, photographi, everi, sn...\n609    [reconnect, old, friend, cup, tea, friendship,...\n610    [embark, road, trip, revisit, cherish, place, ...\n611    [join, commun, choir, harmon, fellow, voic, mu...\n612    [explor, art, medit, find, tranquil, still, mi...\n613    [take, stroll, garden, appreci, beauti, bloom,...\n614    [sip, favorit, vintag, wine, sip, tell, stori,...\n615    [particip, commun, art, class, unleash, creati...\n616    [embark, journey, write, memoir, document, lif...\n617    [attend, lectur, histori, alway, fascin, lesso...\n618    [rediscov, joy, cook, tradit, famili, recip, k...\n619    [join, natur, photographi, club, captur, beaut...\n620    [attend, jazz, concert, sway, rhythm, timeless...\n621    [join, write, group, pen, thought, reflect, wr...\n622    [embark, solo, travel, adventur, discov, beaut...\n623    [attend, vintag, car, show, reminisc, classic,...\n624    [start, commun, garden, grow, plant, friendshi...\n625    [host, famili, dinner, laughter, echo, louder,...\n626    [enrol, danc, class, senior, move, rhythm, lif...\n627    [visit, art, galleri, appreci, brushstrok, tel...\n628    [start, book, club, senior, discuss, live, cha...\n629    [host, picnic, park, bask, warmth, friendship,...\n630    [particip, local, theater, product, prove, sta...\n631    [embark, hike, adventur, conquer, trail, relis...\n632    [host, photographi, exhibit, featur, snapshot,...\n633    [join, senior, cycl, club, feel, wind, hair, f...\n634    [attend, wine, tast, event, savor, rich, flavo...\n635    [start, learn, ballroom, danc, glide, grace, a...\n636    [organ, commun, paint, event, turn, blank, can...\n637    [host, 'memori, lane, even, old, friend, remin...\n638    [join, senior, astronomi, club, stargaz, find,...\n639    [attend, local, jazz, festiv, tap, toe, tune, ...\n640    [start, blog, share, wisdom, gain, year, prove...\n641    [particip, chariti, run, prove, age, barrier, ...\n642      [surviv, challeng, physic, exam, equat, defeat]\n643    [explor, world, code, debug, adventur, #coding...\n644    [join, school, debat, team, word, weapon, read...\n645    [start, photographi, club, school, captur, mom...\n646    [daydream, upcom, prom, dress, danc, –, it', f...\n647    [convinc, teacher, class, outdoor, learn, equa...\n648    [accident, spill, paint, art, class, abstract,...\n649    [tri, master, perfect, kickflip, skateboard, s...\n650    [bond, friend, latest, k-pop, sensat, fangirl,...\n651    [spent, hour, perfect, chemistri, experi, mix,...\n652    [success, organ, surpris, birthday, parti, fri...\n653    [join, drama, club, unleash, inner, actor, lig...\n654    [got, hand, latest, fantasi, novel, dive, real...\n655    [master, art, perfect, doodl, dure, bore, clas...\n656    [attempt, break, school, record, longest, hand...\n657    [sneak, snack, class, like, pro, art, snack-sm...\n658    [host, sleepov, friend, thi, weekend, prepar, ...\n659    [spent, hour, tiktok, danc, onli, realiz, two,...\n660    [accident, like, crush', old, photo, stalk, pr...\n661    [tri, impress, crush, smooth, convers, end, sp...\n662    [master, art, creat, paper, airplan, dure, lec...\n663    [tri, set, new, trend, juggl, textbook, class,...\n664    [hide, snack, stash, backpack, emerg, crave, s...\n665    [plan, surpris, scaveng, hunt, friend, anticip...\n666    [danc, rain, celebr, end, exam, rain, danc, un...\n667    [accident, sent, text, meant, friend, class, g...\n668    [tri, magic, trick, impress, classmat, magic, ...\n669    [perfect, art, creat, origami, dure, dull, lec...\n670    [attempt, set, new, record, consecut, hacki, s...\n671    [creat, secret, handshak, friend, friendship, ...\n672    [embark, mission, find, best, burger, joint, t...\n673    [practic, stand-up, comedi, routin, upcom, tal...\n674    [accident, sent, love, letter, wrong, person, ...\n675    [attempt, impress, teacher, elabor, scienc, ex...\n676    [craft, intric, friendship, bracelet, whole, s...\n677    [attempt, beat, record, consecut, cartwheel, c...\n678    [organ, movi, marathon, friend, popcorn, cinem...\n679    [experi, new, hair, color, bold, chang, bold, ...\n680    [build, time, capsul, captur, memori, futur, t...\n681    [accident, walk, wrong, classroom, first, day,...\n682    [tri, new, smoothi, recip, healthi, start, wee...\n683    [reflect, challeng, school, year, feel, bit, o...\n684    [encount, mean-spirit, comment, onlin, deal, o...\n685         [bad, day, school, everyth, seem, go, wrong]\n686        [feel, make, sport, team, disappoint, linger]\n687    [wit, heat, argument, cafeteria, unpleas, atmo...\n688    [receiv, not-so-great, grade, major, project, ...\n689    [deal, person, setback, sometim, life, throw, ...\n690    [feel, lone, saturday, night, sometim, solitud...\n691    [experienc, cyberbulli, hate, messag, onlin, d...\n692    [caught, torrenti, rainstorm, without, umbrell...\n693    [miss, import, event, due, unforeseen, circums...\n694    [deal, unfound, rumor, circul, person, life, r...\n695    [got, flat, tire, way, import, meet, talk, ser...\n696    [feel, sens, empti, close, friend, move, away,...\n697    [face, reject, dream, colleg, dishearten, dete...\n698    [encount, onlin, toxic, dure, game, session, h...\n699    [bad, hair, day, feel, self-consci, bad, hair,...\n700    [feel, sens, despair, major, project, failur, ...\n701    [experienc, hate, comment, express, person, op...\n702    [string, bad, luck, constant, technolog, malfu...\n703    [miss, long-anticip, event, due, unexpect, cir...\n704    [tri, new, studi, techniqu, upcom, exam, explo...\n705    [organ, commun, cleanup, event, cleaner, neigh...\n706    [share, favorit, book, recommend, classmat, bu...\n707    [experi, new, recip, school, bake, sale, bake,...\n708    [collabor, school, project, peer, teamwork, ma...\n709    [attend, school, club, meet, explor, new, inte...\n710    [explor, new, part-tim, job, opportun, gain, w...\n711    [attend, school, assembl, stay, inform, upcom,...\n712    [explor, new, hobbi, photographi, dure, free, ...\n713    [particip, scienc, fair, showcas, uniqu, exper...\n714    [attend, workshop, time, manag, enhanc, organi...\n715    [volunt, local, chariti, event, give, back, co...\n716    [collabor, group, project, promot, teamwork, s...\n717    [particip, debat, club, enhanc, critic, think,...\n718    [celebr, friend', birthday, surpris, parti, jo...\n719    [success, complet, challeng, code, project, ex...\n720    [attend, school, talent, show, support, classm...\n721    [explor, new, hike, trail, friend, weekend, na...\n722    [win, friendli, sport, competit, rival, school...\n723    [receiv, heartfelt, letter, pen, pal, anoth, c...\n724    [creat, beauti, mural, fellow, art, enthusiast...\n725    [particip, school-wid, art, exhibit, wit, crea...\n726    [achiev, person, best, track, field, competit,...\n727    [collabor, scienc, project, receiv, recognit, ...\n728    [attend, surpris, birthday, parti, organ, frie...\n729    [success, fundrais, school, chariti, initi, jo...\n730    [particip, multicultur, festiv, celebr, divers...\n731    [organ, virtual, talent, show, dure, challeng,...\nName: Text, dtype: object\n","output_type":"stream"}],"execution_count":344},{"cell_type":"code","source":"from gensim.models import Word2Vec\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\n\n# Train Word2Vec using skip-gram (sg=1) with 100 epochs\nsentences = train_df['Text'].tolist()\nw2v_model = Word2Vec(sentences, vector_size=300, window=7, min_count=2, workers=4, sg=1, negative=10, epochs=100)\nw2v_model.save(\"word2vec.model\")\n\n# Function to generate a 1200-dimension sentence vector (avg, max, min, and std pooling)\ndef get_complex_sentence_vector(sentence, model, vector_size=300):\n    vectors = [model.wv[word] for word in sentence if word in model.wv]\n    if vectors:\n        vectors = np.array(vectors)\n        avg_vec = np.mean(vectors, axis=0)\n        max_vec = np.max(vectors, axis=0)\n        min_vec = np.min(vectors, axis=0)\n        std_vec = np.std(vectors, axis=0)\n        return np.concatenate([avg_vec, max_vec, min_vec, std_vec])\n    else:\n        return np.zeros(vector_size * 4)\n\ntrain_df['vector'] = train_df['Text'].apply(lambda x: get_complex_sentence_vector(x, w2v_model))\n\nlabel_encoder = LabelEncoder()\ntrain_df['Sentiment'] = label_encoder.fit_transform(train_df['Sentiment'])\nX = np.vstack(train_df['vector'].values)\ny = train_df['Sentiment'].values.astype(np.int32)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\naccuracies = []\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    model = Sequential([\n        Dense(2048, input_shape=(1200,)),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(1024),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(512),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(256),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(128),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(3, activation='softmax')\n    ])\n    \n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n    \n    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), callbacks=[lr_scheduler], verbose=1)\n    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n    accuracies.append(accuracy)\n    \nprint(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:44:21.633470Z","iopub.execute_input":"2025-03-13T19:44:21.633920Z","iopub.status.idle":"2025-03-13T19:50:23.963635Z","shell.execute_reply.started":"2025-03-13T19:44:21.633877Z","shell.execute_reply":"2025-03-13T19:50:23.961447Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.3405 - loss: 1.7073 - val_accuracy: 0.4898 - val_loss: 1.0740 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4884 - loss: 1.3496 - val_accuracy: 0.5238 - val_loss: 1.0353 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5637 - loss: 1.0553 - val_accuracy: 0.5782 - val_loss: 0.9901 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6145 - loss: 1.0327 - val_accuracy: 0.5442 - val_loss: 1.0844 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6346 - loss: 0.9223 - val_accuracy: 0.5374 - val_loss: 1.2529 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6236 - loss: 0.9369\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6253 - loss: 0.9331 - val_accuracy: 0.5102 - val_loss: 1.5046 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.6875 - loss: 0.8483 - val_accuracy: 0.5442 - val_loss: 1.2719 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7153 - loss: 0.7004 - val_accuracy: 0.5510 - val_loss: 1.2523 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7341 - loss: 0.7308\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7318 - loss: 0.7364 - val_accuracy: 0.5850 - val_loss: 1.0083 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6889 - loss: 0.8269 - val_accuracy: 0.5918 - val_loss: 0.9864 - learning_rate: 2.5000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7019 - loss: 0.7615 - val_accuracy: 0.6122 - val_loss: 0.9486 - learning_rate: 2.5000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7302 - loss: 0.6791 - val_accuracy: 0.6190 - val_loss: 0.9339 - learning_rate: 2.5000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7192 - loss: 0.7380 - val_accuracy: 0.6395 - val_loss: 0.9121 - learning_rate: 2.5000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7230 - loss: 0.7212 - val_accuracy: 0.6667 - val_loss: 0.8412 - learning_rate: 2.5000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7390 - loss: 0.6930 - val_accuracy: 0.6667 - val_loss: 0.8149 - learning_rate: 2.5000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7571 - loss: 0.6606 - val_accuracy: 0.6871 - val_loss: 0.7960 - learning_rate: 2.5000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7396 - loss: 0.6761 - val_accuracy: 0.7007 - val_loss: 0.7777 - learning_rate: 2.5000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7510 - loss: 0.6864 - val_accuracy: 0.7007 - val_loss: 0.7695 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7331 - loss: 0.6957 - val_accuracy: 0.7143 - val_loss: 0.7676 - learning_rate: 2.5000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7602 - loss: 0.6312 - val_accuracy: 0.7075 - val_loss: 0.7720 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7727 - loss: 0.5956 - val_accuracy: 0.7075 - val_loss: 0.7615 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7748 - loss: 0.5796 - val_accuracy: 0.7075 - val_loss: 0.7622 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7732 - loss: 0.6071 - val_accuracy: 0.7007 - val_loss: 0.7676 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7586 - loss: 0.5745\nEpoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7624 - loss: 0.5702 - val_accuracy: 0.7007 - val_loss: 0.7649 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7555 - loss: 0.5898 - val_accuracy: 0.7211 - val_loss: 0.7602 - learning_rate: 1.2500e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7718 - loss: 0.5580 - val_accuracy: 0.7143 - val_loss: 0.7609 - learning_rate: 1.2500e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7985 - loss: 0.5484 - val_accuracy: 0.7075 - val_loss: 0.7607 - learning_rate: 1.2500e-04\nEpoch 28/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7821 - loss: 0.5379\nEpoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7823 - loss: 0.5318 - val_accuracy: 0.7211 - val_loss: 0.7625 - learning_rate: 1.2500e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7867 - loss: 0.4926 - val_accuracy: 0.7211 - val_loss: 0.7639 - learning_rate: 6.2500e-05\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7426 - loss: 0.6565 - val_accuracy: 0.7211 - val_loss: 0.7652 - learning_rate: 6.2500e-05\nEpoch 31/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7748 - loss: 0.5081\nEpoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7769 - loss: 0.5095 - val_accuracy: 0.7347 - val_loss: 0.7735 - learning_rate: 6.2500e-05\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8123 - loss: 0.4982 - val_accuracy: 0.7211 - val_loss: 0.7776 - learning_rate: 3.1250e-05\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7868 - loss: 0.5500 - val_accuracy: 0.7211 - val_loss: 0.7835 - learning_rate: 3.1250e-05\nEpoch 34/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7837 - loss: 0.5424\nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7814 - loss: 0.5470 - val_accuracy: 0.7143 - val_loss: 0.7888 - learning_rate: 3.1250e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7879 - loss: 0.5306 - val_accuracy: 0.7143 - val_loss: 0.7921 - learning_rate: 1.5625e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7548 - loss: 0.5473 - val_accuracy: 0.7143 - val_loss: 0.7953 - learning_rate: 1.5625e-05\nEpoch 37/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7946 - loss: 0.4953\nEpoch 37: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7953 - loss: 0.4978 - val_accuracy: 0.7211 - val_loss: 0.7984 - learning_rate: 1.5625e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7960 - loss: 0.4894 - val_accuracy: 0.7211 - val_loss: 0.8004 - learning_rate: 7.8125e-06\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8009 - loss: 0.5252 - val_accuracy: 0.7211 - val_loss: 0.8029 - learning_rate: 7.8125e-06\nEpoch 40/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8011 - loss: 0.5144\nEpoch 40: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8024 - loss: 0.5143 - val_accuracy: 0.7143 - val_loss: 0.8066 - learning_rate: 7.8125e-06\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8072 - loss: 0.5184 - val_accuracy: 0.7211 - val_loss: 0.8107 - learning_rate: 3.9063e-06\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7907 - loss: 0.5168 - val_accuracy: 0.7143 - val_loss: 0.8138 - learning_rate: 3.9063e-06\nEpoch 43/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8207 - loss: 0.5062\nEpoch 43: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8197 - loss: 0.5064 - val_accuracy: 0.7211 - val_loss: 0.8172 - learning_rate: 3.9063e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7969 - loss: 0.5462 - val_accuracy: 0.7211 - val_loss: 0.8193 - learning_rate: 1.9531e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7830 - loss: 0.5284 - val_accuracy: 0.7211 - val_loss: 0.8236 - learning_rate: 1.9531e-06\nEpoch 46/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8246 - loss: 0.4508\nEpoch 46: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8211 - loss: 0.4564 - val_accuracy: 0.7211 - val_loss: 0.8257 - learning_rate: 1.9531e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8153 - loss: 0.5006 - val_accuracy: 0.7211 - val_loss: 0.8300 - learning_rate: 1.0000e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7911 - loss: 0.5788 - val_accuracy: 0.7211 - val_loss: 0.8341 - learning_rate: 1.0000e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7696 - loss: 0.5766 - val_accuracy: 0.7143 - val_loss: 0.8387 - learning_rate: 1.0000e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8408 - loss: 0.4427 - val_accuracy: 0.7143 - val_loss: 0.8427 - learning_rate: 1.0000e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8117 - loss: 0.4546 - val_accuracy: 0.7143 - val_loss: 0.8468 - learning_rate: 1.0000e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8427 - loss: 0.4377 - val_accuracy: 0.7143 - val_loss: 0.8507 - learning_rate: 1.0000e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7867 - loss: 0.4962 - val_accuracy: 0.7211 - val_loss: 0.8558 - learning_rate: 1.0000e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7802 - loss: 0.5265 - val_accuracy: 0.7211 - val_loss: 0.8580 - learning_rate: 1.0000e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8040 - loss: 0.5096 - val_accuracy: 0.7143 - val_loss: 0.8593 - learning_rate: 1.0000e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8172 - loss: 0.4942 - val_accuracy: 0.7143 - val_loss: 0.8617 - learning_rate: 1.0000e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8024 - loss: 0.5052 - val_accuracy: 0.7143 - val_loss: 0.8653 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8101 - loss: 0.4725 - val_accuracy: 0.7143 - val_loss: 0.8670 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8167 - loss: 0.4633 - val_accuracy: 0.7143 - val_loss: 0.8699 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7912 - loss: 0.4834 - val_accuracy: 0.7143 - val_loss: 0.8739 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7805 - loss: 0.4967 - val_accuracy: 0.7143 - val_loss: 0.8783 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8167 - loss: 0.4673 - val_accuracy: 0.7143 - val_loss: 0.8808 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8258 - loss: 0.4755 - val_accuracy: 0.7143 - val_loss: 0.8811 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8047 - loss: 0.5017 - val_accuracy: 0.7143 - val_loss: 0.8843 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8177 - loss: 0.4589 - val_accuracy: 0.7143 - val_loss: 0.8878 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8046 - loss: 0.5177 - val_accuracy: 0.7143 - val_loss: 0.8901 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8049 - loss: 0.5284 - val_accuracy: 0.7211 - val_loss: 0.8911 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7873 - loss: 0.5080 - val_accuracy: 0.7211 - val_loss: 0.8937 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8185 - loss: 0.4495 - val_accuracy: 0.7143 - val_loss: 0.8954 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8189 - loss: 0.4957 - val_accuracy: 0.7143 - val_loss: 0.8975 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7750 - loss: 0.5461 - val_accuracy: 0.7143 - val_loss: 0.8968 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8174 - loss: 0.4652 - val_accuracy: 0.7211 - val_loss: 0.8985 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8173 - loss: 0.4954 - val_accuracy: 0.7211 - val_loss: 0.8999 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7781 - loss: 0.5261 - val_accuracy: 0.7279 - val_loss: 0.9012 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8032 - loss: 0.5081 - val_accuracy: 0.7211 - val_loss: 0.9038 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7803 - loss: 0.5649 - val_accuracy: 0.7279 - val_loss: 0.9039 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7693 - loss: 0.5223 - val_accuracy: 0.7279 - val_loss: 0.9056 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8035 - loss: 0.5270 - val_accuracy: 0.7279 - val_loss: 0.9070 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7976 - loss: 0.4889 - val_accuracy: 0.7279 - val_loss: 0.9094 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7978 - loss: 0.4875 - val_accuracy: 0.7279 - val_loss: 0.9093 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8320 - loss: 0.4341 - val_accuracy: 0.7279 - val_loss: 0.9086 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8207 - loss: 0.4667 - val_accuracy: 0.7279 - val_loss: 0.9092 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7767 - loss: 0.5315 - val_accuracy: 0.7279 - val_loss: 0.9099 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8157 - loss: 0.4808 - val_accuracy: 0.7279 - val_loss: 0.9092 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7948 - loss: 0.4943 - val_accuracy: 0.7279 - val_loss: 0.9105 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8306 - loss: 0.4592 - val_accuracy: 0.7279 - val_loss: 0.9123 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7789 - loss: 0.4783 - val_accuracy: 0.7279 - val_loss: 0.9132 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8013 - loss: 0.4931 - val_accuracy: 0.7279 - val_loss: 0.9143 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8283 - loss: 0.4980 - val_accuracy: 0.7279 - val_loss: 0.9138 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8010 - loss: 0.5065 - val_accuracy: 0.7279 - val_loss: 0.9156 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8206 - loss: 0.4930 - val_accuracy: 0.7279 - val_loss: 0.9147 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8013 - loss: 0.4850 - val_accuracy: 0.7279 - val_loss: 0.9136 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7668 - loss: 0.5661 - val_accuracy: 0.7279 - val_loss: 0.9152 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7808 - loss: 0.5371 - val_accuracy: 0.7279 - val_loss: 0.9158 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8071 - loss: 0.4773 - val_accuracy: 0.7279 - val_loss: 0.9153 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8059 - loss: 0.4896 - val_accuracy: 0.7279 - val_loss: 0.9155 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8117 - loss: 0.4773 - val_accuracy: 0.7279 - val_loss: 0.9163 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8226 - loss: 0.4488 - val_accuracy: 0.7279 - val_loss: 0.9169 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8168 - loss: 0.5025 - val_accuracy: 0.7211 - val_loss: 0.9170 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8356 - loss: 0.4217 - val_accuracy: 0.7279 - val_loss: 0.9150 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.3388 - loss: 1.7455 - val_accuracy: 0.5578 - val_loss: 1.0369 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5264 - loss: 1.1763 - val_accuracy: 0.6054 - val_loss: 0.9555 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6065 - loss: 1.0309 - val_accuracy: 0.6395 - val_loss: 0.9154 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5965 - loss: 1.1063 - val_accuracy: 0.3673 - val_loss: 1.2480 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6389 - loss: 1.0364 - val_accuracy: 0.5102 - val_loss: 1.0606 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6270 - loss: 1.0082\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6296 - loss: 0.9960 - val_accuracy: 0.5782 - val_loss: 1.1530 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6824 - loss: 0.8156 - val_accuracy: 0.6395 - val_loss: 0.8567 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6992 - loss: 0.7648 - val_accuracy: 0.6667 - val_loss: 0.8639 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6655 - loss: 0.8966 - val_accuracy: 0.6463 - val_loss: 0.8059 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7186 - loss: 0.7548 - val_accuracy: 0.6395 - val_loss: 0.7968 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7006 - loss: 0.7869 - val_accuracy: 0.6327 - val_loss: 0.7586 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6986 - loss: 0.7656 - val_accuracy: 0.6667 - val_loss: 0.7487 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7182 - loss: 0.7327 - val_accuracy: 0.6871 - val_loss: 0.7343 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7410 - loss: 0.6615 - val_accuracy: 0.6531 - val_loss: 0.7587 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7583 - loss: 0.6713 - val_accuracy: 0.6735 - val_loss: 0.7410 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7540 - loss: 0.6231\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7543 - loss: 0.6207 - val_accuracy: 0.6531 - val_loss: 0.7366 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7344 - loss: 0.6582 - val_accuracy: 0.6531 - val_loss: 0.7370 - learning_rate: 2.5000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7656 - loss: 0.5722 - val_accuracy: 0.6531 - val_loss: 0.7346 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7816 - loss: 0.5741 - val_accuracy: 0.6735 - val_loss: 0.7340 - learning_rate: 2.5000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7734 - loss: 0.6000 - val_accuracy: 0.6803 - val_loss: 0.7280 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7590 - loss: 0.6155 - val_accuracy: 0.6939 - val_loss: 0.7179 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7809 - loss: 0.5633 - val_accuracy: 0.7007 - val_loss: 0.7163 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7723 - loss: 0.6231 - val_accuracy: 0.7007 - val_loss: 0.7165 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7878 - loss: 0.5681 - val_accuracy: 0.6735 - val_loss: 0.7271 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7450 - loss: 0.5953\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7482 - loss: 0.5930 - val_accuracy: 0.6803 - val_loss: 0.7362 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7738 - loss: 0.5456 - val_accuracy: 0.6735 - val_loss: 0.7391 - learning_rate: 1.2500e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7951 - loss: 0.5025 - val_accuracy: 0.6803 - val_loss: 0.7351 - learning_rate: 1.2500e-04\nEpoch 28/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7766 - loss: 0.5490\nEpoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7833 - loss: 0.5397 - val_accuracy: 0.6871 - val_loss: 0.7355 - learning_rate: 1.2500e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7809 - loss: 0.5069 - val_accuracy: 0.6871 - val_loss: 0.7300 - learning_rate: 6.2500e-05\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7582 - loss: 0.5802 - val_accuracy: 0.6871 - val_loss: 0.7251 - learning_rate: 6.2500e-05\nEpoch 31/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7712 - loss: 0.6031\nEpoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7767 - loss: 0.5880 - val_accuracy: 0.6939 - val_loss: 0.7240 - learning_rate: 6.2500e-05\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8377 - loss: 0.4372 - val_accuracy: 0.6939 - val_loss: 0.7219 - learning_rate: 3.1250e-05\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7915 - loss: 0.5046 - val_accuracy: 0.6939 - val_loss: 0.7203 - learning_rate: 3.1250e-05\nEpoch 34/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8109 - loss: 0.4887\nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8101 - loss: 0.4956 - val_accuracy: 0.6871 - val_loss: 0.7197 - learning_rate: 3.1250e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8203 - loss: 0.4547 - val_accuracy: 0.7007 - val_loss: 0.7183 - learning_rate: 1.5625e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7932 - loss: 0.5509 - val_accuracy: 0.6939 - val_loss: 0.7156 - learning_rate: 1.5625e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7739 - loss: 0.5533 - val_accuracy: 0.7007 - val_loss: 0.7136 - learning_rate: 1.5625e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8037 - loss: 0.4885 - val_accuracy: 0.7075 - val_loss: 0.7120 - learning_rate: 1.5625e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8156 - loss: 0.5005 - val_accuracy: 0.7075 - val_loss: 0.7099 - learning_rate: 1.5625e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8120 - loss: 0.4907 - val_accuracy: 0.7075 - val_loss: 0.7083 - learning_rate: 1.5625e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8107 - loss: 0.4615 - val_accuracy: 0.7075 - val_loss: 0.7069 - learning_rate: 1.5625e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7847 - loss: 0.5171 - val_accuracy: 0.7075 - val_loss: 0.7067 - learning_rate: 1.5625e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8325 - loss: 0.4745 - val_accuracy: 0.7143 - val_loss: 0.7056 - learning_rate: 1.5625e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8020 - loss: 0.5473 - val_accuracy: 0.7279 - val_loss: 0.7045 - learning_rate: 1.5625e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7961 - loss: 0.5002 - val_accuracy: 0.7279 - val_loss: 0.7060 - learning_rate: 1.5625e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8050 - loss: 0.5429 - val_accuracy: 0.7279 - val_loss: 0.7052 - learning_rate: 1.5625e-05\nEpoch 47/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8206 - loss: 0.4819\nEpoch 47: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8190 - loss: 0.4813 - val_accuracy: 0.7279 - val_loss: 0.7053 - learning_rate: 1.5625e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8038 - loss: 0.4663 - val_accuracy: 0.7279 - val_loss: 0.7057 - learning_rate: 7.8125e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8005 - loss: 0.4772 - val_accuracy: 0.7347 - val_loss: 0.7062 - learning_rate: 7.8125e-06\nEpoch 50/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8252 - loss: 0.4438\nEpoch 50: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8212 - loss: 0.4504 - val_accuracy: 0.7347 - val_loss: 0.7064 - learning_rate: 7.8125e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8206 - loss: 0.4810 - val_accuracy: 0.7347 - val_loss: 0.7067 - learning_rate: 3.9063e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7833 - loss: 0.5461 - val_accuracy: 0.7347 - val_loss: 0.7084 - learning_rate: 3.9063e-06\nEpoch 53/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8252 - loss: 0.4527\nEpoch 53: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8234 - loss: 0.4571 - val_accuracy: 0.7347 - val_loss: 0.7088 - learning_rate: 3.9063e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8370 - loss: 0.4298 - val_accuracy: 0.7415 - val_loss: 0.7105 - learning_rate: 1.9531e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8355 - loss: 0.4524 - val_accuracy: 0.7347 - val_loss: 0.7111 - learning_rate: 1.9531e-06\nEpoch 56/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7802 - loss: 0.5386\nEpoch 56: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7835 - loss: 0.5342 - val_accuracy: 0.7347 - val_loss: 0.7125 - learning_rate: 1.9531e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8215 - loss: 0.4452 - val_accuracy: 0.7347 - val_loss: 0.7138 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8165 - loss: 0.4475 - val_accuracy: 0.7347 - val_loss: 0.7151 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8390 - loss: 0.4555 - val_accuracy: 0.7347 - val_loss: 0.7160 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8047 - loss: 0.5008 - val_accuracy: 0.7347 - val_loss: 0.7167 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8037 - loss: 0.4972 - val_accuracy: 0.7347 - val_loss: 0.7179 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8321 - loss: 0.4443 - val_accuracy: 0.7415 - val_loss: 0.7194 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7974 - loss: 0.4787 - val_accuracy: 0.7415 - val_loss: 0.7219 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8019 - loss: 0.4650 - val_accuracy: 0.7415 - val_loss: 0.7225 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8072 - loss: 0.4941 - val_accuracy: 0.7415 - val_loss: 0.7238 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8224 - loss: 0.4607 - val_accuracy: 0.7415 - val_loss: 0.7263 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7991 - loss: 0.4809 - val_accuracy: 0.7347 - val_loss: 0.7274 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8097 - loss: 0.5474 - val_accuracy: 0.7415 - val_loss: 0.7289 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8314 - loss: 0.4993 - val_accuracy: 0.7415 - val_loss: 0.7310 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8015 - loss: 0.5534 - val_accuracy: 0.7415 - val_loss: 0.7332 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8132 - loss: 0.4999 - val_accuracy: 0.7483 - val_loss: 0.7345 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8197 - loss: 0.4673 - val_accuracy: 0.7483 - val_loss: 0.7349 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8480 - loss: 0.4439 - val_accuracy: 0.7483 - val_loss: 0.7355 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8044 - loss: 0.4816 - val_accuracy: 0.7483 - val_loss: 0.7368 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8177 - loss: 0.4704 - val_accuracy: 0.7483 - val_loss: 0.7372 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7851 - loss: 0.5105 - val_accuracy: 0.7483 - val_loss: 0.7366 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8092 - loss: 0.4482 - val_accuracy: 0.7483 - val_loss: 0.7361 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7889 - loss: 0.5711 - val_accuracy: 0.7483 - val_loss: 0.7385 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8394 - loss: 0.4783 - val_accuracy: 0.7483 - val_loss: 0.7390 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8149 - loss: 0.4342 - val_accuracy: 0.7483 - val_loss: 0.7392 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8025 - loss: 0.5518 - val_accuracy: 0.7483 - val_loss: 0.7402 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8339 - loss: 0.4811 - val_accuracy: 0.7551 - val_loss: 0.7420 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7859 - loss: 0.5253 - val_accuracy: 0.7551 - val_loss: 0.7428 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8108 - loss: 0.4604 - val_accuracy: 0.7551 - val_loss: 0.7423 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7999 - loss: 0.5128 - val_accuracy: 0.7551 - val_loss: 0.7428 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7805 - loss: 0.5146 - val_accuracy: 0.7551 - val_loss: 0.7420 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8047 - loss: 0.4664 - val_accuracy: 0.7619 - val_loss: 0.7420 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7877 - loss: 0.5120 - val_accuracy: 0.7551 - val_loss: 0.7413 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8364 - loss: 0.4355 - val_accuracy: 0.7619 - val_loss: 0.7426 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8232 - loss: 0.5025 - val_accuracy: 0.7483 - val_loss: 0.7416 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8172 - loss: 0.4721 - val_accuracy: 0.7551 - val_loss: 0.7406 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7960 - loss: 0.5287 - val_accuracy: 0.7551 - val_loss: 0.7407 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7946 - loss: 0.5445 - val_accuracy: 0.7551 - val_loss: 0.7421 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8026 - loss: 0.5088 - val_accuracy: 0.7551 - val_loss: 0.7431 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8254 - loss: 0.4983 - val_accuracy: 0.7551 - val_loss: 0.7428 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8013 - loss: 0.4784 - val_accuracy: 0.7483 - val_loss: 0.7422 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8285 - loss: 0.4515 - val_accuracy: 0.7483 - val_loss: 0.7426 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8142 - loss: 0.4892 - val_accuracy: 0.7483 - val_loss: 0.7414 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7939 - loss: 0.4879 - val_accuracy: 0.7483 - val_loss: 0.7422 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8570 - loss: 0.4314 - val_accuracy: 0.7483 - val_loss: 0.7416 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.3591 - loss: 1.7037 - val_accuracy: 0.3425 - val_loss: 1.0569 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5140 - loss: 1.3189 - val_accuracy: 0.6027 - val_loss: 0.9067 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5535 - loss: 1.1108 - val_accuracy: 0.6370 - val_loss: 0.8571 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5927 - loss: 1.0606 - val_accuracy: 0.6027 - val_loss: 0.8753 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6119 - loss: 0.9596 - val_accuracy: 0.7055 - val_loss: 0.7372 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6427 - loss: 0.8907 - val_accuracy: 0.6849 - val_loss: 0.7710 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6687 - loss: 0.8035 - val_accuracy: 0.6575 - val_loss: 0.7723 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6685 - loss: 0.8645\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6692 - loss: 0.8557 - val_accuracy: 0.6370 - val_loss: 0.7583 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6443 - loss: 0.8307 - val_accuracy: 0.6849 - val_loss: 0.7119 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7545 - loss: 0.6937 - val_accuracy: 0.7397 - val_loss: 0.6856 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7293 - loss: 0.6747 - val_accuracy: 0.7397 - val_loss: 0.6819 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7261 - loss: 0.7377 - val_accuracy: 0.7260 - val_loss: 0.6632 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7318 - loss: 0.6887 - val_accuracy: 0.7192 - val_loss: 0.6812 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7507 - loss: 0.5896 - val_accuracy: 0.6986 - val_loss: 0.7167 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7852 - loss: 0.5686\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7842 - loss: 0.5736 - val_accuracy: 0.6849 - val_loss: 0.7334 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7732 - loss: 0.5750 - val_accuracy: 0.6986 - val_loss: 0.7147 - learning_rate: 2.5000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7446 - loss: 0.6143 - val_accuracy: 0.7123 - val_loss: 0.6833 - learning_rate: 2.5000e-04\nEpoch 18/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7659 - loss: 0.6164\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7625 - loss: 0.6253 - val_accuracy: 0.7329 - val_loss: 0.6669 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7679 - loss: 0.5788 - val_accuracy: 0.7329 - val_loss: 0.6683 - learning_rate: 1.2500e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7994 - loss: 0.5690 - val_accuracy: 0.7329 - val_loss: 0.6631 - learning_rate: 1.2500e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7723 - loss: 0.5450 - val_accuracy: 0.7329 - val_loss: 0.6600 - learning_rate: 1.2500e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7920 - loss: 0.5024 - val_accuracy: 0.7329 - val_loss: 0.6598 - learning_rate: 1.2500e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8004 - loss: 0.5188 - val_accuracy: 0.7329 - val_loss: 0.6630 - learning_rate: 1.2500e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8471 - loss: 0.4674 - val_accuracy: 0.7397 - val_loss: 0.6615 - learning_rate: 1.2500e-04\nEpoch 25/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8377 - loss: 0.4713\nEpoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8309 - loss: 0.4797 - val_accuracy: 0.7397 - val_loss: 0.6632 - learning_rate: 1.2500e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7806 - loss: 0.5461 - val_accuracy: 0.7260 - val_loss: 0.6638 - learning_rate: 6.2500e-05\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8233 - loss: 0.4584 - val_accuracy: 0.7260 - val_loss: 0.6594 - learning_rate: 6.2500e-05\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8291 - loss: 0.4596 - val_accuracy: 0.7329 - val_loss: 0.6548 - learning_rate: 6.2500e-05\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7698 - loss: 0.5655 - val_accuracy: 0.7397 - val_loss: 0.6470 - learning_rate: 6.2500e-05\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8268 - loss: 0.4529 - val_accuracy: 0.7397 - val_loss: 0.6403 - learning_rate: 6.2500e-05\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7986 - loss: 0.5202 - val_accuracy: 0.7329 - val_loss: 0.6368 - learning_rate: 6.2500e-05\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8107 - loss: 0.4516 - val_accuracy: 0.7260 - val_loss: 0.6400 - learning_rate: 6.2500e-05\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7990 - loss: 0.4960 - val_accuracy: 0.7329 - val_loss: 0.6395 - learning_rate: 6.2500e-05\nEpoch 34/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8047 - loss: 0.4442\nEpoch 34: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8042 - loss: 0.4505 - val_accuracy: 0.7329 - val_loss: 0.6380 - learning_rate: 6.2500e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7974 - loss: 0.5248 - val_accuracy: 0.7397 - val_loss: 0.6363 - learning_rate: 3.1250e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8199 - loss: 0.5075 - val_accuracy: 0.7329 - val_loss: 0.6348 - learning_rate: 3.1250e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7821 - loss: 0.5497 - val_accuracy: 0.7397 - val_loss: 0.6332 - learning_rate: 3.1250e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8252 - loss: 0.4840 - val_accuracy: 0.7397 - val_loss: 0.6312 - learning_rate: 3.1250e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8027 - loss: 0.4786 - val_accuracy: 0.7466 - val_loss: 0.6300 - learning_rate: 3.1250e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8230 - loss: 0.4328 - val_accuracy: 0.7466 - val_loss: 0.6280 - learning_rate: 3.1250e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7936 - loss: 0.4781 - val_accuracy: 0.7466 - val_loss: 0.6257 - learning_rate: 3.1250e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8068 - loss: 0.5043 - val_accuracy: 0.7397 - val_loss: 0.6251 - learning_rate: 3.1250e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8360 - loss: 0.4347 - val_accuracy: 0.7397 - val_loss: 0.6243 - learning_rate: 3.1250e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8321 - loss: 0.4649 - val_accuracy: 0.7534 - val_loss: 0.6256 - learning_rate: 3.1250e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8248 - loss: 0.5007 - val_accuracy: 0.7534 - val_loss: 0.6237 - learning_rate: 3.1250e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8185 - loss: 0.4641 - val_accuracy: 0.7534 - val_loss: 0.6237 - learning_rate: 3.1250e-05\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7867 - loss: 0.5156 - val_accuracy: 0.7534 - val_loss: 0.6209 - learning_rate: 3.1250e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8349 - loss: 0.4392 - val_accuracy: 0.7534 - val_loss: 0.6178 - learning_rate: 3.1250e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8231 - loss: 0.4921 - val_accuracy: 0.7603 - val_loss: 0.6176 - learning_rate: 3.1250e-05\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8126 - loss: 0.4847 - val_accuracy: 0.7671 - val_loss: 0.6189 - learning_rate: 3.1250e-05\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8362 - loss: 0.4306 - val_accuracy: 0.7671 - val_loss: 0.6201 - learning_rate: 3.1250e-05\nEpoch 52/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8716 - loss: 0.3887\nEpoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8676 - loss: 0.3904 - val_accuracy: 0.7671 - val_loss: 0.6238 - learning_rate: 3.1250e-05\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8074 - loss: 0.4556 - val_accuracy: 0.7808 - val_loss: 0.6256 - learning_rate: 1.5625e-05\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8360 - loss: 0.4357 - val_accuracy: 0.7808 - val_loss: 0.6261 - learning_rate: 1.5625e-05\nEpoch 55/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8120 - loss: 0.4750\nEpoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8139 - loss: 0.4706 - val_accuracy: 0.7808 - val_loss: 0.6272 - learning_rate: 1.5625e-05\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8369 - loss: 0.4608 - val_accuracy: 0.7740 - val_loss: 0.6269 - learning_rate: 7.8125e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8435 - loss: 0.4261 - val_accuracy: 0.7671 - val_loss: 0.6277 - learning_rate: 7.8125e-06\nEpoch 58/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8283 - loss: 0.4645\nEpoch 58: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8273 - loss: 0.4632 - val_accuracy: 0.7671 - val_loss: 0.6279 - learning_rate: 7.8125e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7961 - loss: 0.4896 - val_accuracy: 0.7671 - val_loss: 0.6284 - learning_rate: 3.9063e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8467 - loss: 0.4032 - val_accuracy: 0.7603 - val_loss: 0.6292 - learning_rate: 3.9063e-06\nEpoch 61/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8310 - loss: 0.4735\nEpoch 61: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8338 - loss: 0.4664 - val_accuracy: 0.7603 - val_loss: 0.6303 - learning_rate: 3.9063e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8329 - loss: 0.3906 - val_accuracy: 0.7671 - val_loss: 0.6317 - learning_rate: 1.9531e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8294 - loss: 0.4437 - val_accuracy: 0.7671 - val_loss: 0.6324 - learning_rate: 1.9531e-06\nEpoch 64/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8050 - loss: 0.4614\nEpoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8076 - loss: 0.4621 - val_accuracy: 0.7671 - val_loss: 0.6334 - learning_rate: 1.9531e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8287 - loss: 0.4926 - val_accuracy: 0.7671 - val_loss: 0.6334 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8484 - loss: 0.4037 - val_accuracy: 0.7671 - val_loss: 0.6339 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8228 - loss: 0.4399 - val_accuracy: 0.7671 - val_loss: 0.6353 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8061 - loss: 0.4683 - val_accuracy: 0.7671 - val_loss: 0.6359 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8301 - loss: 0.4670 - val_accuracy: 0.7671 - val_loss: 0.6365 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8491 - loss: 0.4114 - val_accuracy: 0.7671 - val_loss: 0.6360 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8185 - loss: 0.4447 - val_accuracy: 0.7603 - val_loss: 0.6365 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8478 - loss: 0.4317 - val_accuracy: 0.7603 - val_loss: 0.6360 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8109 - loss: 0.4287 - val_accuracy: 0.7603 - val_loss: 0.6360 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8533 - loss: 0.4165 - val_accuracy: 0.7603 - val_loss: 0.6370 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7994 - loss: 0.4852 - val_accuracy: 0.7603 - val_loss: 0.6373 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8391 - loss: 0.4029 - val_accuracy: 0.7603 - val_loss: 0.6374 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8215 - loss: 0.4988 - val_accuracy: 0.7603 - val_loss: 0.6379 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8190 - loss: 0.4895 - val_accuracy: 0.7603 - val_loss: 0.6394 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8526 - loss: 0.4212 - val_accuracy: 0.7603 - val_loss: 0.6398 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8073 - loss: 0.4788 - val_accuracy: 0.7603 - val_loss: 0.6393 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8611 - loss: 0.3838 - val_accuracy: 0.7603 - val_loss: 0.6393 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8682 - loss: 0.3896 - val_accuracy: 0.7603 - val_loss: 0.6406 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8458 - loss: 0.4259 - val_accuracy: 0.7603 - val_loss: 0.6412 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8180 - loss: 0.4302 - val_accuracy: 0.7671 - val_loss: 0.6409 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8188 - loss: 0.4429 - val_accuracy: 0.7603 - val_loss: 0.6407 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8345 - loss: 0.4735 - val_accuracy: 0.7603 - val_loss: 0.6405 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8084 - loss: 0.5005 - val_accuracy: 0.7603 - val_loss: 0.6403 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8130 - loss: 0.4542 - val_accuracy: 0.7603 - val_loss: 0.6413 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8407 - loss: 0.4074 - val_accuracy: 0.7603 - val_loss: 0.6420 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8253 - loss: 0.4938 - val_accuracy: 0.7603 - val_loss: 0.6416 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8343 - loss: 0.4649 - val_accuracy: 0.7603 - val_loss: 0.6413 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8382 - loss: 0.4181 - val_accuracy: 0.7603 - val_loss: 0.6416 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8230 - loss: 0.4490 - val_accuracy: 0.7603 - val_loss: 0.6416 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8085 - loss: 0.4653 - val_accuracy: 0.7603 - val_loss: 0.6406 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8549 - loss: 0.4012 - val_accuracy: 0.7603 - val_loss: 0.6410 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8248 - loss: 0.4852 - val_accuracy: 0.7603 - val_loss: 0.6414 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7940 - loss: 0.5039 - val_accuracy: 0.7603 - val_loss: 0.6421 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8228 - loss: 0.4285 - val_accuracy: 0.7603 - val_loss: 0.6417 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8481 - loss: 0.4112 - val_accuracy: 0.7603 - val_loss: 0.6420 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8318 - loss: 0.4338 - val_accuracy: 0.7603 - val_loss: 0.6422 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.3853 - loss: 1.6163 - val_accuracy: 0.6027 - val_loss: 0.9619 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5276 - loss: 1.3142 - val_accuracy: 0.6027 - val_loss: 0.9027 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5645 - loss: 1.1407 - val_accuracy: 0.5616 - val_loss: 0.9386 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5905 - loss: 1.0248 - val_accuracy: 0.6096 - val_loss: 0.9713 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6178 - loss: 0.9824 - val_accuracy: 0.6301 - val_loss: 0.8822 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6492 - loss: 0.7976 - val_accuracy: 0.6644 - val_loss: 0.8725 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6284 - loss: 0.8669 - val_accuracy: 0.6233 - val_loss: 0.9666 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7248 - loss: 0.7234 - val_accuracy: 0.6644 - val_loss: 0.8755 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6963 - loss: 0.7670 - val_accuracy: 0.6370 - val_loss: 0.8504 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7064 - loss: 0.6729 - val_accuracy: 0.6507 - val_loss: 0.7994 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7307 - loss: 0.7285 - val_accuracy: 0.6644 - val_loss: 0.7963 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7541 - loss: 0.6518 - val_accuracy: 0.6644 - val_loss: 0.7964 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7690 - loss: 0.6238 - val_accuracy: 0.6370 - val_loss: 0.9211 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7780 - loss: 0.6294\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7783 - loss: 0.6202 - val_accuracy: 0.6370 - val_loss: 0.8140 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7622 - loss: 0.6501 - val_accuracy: 0.6712 - val_loss: 0.7843 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7797 - loss: 0.5424 - val_accuracy: 0.6849 - val_loss: 0.7658 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7988 - loss: 0.4862 - val_accuracy: 0.6301 - val_loss: 0.8684 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8067 - loss: 0.4760 - val_accuracy: 0.6370 - val_loss: 0.9127 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7869 - loss: 0.4976\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7884 - loss: 0.4959 - val_accuracy: 0.6438 - val_loss: 0.8797 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8224 - loss: 0.4615 - val_accuracy: 0.6712 - val_loss: 0.8353 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7962 - loss: 0.4935 - val_accuracy: 0.6781 - val_loss: 0.8091 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8366 - loss: 0.4617\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8353 - loss: 0.4636 - val_accuracy: 0.6781 - val_loss: 0.8246 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8248 - loss: 0.4470 - val_accuracy: 0.6781 - val_loss: 0.8207 - learning_rate: 1.2500e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8115 - loss: 0.4910 - val_accuracy: 0.6712 - val_loss: 0.8265 - learning_rate: 1.2500e-04\nEpoch 25/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8270 - loss: 0.4620\nEpoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8280 - loss: 0.4596 - val_accuracy: 0.6644 - val_loss: 0.8407 - learning_rate: 1.2500e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8195 - loss: 0.4223 - val_accuracy: 0.6644 - val_loss: 0.8411 - learning_rate: 6.2500e-05\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8280 - loss: 0.3624 - val_accuracy: 0.6712 - val_loss: 0.8373 - learning_rate: 6.2500e-05\nEpoch 28/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8308 - loss: 0.4107\nEpoch 28: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8300 - loss: 0.4100 - val_accuracy: 0.6712 - val_loss: 0.8416 - learning_rate: 6.2500e-05\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8256 - loss: 0.4421 - val_accuracy: 0.6712 - val_loss: 0.8410 - learning_rate: 3.1250e-05\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8327 - loss: 0.4164 - val_accuracy: 0.6849 - val_loss: 0.8312 - learning_rate: 3.1250e-05\nEpoch 31/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8203 - loss: 0.4047\nEpoch 31: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8213 - loss: 0.4074 - val_accuracy: 0.6781 - val_loss: 0.8260 - learning_rate: 3.1250e-05\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8480 - loss: 0.4024 - val_accuracy: 0.6849 - val_loss: 0.8196 - learning_rate: 1.5625e-05\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8174 - loss: 0.4036 - val_accuracy: 0.6849 - val_loss: 0.8152 - learning_rate: 1.5625e-05\nEpoch 34/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8623 - loss: 0.3582\nEpoch 34: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8603 - loss: 0.3629 - val_accuracy: 0.6918 - val_loss: 0.8120 - learning_rate: 1.5625e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8521 - loss: 0.3833 - val_accuracy: 0.6986 - val_loss: 0.8058 - learning_rate: 7.8125e-06\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8561 - loss: 0.4002 - val_accuracy: 0.6986 - val_loss: 0.8038 - learning_rate: 7.8125e-06\nEpoch 37/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8443 - loss: 0.3958\nEpoch 37: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8453 - loss: 0.3974 - val_accuracy: 0.6918 - val_loss: 0.7974 - learning_rate: 7.8125e-06\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8264 - loss: 0.4379 - val_accuracy: 0.6918 - val_loss: 0.7958 - learning_rate: 3.9063e-06\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8322 - loss: 0.4433 - val_accuracy: 0.6918 - val_loss: 0.7910 - learning_rate: 3.9063e-06\nEpoch 40/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8164 - loss: 0.4376\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8156 - loss: 0.4380 - val_accuracy: 0.6849 - val_loss: 0.7895 - learning_rate: 3.9063e-06\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8494 - loss: 0.3594 - val_accuracy: 0.6781 - val_loss: 0.7857 - learning_rate: 1.9531e-06\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8434 - loss: 0.3903 - val_accuracy: 0.6849 - val_loss: 0.7854 - learning_rate: 1.9531e-06\nEpoch 43/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8430 - loss: 0.3836\nEpoch 43: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8437 - loss: 0.3877 - val_accuracy: 0.6849 - val_loss: 0.7819 - learning_rate: 1.9531e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8243 - loss: 0.4387 - val_accuracy: 0.6781 - val_loss: 0.7811 - learning_rate: 1.0000e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8506 - loss: 0.3905 - val_accuracy: 0.6781 - val_loss: 0.7789 - learning_rate: 1.0000e-06\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8374 - loss: 0.3842 - val_accuracy: 0.6781 - val_loss: 0.7784 - learning_rate: 1.0000e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8612 - loss: 0.3850 - val_accuracy: 0.6918 - val_loss: 0.7759 - learning_rate: 1.0000e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8563 - loss: 0.3858 - val_accuracy: 0.6918 - val_loss: 0.7741 - learning_rate: 1.0000e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8260 - loss: 0.4294 - val_accuracy: 0.6986 - val_loss: 0.7703 - learning_rate: 1.0000e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8064 - loss: 0.4505 - val_accuracy: 0.6986 - val_loss: 0.7688 - learning_rate: 1.0000e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8099 - loss: 0.5183 - val_accuracy: 0.6986 - val_loss: 0.7675 - learning_rate: 1.0000e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8248 - loss: 0.4604 - val_accuracy: 0.6986 - val_loss: 0.7678 - learning_rate: 1.0000e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8176 - loss: 0.4654 - val_accuracy: 0.7055 - val_loss: 0.7676 - learning_rate: 1.0000e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8402 - loss: 0.4465 - val_accuracy: 0.7055 - val_loss: 0.7678 - learning_rate: 1.0000e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8293 - loss: 0.4411 - val_accuracy: 0.7123 - val_loss: 0.7677 - learning_rate: 1.0000e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8656 - loss: 0.3926 - val_accuracy: 0.7192 - val_loss: 0.7694 - learning_rate: 1.0000e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8324 - loss: 0.3942 - val_accuracy: 0.7192 - val_loss: 0.7683 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8573 - loss: 0.3729 - val_accuracy: 0.7192 - val_loss: 0.7681 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8324 - loss: 0.4046 - val_accuracy: 0.7192 - val_loss: 0.7684 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8123 - loss: 0.4624 - val_accuracy: 0.7123 - val_loss: 0.7697 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8498 - loss: 0.3930 - val_accuracy: 0.7123 - val_loss: 0.7701 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8517 - loss: 0.3720 - val_accuracy: 0.7123 - val_loss: 0.7718 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8209 - loss: 0.4363 - val_accuracy: 0.7123 - val_loss: 0.7724 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8664 - loss: 0.3851 - val_accuracy: 0.7123 - val_loss: 0.7713 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8332 - loss: 0.4081 - val_accuracy: 0.7123 - val_loss: 0.7707 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8207 - loss: 0.4206 - val_accuracy: 0.7192 - val_loss: 0.7721 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8323 - loss: 0.4252 - val_accuracy: 0.7192 - val_loss: 0.7713 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8316 - loss: 0.4076 - val_accuracy: 0.7192 - val_loss: 0.7728 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8793 - loss: 0.3575 - val_accuracy: 0.7192 - val_loss: 0.7726 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8177 - loss: 0.4667 - val_accuracy: 0.7192 - val_loss: 0.7723 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8323 - loss: 0.3912 - val_accuracy: 0.7192 - val_loss: 0.7745 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8354 - loss: 0.4016 - val_accuracy: 0.7192 - val_loss: 0.7727 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8223 - loss: 0.4802 - val_accuracy: 0.7192 - val_loss: 0.7725 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8545 - loss: 0.3965 - val_accuracy: 0.7192 - val_loss: 0.7719 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8230 - loss: 0.4548 - val_accuracy: 0.7192 - val_loss: 0.7697 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8518 - loss: 0.4023 - val_accuracy: 0.7192 - val_loss: 0.7704 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8469 - loss: 0.3780 - val_accuracy: 0.7192 - val_loss: 0.7712 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8012 - loss: 0.4417 - val_accuracy: 0.7123 - val_loss: 0.7725 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8298 - loss: 0.4154 - val_accuracy: 0.7123 - val_loss: 0.7715 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8597 - loss: 0.3735 - val_accuracy: 0.7123 - val_loss: 0.7712 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8383 - loss: 0.4303 - val_accuracy: 0.7123 - val_loss: 0.7718 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8319 - loss: 0.4039 - val_accuracy: 0.7123 - val_loss: 0.7735 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8353 - loss: 0.4258 - val_accuracy: 0.7123 - val_loss: 0.7738 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8401 - loss: 0.4121 - val_accuracy: 0.7123 - val_loss: 0.7726 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8553 - loss: 0.4074 - val_accuracy: 0.7123 - val_loss: 0.7737 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8170 - loss: 0.4849 - val_accuracy: 0.7123 - val_loss: 0.7751 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8410 - loss: 0.4267 - val_accuracy: 0.6986 - val_loss: 0.7758 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8259 - loss: 0.4302 - val_accuracy: 0.6986 - val_loss: 0.7776 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8145 - loss: 0.4507 - val_accuracy: 0.6986 - val_loss: 0.7769 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8383 - loss: 0.4271 - val_accuracy: 0.6986 - val_loss: 0.7784 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8479 - loss: 0.4367 - val_accuracy: 0.6986 - val_loss: 0.7760 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7987 - loss: 0.4789 - val_accuracy: 0.6986 - val_loss: 0.7771 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8498 - loss: 0.4193 - val_accuracy: 0.6986 - val_loss: 0.7794 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8018 - loss: 0.4573 - val_accuracy: 0.6986 - val_loss: 0.7790 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8400 - loss: 0.3958 - val_accuracy: 0.6986 - val_loss: 0.7789 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8545 - loss: 0.4180 - val_accuracy: 0.6986 - val_loss: 0.7774 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8377 - loss: 0.4378 - val_accuracy: 0.6986 - val_loss: 0.7767 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8375 - loss: 0.3788 - val_accuracy: 0.6986 - val_loss: 0.7774 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8392 - loss: 0.4429 - val_accuracy: 0.7055 - val_loss: 0.7787 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8250 - loss: 0.4414 - val_accuracy: 0.7055 - val_loss: 0.7783 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.3782 - loss: 1.7134 - val_accuracy: 0.5753 - val_loss: 1.0129 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5245 - loss: 1.2524 - val_accuracy: 0.2740 - val_loss: 1.1991 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5457 - loss: 1.1509 - val_accuracy: 0.3014 - val_loss: 1.1320 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5818 - loss: 1.0510 - val_accuracy: 0.6027 - val_loss: 0.9213 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6654 - loss: 0.8676 - val_accuracy: 0.6507 - val_loss: 0.8663 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6539 - loss: 0.8861 - val_accuracy: 0.5822 - val_loss: 0.9060 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6552 - loss: 0.9300 - val_accuracy: 0.6096 - val_loss: 1.0139 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6877 - loss: 0.7833\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6877 - loss: 0.7813 - val_accuracy: 0.6644 - val_loss: 0.8736 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7197 - loss: 0.7718 - val_accuracy: 0.6438 - val_loss: 0.7898 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7200 - loss: 0.7671 - val_accuracy: 0.6233 - val_loss: 0.8585 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7243 - loss: 0.7627 - val_accuracy: 0.6438 - val_loss: 0.7807 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7291 - loss: 0.7307 - val_accuracy: 0.6986 - val_loss: 0.7179 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7559 - loss: 0.6365 - val_accuracy: 0.6644 - val_loss: 0.6877 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7700 - loss: 0.6182 - val_accuracy: 0.6986 - val_loss: 0.6825 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7249 - loss: 0.6475 - val_accuracy: 0.6986 - val_loss: 0.6981 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7875 - loss: 0.6105 - val_accuracy: 0.6781 - val_loss: 0.6963 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7548 - loss: 0.6026\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7560 - loss: 0.6056 - val_accuracy: 0.6849 - val_loss: 0.6913 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7589 - loss: 0.5674 - val_accuracy: 0.7192 - val_loss: 0.6787 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7754 - loss: 0.5948 - val_accuracy: 0.7397 - val_loss: 0.6693 - learning_rate: 2.5000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7925 - loss: 0.5384 - val_accuracy: 0.7466 - val_loss: 0.6687 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7907 - loss: 0.5646 - val_accuracy: 0.7329 - val_loss: 0.6579 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7997 - loss: 0.5216 - val_accuracy: 0.7260 - val_loss: 0.6441 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7755 - loss: 0.5425 - val_accuracy: 0.7260 - val_loss: 0.6449 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8037 - loss: 0.4930 - val_accuracy: 0.7397 - val_loss: 0.6555 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8182 - loss: 0.4855\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8162 - loss: 0.4883 - val_accuracy: 0.7192 - val_loss: 0.6473 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8027 - loss: 0.5534 - val_accuracy: 0.7192 - val_loss: 0.6477 - learning_rate: 1.2500e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7707 - loss: 0.5963 - val_accuracy: 0.7123 - val_loss: 0.6545 - learning_rate: 1.2500e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7954 - loss: 0.5150 - val_accuracy: 0.7123 - val_loss: 0.6402 - learning_rate: 1.2500e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7840 - loss: 0.5244 - val_accuracy: 0.7397 - val_loss: 0.6238 - learning_rate: 1.2500e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8033 - loss: 0.4692 - val_accuracy: 0.7397 - val_loss: 0.6131 - learning_rate: 1.2500e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8665 - loss: 0.3902 - val_accuracy: 0.7466 - val_loss: 0.6149 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8084 - loss: 0.4882 - val_accuracy: 0.7466 - val_loss: 0.6147 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8358 - loss: 0.3780\nEpoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8344 - loss: 0.3871 - val_accuracy: 0.7466 - val_loss: 0.6208 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8558 - loss: 0.3817 - val_accuracy: 0.7534 - val_loss: 0.6145 - learning_rate: 6.2500e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8575 - loss: 0.3915 - val_accuracy: 0.7740 - val_loss: 0.6115 - learning_rate: 6.2500e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8811 - loss: 0.3345 - val_accuracy: 0.7671 - val_loss: 0.6098 - learning_rate: 6.2500e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8522 - loss: 0.3987 - val_accuracy: 0.7671 - val_loss: 0.6078 - learning_rate: 6.2500e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8247 - loss: 0.3860 - val_accuracy: 0.7740 - val_loss: 0.6016 - learning_rate: 6.2500e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8048 - loss: 0.4604 - val_accuracy: 0.7740 - val_loss: 0.5995 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8378 - loss: 0.4259 - val_accuracy: 0.7671 - val_loss: 0.5952 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8496 - loss: 0.3893 - val_accuracy: 0.7740 - val_loss: 0.5939 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8544 - loss: 0.4062 - val_accuracy: 0.7671 - val_loss: 0.5947 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8549 - loss: 0.3680 - val_accuracy: 0.7671 - val_loss: 0.5976 - learning_rate: 6.2500e-05\nEpoch 44/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8342 - loss: 0.4119\nEpoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8383 - loss: 0.4086 - val_accuracy: 0.7603 - val_loss: 0.6047 - learning_rate: 6.2500e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8551 - loss: 0.4163 - val_accuracy: 0.7603 - val_loss: 0.6091 - learning_rate: 3.1250e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8610 - loss: 0.3604 - val_accuracy: 0.7603 - val_loss: 0.6134 - learning_rate: 3.1250e-05\nEpoch 47/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8312 - loss: 0.4337\nEpoch 47: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8355 - loss: 0.4275 - val_accuracy: 0.7671 - val_loss: 0.6110 - learning_rate: 3.1250e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8612 - loss: 0.3935 - val_accuracy: 0.7671 - val_loss: 0.6093 - learning_rate: 1.5625e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8179 - loss: 0.4376 - val_accuracy: 0.7671 - val_loss: 0.6075 - learning_rate: 1.5625e-05\nEpoch 50/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8580 - loss: 0.3788\nEpoch 50: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8575 - loss: 0.3843 - val_accuracy: 0.7603 - val_loss: 0.6071 - learning_rate: 1.5625e-05\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8426 - loss: 0.3627 - val_accuracy: 0.7671 - val_loss: 0.6063 - learning_rate: 7.8125e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8377 - loss: 0.4249 - val_accuracy: 0.7671 - val_loss: 0.6055 - learning_rate: 7.8125e-06\nEpoch 53/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8493 - loss: 0.3633\nEpoch 53: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8476 - loss: 0.3703 - val_accuracy: 0.7671 - val_loss: 0.6045 - learning_rate: 7.8125e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8218 - loss: 0.4498 - val_accuracy: 0.7671 - val_loss: 0.6051 - learning_rate: 3.9063e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8300 - loss: 0.4089 - val_accuracy: 0.7671 - val_loss: 0.6045 - learning_rate: 3.9063e-06\nEpoch 56/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8698 - loss: 0.3551\nEpoch 56: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8699 - loss: 0.3580 - val_accuracy: 0.7671 - val_loss: 0.6046 - learning_rate: 3.9063e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8551 - loss: 0.3680 - val_accuracy: 0.7740 - val_loss: 0.6046 - learning_rate: 1.9531e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8584 - loss: 0.3868 - val_accuracy: 0.7808 - val_loss: 0.6054 - learning_rate: 1.9531e-06\nEpoch 59/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8504 - loss: 0.3872\nEpoch 59: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8509 - loss: 0.3879 - val_accuracy: 0.7808 - val_loss: 0.6069 - learning_rate: 1.9531e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7985 - loss: 0.4336 - val_accuracy: 0.7808 - val_loss: 0.6064 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8410 - loss: 0.3763 - val_accuracy: 0.7740 - val_loss: 0.6065 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8602 - loss: 0.3786 - val_accuracy: 0.7740 - val_loss: 0.6075 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8659 - loss: 0.3555 - val_accuracy: 0.7740 - val_loss: 0.6082 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8508 - loss: 0.3919 - val_accuracy: 0.7740 - val_loss: 0.6093 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8479 - loss: 0.3629 - val_accuracy: 0.7740 - val_loss: 0.6095 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8612 - loss: 0.3803 - val_accuracy: 0.7740 - val_loss: 0.6102 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8717 - loss: 0.3700 - val_accuracy: 0.7740 - val_loss: 0.6108 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8393 - loss: 0.3929 - val_accuracy: 0.7740 - val_loss: 0.6106 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8449 - loss: 0.4173 - val_accuracy: 0.7740 - val_loss: 0.6113 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8701 - loss: 0.3741 - val_accuracy: 0.7740 - val_loss: 0.6123 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8821 - loss: 0.3597 - val_accuracy: 0.7740 - val_loss: 0.6130 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8623 - loss: 0.3959 - val_accuracy: 0.7740 - val_loss: 0.6139 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8659 - loss: 0.3596 - val_accuracy: 0.7740 - val_loss: 0.6141 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8496 - loss: 0.3735 - val_accuracy: 0.7740 - val_loss: 0.6158 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8678 - loss: 0.3579 - val_accuracy: 0.7740 - val_loss: 0.6172 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8327 - loss: 0.4562 - val_accuracy: 0.7740 - val_loss: 0.6175 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8339 - loss: 0.4099 - val_accuracy: 0.7740 - val_loss: 0.6186 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8771 - loss: 0.3310 - val_accuracy: 0.7740 - val_loss: 0.6186 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8525 - loss: 0.3684 - val_accuracy: 0.7740 - val_loss: 0.6191 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8478 - loss: 0.3369 - val_accuracy: 0.7740 - val_loss: 0.6198 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8715 - loss: 0.3720 - val_accuracy: 0.7740 - val_loss: 0.6195 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8615 - loss: 0.3459 - val_accuracy: 0.7740 - val_loss: 0.6193 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8401 - loss: 0.4228 - val_accuracy: 0.7740 - val_loss: 0.6191 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8937 - loss: 0.3014 - val_accuracy: 0.7740 - val_loss: 0.6194 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8472 - loss: 0.3865 - val_accuracy: 0.7740 - val_loss: 0.6192 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8451 - loss: 0.3553 - val_accuracy: 0.7740 - val_loss: 0.6190 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8563 - loss: 0.3792 - val_accuracy: 0.7740 - val_loss: 0.6200 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8427 - loss: 0.4112 - val_accuracy: 0.7740 - val_loss: 0.6205 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8449 - loss: 0.3942 - val_accuracy: 0.7740 - val_loss: 0.6203 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8566 - loss: 0.3663 - val_accuracy: 0.7740 - val_loss: 0.6203 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8586 - loss: 0.3761 - val_accuracy: 0.7740 - val_loss: 0.6196 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8215 - loss: 0.4201 - val_accuracy: 0.7740 - val_loss: 0.6191 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8470 - loss: 0.3948 - val_accuracy: 0.7740 - val_loss: 0.6193 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8562 - loss: 0.3839 - val_accuracy: 0.7740 - val_loss: 0.6179 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8471 - loss: 0.3585 - val_accuracy: 0.7740 - val_loss: 0.6180 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8636 - loss: 0.3815 - val_accuracy: 0.7740 - val_loss: 0.6182 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8409 - loss: 0.3864 - val_accuracy: 0.7740 - val_loss: 0.6190 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8803 - loss: 0.3611 - val_accuracy: 0.7740 - val_loss: 0.6196 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8290 - loss: 0.3909 - val_accuracy: 0.7740 - val_loss: 0.6191 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8453 - loss: 0.3725 - val_accuracy: 0.7740 - val_loss: 0.6197 - learning_rate: 1.0000e-06\nMean Accuracy: 0.7432\n","output_type":"stream"}],"execution_count":345}]}