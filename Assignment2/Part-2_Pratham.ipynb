{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316566,"sourceType":"datasetVersion","datasetId":4245661}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Optional: Improves WordNet performance\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:32.048358Z","iopub.execute_input":"2025-03-13T18:51:32.048734Z","iopub.status.idle":"2025-03-13T18:51:32.069176Z","shell.execute_reply.started":"2025-03-13T18:51:32.048705Z","shell.execute_reply":"2025-03-13T18:51:32.068056Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\n","output_type":"stream"}],"execution_count":315},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:32.070640Z","iopub.execute_input":"2025-03-13T18:51:32.070975Z","iopub.status.idle":"2025-03-13T18:51:32.086307Z","shell.execute_reply.started":"2025-03-13T18:51:32.070918Z","shell.execute_reply":"2025-03-13T18:51:32.085078Z"}},"outputs":[],"execution_count":316},{"cell_type":"code","source":"import nltk\nimport subprocess\n\nnltk.download('wordnet', download_dir='/kaggle/working/')\nnltk.download('omw-1.4', download_dir='/kaggle/working/')\n\ncommand = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\nsubprocess.run(command.split())\n\nnltk.data.path.append('/kaggle/working/')\n\nlemmatizer = WordNetLemmatizer()\n\ntrain_df['Sentiment'] = train_df['Sentiment'].astype(str).str.strip().str.lower().apply(lemmatizer.lemmatize)\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:32.089153Z","iopub.execute_input":"2025-03-13T18:51:32.089479Z","iopub.status.idle":"2025-03-13T18:51:32.195492Z","shell.execute_reply.started":"2025-03-13T18:51:32.089452Z","shell.execute_reply":"2025-03-13T18:51:32.194410Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /kaggle/working/...\n[nltk_data]   Package omw-1.4 is already up-to-date!\nSentiment\npositive                45\njoy                     44\nexcitement              37\ncontentment             19\nneutral                 18\ngratitude               18\ncuriosity               16\nserenity                15\nhappy                   14\nnostalgia               11\ndespair                 11\ngrief                    9\nawe                      9\nsad                      9\nhopeful                  9\nloneliness               9\nembarrassed              8\nacceptance               8\nconfusion                8\neuphoria                 7\nelation                  7\nenthusiasm               7\npride                    7\ndetermination            7\nregret                   6\nfrustration              6\nambivalence              6\nmelancholy               6\nnumbness                 6\nplayful                  6\nindifference             6\nbad                      6\nhate                     6\nsurprise                 6\ninspiration              6\nbitterness               5\nfrustrated               5\nbetrayal                 5\nhope                     5\nhappiness                5\ndisgust                  5\ninspired                 5\nempowerment              5\nproud                    4\ngrateful                 4\nthrill                   4\noverwhelmed              4\ncompassionate            4\nreflection               4\nenchantment              4\ndesolation               4\nnegative                 4\nadmiration               4\nboredom                  4\ncalmness                 4\nreverence                4\nfulfillment              4\ncompassion               4\narousal                  4\ntenderness               4\namusement                3\nanticipation             3\nenvious                  3\ndismissive               3\nbitter                   3\nheartbreak               3\nadventure                3\ndevastated               3\nsatisfaction             3\nwonder                   3\naccomplishment           3\ncreativity               3\nharmony                  3\nkind                     3\njealous                  3\nlove                     3\nfearful                  3\nconfident                3\nfree-spirited            3\nresentment               3\nempathetic               3\nshame                    3\njealousy                 3\nsorrow                   2\nexploration              2\ncaptivation              2\ntranquility              2\nradiance                 2\nloss                     2\nmischievous              2\nrejuvenation             2\nresilience               2\nemotion                  2\ndisappointment           2\nisolation                2\ncoziness                 2\nwhimsy                   2\nintimidation             2\ncontemplation            2\nanxiety                  2\nhelplessness             2\nenvy                     2\nanger                    2\nzest                     2\nyearning                 2\napprehensive             2\nfear                     2\nsadness                  2\nenjoyment                2\nadoration                2\naffection                2\ndisappointed             2\nengagement               1\nobstacle                 1\nheartwarming             1\ntriumph                  1\nsuspense                 1\ntouched                  1\nrunway creativity        1\nsympathy                 1\niconic                   1\nconnection               1\nhypnotic                 1\ncolorful                 1\necstasy                  1\ncharm                    1\njourney                  1\npressure                 1\nocean's freedom          1\nrelief                   1\ncreative inspiration     1\ncelestial wonder         1\nnature's beauty          1\nthrilling journey        1\nwinter magic             1\nculinary adventure       1\nmesmerizing              1\nvibrancy                 1\nimagination              1\nenvisioning history      1\njoy in baking            1\nbreakthrough             1\nsolace                   1\ncelebration              1\nmiscalculation           1\nrenewed effort           1\nwhispers of the past     1\nchallenge                1\nmindfulness              1\nenergy                   1\nmelodic                  1\nmotivation               1\nculinaryodyssey          1\nartisticburst            1\nadrenaline               1\ndazzle                   1\nfreedom                  1\ninnerjourney             1\nfestivejoy               1\njoyfulreunion            1\ngrandeur                 1\nblessed                  1\nappreciation             1\nconfidence               1\nwonderment               1\noptimism                 1\npensive                  1\nplayfuljoy               1\nelegance                 1\nimmersion                1\nspark                    1\nmarvel                   1\noverjoyed                1\ndreamchaser              1\nromance                  1\namazement                1\nsuccess                  1\nfriendship               1\nkindness                 1\npositivity               1\nsolitude                 1\nheartache                1\nruin                     1\ndesperation              1\ndarkness                 1\nexhaustion               1\nlostlove                 1\nemotionalstorm           1\nsuffering                1\nbittersweet              1\nintrigue                 1\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":317},{"cell_type":"code","source":"unique_values = set()\nunique_values.update(train_df['Sentiment'])\nunique_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:32.197025Z","iopub.execute_input":"2025-03-13T18:51:32.197408Z","iopub.status.idle":"2025-03-13T18:51:32.209312Z","shell.execute_reply.started":"2025-03-13T18:51:32.197366Z","shell.execute_reply":"2025-03-13T18:51:32.207741Z"}},"outputs":[{"execution_count":318,"output_type":"execute_result","data":{"text/plain":"{'acceptance',\n 'accomplishment',\n 'admiration',\n 'adoration',\n 'adrenaline',\n 'adventure',\n 'affection',\n 'amazement',\n 'ambivalence',\n 'amusement',\n 'anger',\n 'anticipation',\n 'anxiety',\n 'appreciation',\n 'apprehensive',\n 'arousal',\n 'artisticburst',\n 'awe',\n 'bad',\n 'betrayal',\n 'bitter',\n 'bitterness',\n 'bittersweet',\n 'blessed',\n 'boredom',\n 'breakthrough',\n 'calmness',\n 'captivation',\n 'celebration',\n 'celestial wonder',\n 'challenge',\n 'charm',\n 'colorful',\n 'compassion',\n 'compassionate',\n 'confidence',\n 'confident',\n 'confusion',\n 'connection',\n 'contemplation',\n 'contentment',\n 'coziness',\n 'creative inspiration',\n 'creativity',\n 'culinary adventure',\n 'culinaryodyssey',\n 'curiosity',\n 'darkness',\n 'dazzle',\n 'desolation',\n 'despair',\n 'desperation',\n 'determination',\n 'devastated',\n 'disappointed',\n 'disappointment',\n 'disgust',\n 'dismissive',\n 'dreamchaser',\n 'ecstasy',\n 'elation',\n 'elegance',\n 'embarrassed',\n 'emotion',\n 'emotionalstorm',\n 'empathetic',\n 'empowerment',\n 'enchantment',\n 'energy',\n 'engagement',\n 'enjoyment',\n 'enthusiasm',\n 'envious',\n 'envisioning history',\n 'envy',\n 'euphoria',\n 'excitement',\n 'exhaustion',\n 'exploration',\n 'fear',\n 'fearful',\n 'festivejoy',\n 'free-spirited',\n 'freedom',\n 'friendship',\n 'frustrated',\n 'frustration',\n 'fulfillment',\n 'grandeur',\n 'grateful',\n 'gratitude',\n 'grief',\n 'happiness',\n 'happy',\n 'harmony',\n 'hate',\n 'heartache',\n 'heartbreak',\n 'heartwarming',\n 'helplessness',\n 'hope',\n 'hopeful',\n 'hypnotic',\n 'iconic',\n 'imagination',\n 'immersion',\n 'indifference',\n 'innerjourney',\n 'inspiration',\n 'inspired',\n 'intimidation',\n 'intrigue',\n 'isolation',\n 'jealous',\n 'jealousy',\n 'journey',\n 'joy',\n 'joy in baking',\n 'joyfulreunion',\n 'kind',\n 'kindness',\n 'loneliness',\n 'loss',\n 'lostlove',\n 'love',\n 'marvel',\n 'melancholy',\n 'melodic',\n 'mesmerizing',\n 'mindfulness',\n 'miscalculation',\n 'mischievous',\n 'motivation',\n \"nature's beauty\",\n 'negative',\n 'neutral',\n 'nostalgia',\n 'numbness',\n 'obstacle',\n \"ocean's freedom\",\n 'optimism',\n 'overjoyed',\n 'overwhelmed',\n 'pensive',\n 'playful',\n 'playfuljoy',\n 'positive',\n 'positivity',\n 'pressure',\n 'pride',\n 'proud',\n 'radiance',\n 'reflection',\n 'regret',\n 'rejuvenation',\n 'relief',\n 'renewed effort',\n 'resentment',\n 'resilience',\n 'reverence',\n 'romance',\n 'ruin',\n 'runway creativity',\n 'sad',\n 'sadness',\n 'satisfaction',\n 'serenity',\n 'shame',\n 'solace',\n 'solitude',\n 'sorrow',\n 'spark',\n 'success',\n 'suffering',\n 'surprise',\n 'suspense',\n 'sympathy',\n 'tenderness',\n 'thrill',\n 'thrilling journey',\n 'touched',\n 'tranquility',\n 'triumph',\n 'vibrancy',\n 'whimsy',\n 'whispers of the past',\n 'winter magic',\n 'wonder',\n 'wonderment',\n 'yearning',\n 'zest'}"},"metadata":{}}],"execution_count":318},{"cell_type":"code","source":"import spacy\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nnlp = spacy.load(\"en_core_web_md\")\n\nref_words = {\n    \"Positive\": \"positive\",\n    \"Negative\": \"negative\",\n    \"Neutral\": \"neutral\"\n}\n\nref_vectors = {category: nlp(word).vector for category, word in ref_words.items()}\n\ndef assign_sentiment_category(sentiment):\n    word_vector = nlp(sentiment).vector.reshape(1, -1)\n    \n    similarities = {}\n    for category, ref_vec in ref_vectors.items():\n        ref_vec = ref_vec.reshape(1, -1)\n        sim = cosine_similarity(word_vector, ref_vec)[0][0]\n        similarities[category] = sim\n\n    return max(similarities, key=similarities.get)\n\ntrain_df['Sentiment'] = train_df['Sentiment'].apply(assign_sentiment_category)\n\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:32.211058Z","iopub.execute_input":"2025-03-13T18:51:32.211488Z","iopub.status.idle":"2025-03-13T18:51:39.880632Z","shell.execute_reply.started":"2025-03-13T18:51:32.211446Z","shell.execute_reply":"2025-03-13T18:51:39.879544Z"}},"outputs":[{"name":"stdout","text":"Sentiment\nPositive    364\nNegative    290\nNeutral      78\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":319},{"cell_type":"code","source":"!pip install nltk  \n\nimport nltk\nnltk.download('stopwords')  \nfrom nltk.corpus import stopwords\nimport string\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom nltk.stem import PorterStemmer\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer()\n\nemoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"  \n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F700-\\U0001F77F\" \n                           u\"\\U0001F780-\\U0001F7FF\"  \n                           u\"\\U0001F800-\\U0001F8FF\" \n                           u\"\\U0001F900-\\U0001F9FF\" \n                           u\"\\U0001FA00-\\U0001FA6F\" \n                           u\"\\U0001FA70-\\U0001FAFF\" \n                           u\"\\U00002702-\\U000027B0\" \n                           u\"\\U000024C2-\\U0001F251\" \n                           \"]+\", flags=re.UNICODE)\n\ndef split_and_remove_stopwords(text):\n    text = emoji_pattern.sub(r'', text)\n    tokens = text.split()\n\n    filtered_tokens = [\n        stemmer.stem(lemmatizer.lemmatize(word.lower().rstrip(string.punctuation)))\n        for word in tokens if stemmer.stem(word.lower().rstrip(string.punctuation)) not in stop_words\n    ]\n\n    return filtered_tokens\n\ntrain_df['Text'] = train_df['Text'].apply(split_and_remove_stopwords)\n\nprint(train_df['Text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T18:51:39.881761Z","iopub.execute_input":"2025-03-13T18:51:39.882123Z","iopub.status.idle":"2025-03-13T18:51:44.814667Z","shell.execute_reply.started":"2025-03-13T18:51:39.882083Z","shell.execute_reply":"2025-03-13T18:51:44.812922Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n0                             [enjoy, beauti, day, park]\n1                      [traffic, wa, terribl, thi, morn]\n2                                [finish, amaz, workout]\n3                       [excit, upcom, weekend, getaway]\n4                     [tri, new, recip, dinner, tonight]\n5                      [feel, grate, littl, thing, life]\n6          [raini, day, call, cozi, blanket, hot, cocoa]\n7                        [new, movi, releas, must-watch]\n8                        [polit, discuss, heat, timelin]\n9                       [miss, summer, vibe, beach, day]\n10                     [publish, new, blog, post, check]\n11                           [feel, bit, weather, today]\n12                          [explor, city', hidden, gem]\n13                           [new, year, new, fit, goal]\n14                         [technolog, chang, way, live]\n15                          [reflect, past, look, ahead]\n16                          [adopt, cute, furri, friend]\n17                   [late-night, game, session, friend]\n18                         [attend, virtual, confer, ai]\n19                        [winter, blue, got, feel, low]\n20                       [sip, coffe, enjoy, good, book]\n21                     [explor, world, virtual, realiti]\n22                     [product, day, tick, to-do, list]\n23                   [finish, challeng, workout, routin]\n24                              [celebr, mileston, work]\n25                              [sunday, brunch, friend]\n26                 [learn, new, languag, person, growth]\n27                             [quiet, even, good, book]\n28                     [reflect, import, mental, health]\n29                                [new, paint, progress]\n30           [weekend, road, trip, explor, scenic, view]\n31                      [enjoy, cup, tea, watch, sunset]\n32                      [code, new, project, enthusiasm]\n33                      [feel, inspir, attend, workshop]\n34                     [winter, sport, day, local, park]\n35                 [qualiti, time, famili, thi, weekend]\n36               [attend, live, music, concert, tonight]\n37                                [practic, mind, medit]\n38                            [tri, new, dessert, recip]\n39                      [excit, upcom, game, tournament]\n40                        [plan, garden, makeov, spring]\n41                  [celebr, friend', birthday, tonight]\n42                      [feel, accomplish, product, day]\n43                              [cozi, even, good, movi]\n44           [explor, local, art, galleri, thi, weekend]\n45                  [new, book, releas, favorit, author]\n46                    [attend, virtual, realiti, meetup]\n47                              [reflect, beauti, natur]\n48                    [cook, special, dinner, love, one]\n49                         [feel, optimist, week, ahead]\n50                 [start, new, fit, challeng, tomorrow]\n51                   [sunday, bike, ride, scenic, trail]\n52            [can't, believ, injustic, happen, societi]\n53             [feel, sens, fear, watch, thriller, movi]\n54              [heartbroken, hear, news, natur, disast]\n55                     [state, world', environ, disgust]\n56             [pure, happi, celebr, love, one', achiev]\n57        [laughter, best, medicine—enjoy, comedi, show]\n58                   [share, love, posit, vibe, everyon]\n59                          [amus, incid, brighten, day]\n60                       [enjoy, quiet, even, book, tea]\n61              [admir, beauti, natur, dure, peac, hike]\n62                       [send, affection, vibe, follow]\n63                   [experienc, awe, breathtak, sunset]\n64                  [disappoint, servic, local, restaur]\n65                    [surpris, gift, friend, made, day]\n66                [find, accept, midst, life', challeng]\n67                           [overflow, ador, ador, pet]\n68               [anticip, thrill, adventur, come, week]\n69               [bitter, experi, turn, valuabl, lesson]\n70                        [find, calm, midst, busi, day]\n71                   [confus, cloud, mind, navig, decis]\n72                          [excit, build, upcom, vacat]\n73              [kind, wit, today, restor, faith, human]\n74                     [pride, achiev, person, mileston]\n75                      [moment, shame, stand, injustic]\n76                         [fume, anger, heat, argument]\n77                          [fear, unknown, keep, night]\n78          [heartfelt, sad, bid, farewel, dear, friend]\n79           [state, corrupt, societi, utterli, disgust]\n80        [overflow, happi, welcom, new, famili, member]\n81     [laughter, key, joy—attend, stand-up, comedi, ...\n82                [send, love, follow, thi, beauti, day]\n83                    [amus, antic, pet—it', pure, amus]\n84          [enjoy, everi, moment, thi, trip—pur, enjoy]\n85                [admir, dedic, volunt, local, chariti]\n86               [send, affection, vibe, friend, famili]\n87                      [awe-struck, beauti, night, sky]\n88         [disappoint, lack, progress, person, project]\n89     [surpris, visit, old, friend, brought, tear, joy]\n90                               [embrac, accept, life']\n91                  [overflow, ador, cute, rescu, puppi]\n92                   [anticip, releas, much-await, movi]\n93              [bitter, experi, custom, servic, depart]\n94               [find, calm, amidst, chao, daili, life]\n95       [confus, reign, tri, make, sens, recent, event]\n96              [excit, build, surpris, birthday, parti]\n97                           [wit, act, kind, made, day]\n98             [pride, complet, challeng, fit, challeng]\n99                      [moment, shame, speak, injustic]\n100                     [reflect, beauti, divers, world]\n101                     [excit, quiet, even, good, book]\n102                     [feel, bitter, unfair, workplac]\n103                       [calm, prevail, practic, mind]\n104              [confus, surround, navig, life', choic]\n105     [excit, weekend, road, trip, explor, new, place]\n106             [kind, wit, today, restor, faith, human]\n107        [pride, accomplish, person, profession, goal]\n108               [shame, true, valu, difficult, situat]\n109             [revisit, old, memori, feel, sens, elat]\n110             [victori, team, brought, euphoria, citi]\n111             [embrac, beauti, natur, moment, content]\n112              [medit, seren, lake, find, inner, peac]\n113                   [overflow, gratitud, life', bless]\n114         [hope, brighter, tomorrow, despit, challeng]\n115                        [empow, make, differ, commun]\n116    [compass, action, support, local, chariti, event]\n117                 [moment, tender, connect, love, one]\n118              [arous, excit, await, special, announc]\n119                     [enthusiast, dive, new, project]\n120                [feel, sens, fulfil, reach, mileston]\n121                    [rever, beauti, histor, landmark]\n122                [elat, surpris, reunion, old, friend]\n123               [euphoria, live, music, concert, star]\n124                    [content, simplic, quiet, sunday]\n125                  [seren, found, page, favorit, book]\n126       [gratitud, support, receiv, dure, tough, time]\n127                        [hope, possibl, new, journey]\n128                     [empower, learn, person, growth]\n129               [compass, toward, need, dure, holiday]\n130                 [tender, warmth, cozi, winter, even]\n131                      [arous, excit, upcom, adventur]\n132                 [enthusiasm, creativ, project, make]\n133         [fulfil, complet, challeng, workout, routin]\n134                   [rever, artistri, display, museum]\n135                         [elat, achiev, person, goal]\n136                    [elat, discov, hidden, gem, citi]\n137                [euphoria, surpris, birthday, celebr]\n138                  [content, simplic, home-cook, meal]\n139                  [seren, found, melodi, peac, piano]\n140                  [gratitud, support, commun, around]\n141                  [hope, prospect, new, busi, ventur]\n142                              [empower, mentor, guid]\n143                  [compass, shown, act, kind, commun]\n144               [tender, heartfelt, messag, love, one]\n145              [arous, excit, befor, much-await, trip]\n146             [enthusiasm, new, artist, project, work]\n147                           [feel, sens, fulfil, help]\n148                  [rever, histor, signific, landmark]\n149                        [elat, achiev, fit, mileston]\n150                 [euphoria, success, product, launch]\n151                         [content, embrac, love, one]\n152                  [seren, found, beauti, sunset, sea]\n153                   [gratitud, small, joy, day, bring]\n154                      [hope, potenti, person, growth]\n155                         [empower, learn, new, skill]\n156                    [compass, volunt, local, chariti]\n157                  [tender, quiet, moment, share, pet]\n158                        [arous, excit, upcom, festiv]\n159             [enthusiasm, diy, home, improv, project]\n160                   [fulfil, complet, challeng, puzzl]\n161                  [rever, wonder, natur, hike, trail]\n162          [elat, surpris, reunion, childhood, friend]\n163                    [suffer, despair, anoth, setback]\n164          [overwhelm, grief, miss, love, one, dearli]\n165                 [loneli, creep, night, grow, colder]\n166                     [jealousi, consum, wit, success]\n167                        [resent, build, past, betray]\n168              [frustrat, mount, obstacl, block, path]\n169           [boredom, set, day, feel, endlessli, dull]\n170        [anxieti, grip, heart, worri, cloud, thought]\n171                     [intimid, unknown, futur, ahead]\n172                     [helpless, sink, challeng, pile]\n173                      [envi, eat, away, see, prosper]\n174             [regret, miss, opportun, haunt, thought]\n175                  [disgust, sight, injustic, cruelti]\n176                 [drown, despair, hope, slip, finger]\n177     [grief, weigh, heavi, tear, constant, companion]\n178          [loneli, crowd, room, silent, cri, connect]\n179                [jealousi, gnaw, confid, toxic, emot]\n180               [resent, fester, poison, relationship]\n181                [frustrat, boil, volcan, erupt, emot]\n182     [boredom, settl, like, dust, life, feel, mundan]\n183    [anxieti, grip, chest, relentless, grip, thought]\n184         [intimid, challeng, ahead, fear, take, hold]\n185              [helpless, engulf, drown, sea, problem]\n186              [envi, poison, thought, covet, success]\n187                  [regret, decis, led, pain, present]\n188                   [disgust, corrupt, stain, societi]\n189                   [sink, despair, day, darker, last]\n190              [grief, overwhelm, storm, emot, within]\n191         [loneli, echo, empti, space, yearn, connect]\n192    [jealousi, poison, thought, resent, brew, within]\n193                 [resent, fester, wound, refus, heal]\n194                [frustrat, escal, thunderstorm, emot]\n195          [boredom, linger, stagnant, pool, indiffer]\n196    [embark, journey, discoveri, fuel, curios, thi...\n197    [lost, vast, sea, inform, indiffer, wave, digi...\n198    [complex, puzzl, life, leaf, state, perpetu, c...\n199    [numb, settl, shield, overwhelm, emot, life, t...\n200    [gaze, sunset, melanchol, long, moment, slip, ...\n201    [revisit, old, photograph, caught, embrac, nos...\n202    [torn, conflict, emot, ambival, paint, decis, ...\n203    [embrac, ebb, flow, life, find, accept, danc, ...\n204    [face, challeng, head-on, determin, fuel, fire...\n205    [seren, found, still, natur, tranquil, retreat...\n206    [curios, lead, rabbit, hole, knowledg, perpetu...\n207    [float, day, air, indiffer, detach, mundan, ha...\n208    [entangl, web, thought, confus, reign, navig, ...\n209    [numb, chao, emot, lock, away, stoic, facad, c...\n210    [melancholi, whisper, breez, silent, convers, ...\n211    [stumbl, upon, old, journal, nostalgia, flood,...\n212    [tapestri, conflict, feel, weav, uncertainti, ...\n213    [embrac, flaw, find, accept, imperfect, journe...\n214    [determin, burn, like, wildfir, overcom, obsta...\n215    [tranquil, moment, ocean, seren, wash, peac, r...\n216    [explor, new, horizon, spark, curios, adventur...\n217    [drift, day, nonchal, demeanor, embrac, art, i...\n218    [wrestl, thought, perplex, mind, lost, labyrin...\n219    [immers, state, emot, numb, shield, storm, dai...\n220    [melanchol, symphoni, play, background, soundt...\n221    [flip, page, old, yearbook, nostalgia, paint, ...\n222    [torn, oppos, emot, ambival, color, decis, sha...\n223    [embrac, life', imperfect, find, accept, journ...\n224    [fieri, determin, burn, within, fuel, vision, ...\n225    [bask, seren, quiet, forest, whisper, natur, b...\n226    [indiffer, nois, world, silent, observ, midst,...\n227    [navig, labyrinth, thought, confus, constant, ...\n228    [impenetr, numb, shield, emot, storm, fortress...\n229    [melancholi, paint, world, hue, nostalgia, can...\n230    [journey, past, flip, page, old, diari, nostal...\n231    [ambival, cloud, decis, caught, crossroad, con...\n232    [embrac, imperfect, find, accept, mosaic, life...\n233    [determin, drive, forc, propel, forward, path,...\n234    [seek, seren, melodi, raindrop, tranquil, esca...\n235    [curios, drive, explor, unknown, seeker, knowl...\n236    [drift, day, air, nonchal, indiffer, trivial, ...\n237    [lost, labyrinth, thought, confus, cast, shado...\n238    [wrap, cloak, emot, numb, shield, storm, life'...\n239    [melancholi, companion, paint, canva, life, br...\n240    [leaf, page, old, photo, album, nostalgia, wea...\n241    [ambival, air, caught, crossroad, conflict, em...\n242    [embrac, beauti, imperfect, find, accept, mosa...\n243    [determin, ablaz, forg, path, challeng, sculpt...\n244    [immers, seren, moonlit, night, quiet, whisper...\n245    [fuel, curios, ventur, unchart, realm, fearles...\n246    [wrap, cloak, emot, numb, shield, storm, life'...\n247    [danc, life, exuber, carefre, spirit, embrac, ...\n248    [bask, golden, glow, content, seren, river, fl...\n249    [gaze, toward, horizon, hope, eye, paint, canv...\n250    [stand, tall, proud, oak, branch, achiev, reac...\n251    [heart, overflow, gratitud, garden, appreci, b...\n252    [extend, hand, empathet, thread, weav, tapestr...\n253    [compassion, cloud, heavi, care, shower, empat...\n254    [play, danc, rain, laughter, whimsic, spirit, ...\n255    [soar, wing, free, spirit, unburden, chain, co...\n256    [bath, glow, inspir, creativ, phoenix, rise, a...\n257    [navig, sea, hope, sail, toward, sunris, possi...\n258    [stride, confid, footprint, self-assured, impr...\n259    [lost, symphoni, night, moonlit, serenad, whis...\n260    [unveil, layer, curios, labyrinth, question, l...\n261    [embrac, autumn, breez, leaf, ambival, danc, w...\n262    [gratitud, guid, star, navig, constel, bless, ...\n263    [zest, heart, sprint, field, enthusiasm, chase...\n264    [compassion, rain, tear, empathi, fall, gentli...\n265    [proudli, scale, peak, achiev, mountain, conqu...\n266    [embrac, hope, dawn, garden, sow, seed, optim,...\n267    [play, escapad, carniv, life, carousel, laught...\n268    [float, cloud, inspir, artist, paint, sky, str...\n269    [navig, river, content, seren, boat, cruis, tr...\n270    [empathi, lantern, wander, dark, alley, sorrow...\n271    [free, spirit, soar, wing, dream, leav, trail,...\n272    [bath, golden, hue, grate, sunset, appreci, ca...\n273    [confid, stride, danc, life, ballroom, self-as...\n274    [hope, whisper, wind, carri, promis, brighter,...\n275    [play, juggl, respons, circu, perform, balanc,...\n276    [whisper, tale, inspir, star, storytel, craft,...\n277    [chart, cours, wave, hope, anticip, sailor, st...\n278    [compassion, rain, tear, empathi, fall, gentli...\n279    [proudli, scale, peak, achiev, mountain, conqu...\n280    [embrac, hope, dawn, garden, sow, seed, optim,...\n281    [play, escapad, carniv, life, carousel, laught...\n282    [float, cloud, inspir, artist, paint, sky, str...\n283    [navig, river, content, seren, boat, cruis, tr...\n284    [empathi, lantern, wander, dark, alley, sorrow...\n285    [free, spirit, soar, wing, dream, leav, trail,...\n286    [bath, golden, hue, grate, sunset, appreci, ca...\n287    [confid, stride, danc, life, ballroom, self-as...\n288    [hope, whisper, wind, carri, promis, brighter,...\n289    [play, juggl, respons, circu, perform, balanc,...\n290    [whisper, tale, inspir, star, storytel, craft,...\n291    [chart, cours, wave, hope, anticip, sailor, st...\n292    [compassion, rain, tear, empathi, fall, gentli...\n293    [proudli, scale, peak, achiev, mountain, conqu...\n294    [embrac, hope, dawn, garden, sow, seed, optim,...\n295    [play, escapad, carniv, life, carousel, laught...\n296    [drown, abyss, despair, heart, shatter, fragme...\n297    [bitter, fester, like, venom, vine, entwin, so...\n298    [wander, desert, loneli, step, heavi, sigh, mi...\n299    [yearn, touch, that', echo, distant, warmth, h...\n300    [eye, wide, open, night, fear, shadow, danc, w...\n301    [apprehens, step, tightrop, uncertainti, balan...\n302    [overwhelm, weight, world, atla, trembl, shoul...\n303    [jealousi, green-ey, monster, lurk, shadow, ca...\n304    [devast, storm, betray, wreckag, trust, scatte...\n305    [frustrat, finger, tap, keyboard, symphoni, an...\n306    [enviou, eye, fixat, gild, prize, heartach, fu...\n307    [dismiss, glanc, fortress, built, indiffer, wa...\n308    [shatter, dream, lie, floor, like, fragment, g...\n309    [loneli, silent, companion, night, onli, echo,...\n310    [fear, whisper, dark, mind, haunt, specter, un...\n311    [bitter, bitter, aftertast, linger, tongu, wor...\n312    [overwhelm, cacophoni, expect, drown, soul, te...\n313    [jealousi, venom, seep, vein, poison, heart, t...\n314    [devast, revel, betray, trust, shatter, like, ...\n315    [frustrat, attempt, mend, broken, connect, thr...\n316    [enviou, gaze, cast, upon, podium, success, bi...\n317    [dismiss, gestur, curtain, drawn, shield, vuln...\n318    [despair, like, heavi, fog, envelop, everi, th...\n319    [bitter, bitter, chill, air, freez, moment, ic...\n320    [loneli, solitari, moon, starless, sky, cast, ...\n321    [yearn, warmth, vanish, sun, heartach, paint, ...\n322    [fear, eye, scan, shadow, prison, night, terro...\n323    [apprehens, whisper, wind, forecast, uncertain...\n324    [overwhelm, maze, expect, minotaur, pressur, l...\n325    [jealousi, fester, wound, pain, intensifi, gla...\n326    [devast, heart, ruin, echo, shatter, dream, re...\n327    [frustrat, attempt, untangl, knot, confus, thr...\n328    [enviou, eye, lock, treasur, chest, opportun, ...\n329    [dismiss, gestur, curtain, drawn, shield, vuln...\n330    [shatter, dream, lie, floor, like, fragment, g...\n331    [loneli, silent, companion, night, onli, echo,...\n332            [awe-struck, breathtak, sunris, mountain]\n333                          [navig, challeng, determin]\n334            [nostalgia, hit, flip, old, photo, album]\n335              [thrill, wit, grandeur, cultur, festiv]\n336           [calm, found, rhythm, raindrop, windowpan]\n337    [overwhelm, support, receiv, dure, person, cha...\n338    [excit, build, countdown, long-await, vacat, b...\n339      [reflect, life', journey, grate, lesson, learn]\n340    [bittersweet, emot, aris, bid, farewel, dear, ...\n341      [curios, spark, explor, mysteri, ancient, ruin]\n342       [admir, intric, detail, handcraft, masterpiec]\n343      [overjoy, warmth, cozi, fireplac, winter, even]\n344     [inspir, strike, observ, color, vibrant, sunset]\n345         [motiv, achiev, fit, goal, invigor, workout]\n346      [gratitud, simpl, joy, found, cup, morn, coffe]\n347        [feel, empow, conquer, challeng, hike, trail]\n348           [amus, antic, play, kitten, dure, playtim]\n349       [contempl, life', mysteri, starri, night, sky]\n350       [joy, reunion, long-lost, friend, year, separ]\n351              [excit, build, prepar, surpris, celebr]\n352    [satisfact, deriv, success, complet, diy, proj...\n353           [feel, bless, support, commun, time, need]\n354       [captiv, seren, tranquil, garden, full, bloom]\n355             [anticip, upcom, adventur, exot, destin]\n356      [reflect, person, growth, achiev, life, experi]\n357    [nostalg, memori, flood, revisit, childhood, f...\n358    [appreci, vibrant, cultur, experienc, dure, tr...\n359      [confid, soar, overcom, public, speak, anxieti]\n360     [content, midst, famili, gather, fill, laughter]\n361    [enthusiasm, learn, new, skill, expand, knowledg]\n362        [surpris, delight, discov, hidden, gem, citi]\n363       [sens, accomplish, complet, challeng, workout]\n364               [wonder, beauti, doubl, rainbow, rain]\n365       [optim, bright, futur, amidst, challeng, time]\n366    [pride, achiev, person, mileston, career, prog...\n367     [happi, bloom, like, flower, garden, sunni, day]\n368         [elat, discov, rare, book, quaint, bookstor]\n369    [curios, piqu, mysteri, ancient, archaeolog, s...\n370      [mesmer, cosmic, danc, firefli, moonlit, night]\n371    [intrigu, symphoni, color, abstract, art, exhi...\n372    [giggl, joy, echo, air, dure, children', playdat]\n373                [envelop, seren, practic, mind, lake]\n374    [chase, dream, like, kite, soar, high, vast, o...\n375    [spellbound, eleg, ballroom, danc, crystal, ch...\n376    [whimsic, delight, world, fairi, tale, magic, ...\n377    [pensiv, contempl, amid, ancient, ruin, forgot...\n378    [embrac, thrill, speed, rollercoaster', exhila...\n379    [harmoni, reson, musician, play, melodi, uniti...\n380    [burst, creativ, quiet, solitud, artist', studio]\n381    [radiant, joy, akin, bloom, flower, sun-kiss, ...\n382          [sens, wonder, vast, cosmo, stargaz, night]\n383         [rejuven, salti, breez, sound, wave, seasid]\n384        [whisper, inspir, rustl, leaf, seren, forest]\n385    [savor, warmth, cup, cocoa, chilli, winter, even]\n386    [heartfelt, gratitud, laughter, share, dure, f...\n387    [embark, culinari, adventur, savor, exot, flav...\n388    [euphoria, flood, final, puzzl, piec, click, p...\n389    [awe-inspir, grandeur, ancient, cathedral', in...\n390        [captiv, ether, beauti, field, fill, firefli]\n391    [immers, enchant, melodi, street, musician', v...\n392         [joy, laughter, reson, live, summer, carniv]\n393    [explor, univers, within, dure, mind, medit, s...\n394     [soar, like, free, spirit, wind, coastal, cliff]\n395       [dazzl, eleg, masquerad, ball', dazzl, costum]\n396      [whimsic, delight, world, whimsic, fairi, tale]\n397      [reflect, contempl, amid, ruin, forgotten, era]\n398    [ride, adrenalin, rush, rollercoaster', wild, ...\n399    [harmoni, reson, musician, play, symphoni, uniti]\n400    [burst, artist, creativ, quietud, artist', stu...\n401    [radiant, joy, akin, blossom, flower, sunlit, ...\n402            [awe-inspir, vast, cosmo, stargaz, night]\n403         [rejuven, salti, breez, sound, wave, seasid]\n404        [whisper, inspir, rustl, leaf, seren, forest]\n405    [savor, warmth, cup, cocoa, chilli, winter, even]\n406    [heartfelt, gratitud, laughter, share, dure, f...\n407    [embark, culinari, odyssey, savor, flavor, aro...\n408    [euphoria, flood, final, puzzl, piec, fit, per...\n409    [awe-struck, grandeur, ancient, cathedral', in...\n410    [curios, awaken, mysteri, ancient, archaeolog,...\n411           [giddi, excit, first, snowflak, danc, sky]\n412    [content, envelop, aroma, freshli, bake, bread...\n413     [inspir, resili, lone, tree, stand, tall, storm]\n414    [lost, page, captiv, novel, transport, anoth, ...\n415    [drench, nostalgia, flip, old, famili, photo, ...\n416    [spark, inspir, ignit, like, shoot, star, nigh...\n417     [imbu, gratitud, simpl, pleasur, warm, cup, tea]\n418    [marvel, kaleidoscop, color, vibrant, street, ...\n419    [awash, seren, sun, set, tranquil, lakesid, re...\n420        [drown, sorrow, memori, lost, love, resurfac]\n421           [numb, set, weight, loneli, grow, heavier]\n422    [tear, fall, like, raindrop, mourn, end, cheri...\n423    [despair, cloud, mind, feel, adrift, endless, ...\n424    [shatter, betray, trust, crumbl, like, fragil,...\n425    [ach, heart, symphoni, pain, play, silenc, sol...\n426    [emot, storm, whirlwind, sad, engulf, everi, t...\n427    [haunt, regret, ghost, past, linger, relentles...\n428     [torn, apart, grief, echo, loss, reverber, soul]\n429    [isol, deepen, emot, winter, warmth, distant, ...\n430    [soul-crush, disappoint, hope, shatter, like, ...\n431    [pain, echo, love, onc, cherish, lost, abyss, ...\n432    [heartach, deepen, solitari, journey, abyss, d...\n433    [melancholi, linger, bittersweet, serenad, qui...\n434    [bitter, like, poison, seep, everi, crevic, wo...\n435    [emot, exhaust, weight, world, crush, weari, s...\n436    [sorrow, echo, symphoni, pain, play, string, l...\n437       [dark, descend, engulf, soul, shadow, despair]\n438    [desper, whisper, silent, plea, glimmer, hope,...\n439    [heart, ruin, remnant, shatter, dream, scatter...\n440    [shatter, echo, shatter, dream, fragment, hope...\n441    [avoid, thorn, regret, walk, barefoot, path, r...\n442    [labyrinth, grief, wall, echo, footstep, lost,...\n443    [soul, adrift, sea, solitud, wave, loneli, cra...\n444    [bitter, betray, tast, linger, stain, palat, t...\n445    [ruin, hope, echo, shatter, dream, whisper, ta...\n446    [sink, like, stone, ocean, heartbreak, rippl, ...\n447    [tear, ink, stain, page, journal, testament, s...\n448    [wasteland, lost, trust, echo, broken, promis,...\n449    [avoid, shard, shatter, dream, walk, tightrop,...\n450    [suffoc, silenc, solitud, echo, laughter, onc,...\n451    [haunt, specter, lost, possibl, ghost, refus, ...\n452    [labyrinth, despair, echo, broken, heart, reve...\n453    [sink, like, autumn, leaf, river, sorrow, carr...\n454    [garden, broken, dream, petal, fall, silent, t...\n455    [tear, currenc, grief, spent, marketplac, lost...\n456    [wander, maze, betray, wall, close, everi, wro...\n457    [soul, weather, storm, heartbreak, seek, refug...\n458    [tapestri, despair, thread, hope, unravel, lea...\n459    [like, wither, rose, garden, love, petal, fall...\n460    [void, heartach, echo, love, song, play, note,...\n461    [nostalgia, bittersweet, danc, moonlit, ballro...\n462    [symphoni, grief, tear, note, compos, melancho...\n463    [betray, venom, serpent, slither, garden, trus...\n464    [sink, quicksand, despair, harder, fight, deep...\n465    [wander, cemeteri, lost, dream, tombston, mark...\n466    [swept, away, river, regret, current, past, re...\n467    [whisper, lost, love, linger, attic, heart, fo...\n468    [galleri, broken, promis, shatter, vow, frame,...\n469       [echo, solitud, silent, convers, soul, shadow]\n470    [danc, sunshin, step, celebr, joy, found, simp...\n471    [laughter, echo, air, choru, happi, lift, spir...\n472    [garden, content, bloom, whisper, tale, inner,...\n473    [chase, dream, vibrant, sky, journey, fuel, ho...\n474    [serenad, star, heart, full, gratitud, melodi,...\n475    [bask, glow, accomplish, mileston, step, stone...\n476    [danc, posit, everi, step, rhythm, uplift, sou...\n477    [overflow, joy, cup, laughter, share, friend, ...\n478    [drape, warmth, kind, quilt, compass, stitch, ...\n479    [garden, friendship, bloom, testament, beauti,...\n480    [embrac, love, heartbeat, melodi, danc, rhythm...\n481    [surround, color, joy, canva, paint, laughter,...\n482    [symphoni, excit, note, burst, energi, ignit, ...\n483    [surpris, gift, wrap, anticip, unfold, moment,...\n484    [lost, maze, curios, twist, turn, unveil, trea...\n485    [float, cloud, gratitud, raindrop, bless, show...\n486    [like, comet, inspir, streak, sky, creativ, le...\n487    [celebr, success, firework, accomplish, light,...\n488    [symphoni, laughter, note, key, unlock, door, ...\n489    [carniv, emot, rollercoast, thrill, send, hear...\n490    [stand, befor, grandeur, eiffel, tower, moment...\n491    [lost, enchant, disneyland, ride, journey, rea...\n492    [explor, wonder, ferrari, world, roar, engin, ...\n493    [amidst, tulip, field, keukenhof, tapestri, co...\n494    [wander, histor, street, kyoto, step, journey,...\n495    [embrac, grand, canyon, nature', masterpiec, m...\n496    [journey, seren, santorini, sunset, paint, sky...\n497    [amaz, architectur, marvel, petra, stone, tell...\n498    [embark, gondola, ride, venic, canal, reflect,...\n499    [summit, machu, picchu, breathtak, panorama, w...\n500    [heart, new, york, citi, time, squar, dazzl, l...\n501    [captiv, histor, charm, colosseum, stone, echo...\n502    [sail, azur, water, maldiv, wave, whisper, ser...\n503    [midst, amazon, rainforest, symphoni, wildlif,...\n504    [walk, great, wall, china, step, testament, an...\n505    [summit, mount, fuji, breathtak, sunris, paint...\n506    [explor, ancient, ruin, angkor, wat, stone, wh...\n507    [ski, slope, swiss, alp, turn, danc, majesti, ...\n508    [tranquil, kyoto', bamboo, forest, whisper, an...\n509    [cruis, fjord, norway, ici, landscap, breathta...\n510    [front, row, adele', concert, note, 'someon, l...\n511    [danc, star, beyoncé', live, show, feel, power...\n512    [crowd, taylor, swift, concert, lyric, 'love, ...\n513    [rock, guitar, solo, queen, tribut, concert, j...\n514    [sway, ed, sheeran', acoust, melodi, seren, ev...\n515    [immers, pulsat, beat, bruno, mar, concert, 'u...\n516    [michael, jackson, tribut, show, moonwalk, hit...\n517    [swing, rhythm, frank, sinatra, tribut, feel, ...\n518    [mosh, pit, metallica, concert, thunder, chord...\n519    [experienc, magic, coldplay, concert, 'fix, be...\n520    [justin, bieber, concert, infecti, beat, 'babi...\n521    [spotlight, ladi, gaga, show, costum, chang, m...\n522    [immers, soul, melodi, adel, tear, flow, freel...\n523    [drench, confetti, kati, perri, concert, kalei...\n524    [audienc, jay-z, perform, lyric, 'empir, state...\n525    [danc, shakira', rhythmic, beat, hip, sway, hy...\n526    [u2, concert, anthem, chord, 'with, without, c...\n527    [rock, gun, n, rose, show, icon, riff, 'sweet,...\n528    [crowd, ariana, grand, concert, high, note, 'i...\n529    [sway, regga, vibe, bob, marley', tribut, conc...\n530    [captiv, spellbind, plot, twist, audienc, appl...\n531    [credit, roll, profound, sens, nostalgia, wash...\n532    [stream, latest, web, seri, viewer, engross, c...\n533    [film, festiv, indi, filmmaker', creation, rec...\n534    [watch, heartwarm, famili, drama, tear, flow, ...\n535    [oscar, actor, gracious, accept, award, radiat...\n536    [discov, hidden, gem, world, documentari, view...\n537    [movi, credit, roll, viewer, experi, mix, awe,...\n538    [binge-watch, thrill, crime, seri, suspens, ke...\n539    [close, scene, unfold, sens, satisfact, wash, ...\n540    [celebr, histor, victori, world, cup, nation, ...\n541    [olymp, athlete', persever, shine, earn, gold,...\n542    [cricket, championship, nail-bit, finish, leaf...\n543    [wit, record-break, marathon, spectat, fill, a...\n544    [tenni, grand, slam, fierc, rivalri, unfold, c...\n545    [cheer, underdog, basketbal, final, crowd, eru...\n546    [golf, tournament, golfer', precis, focu, lead...\n547    [experienc, thrill, high-spe, formula, 1, race...\n548    [cycl, world, championship, climber, conquer, ...\n549    [wit, heartwarm, comeback, hockey, final, fan,...\n550    [seri, defeat, soccer, team, face, disappoint,...\n551    [tenni, tournament, highli, anticip, player, e...\n552    [face, defeat, championship, boxer, reflect, c...\n553    [midst, cycl, race, tire, blowout, lead, frust...\n554    [gymnast', unexpect, fall, dure, routin, spark...\n555    [golf, tournament, miss, crucial, putt, result...\n556    [experienc, seri, loss, basketbal, season, tea...\n557    [despit, meticul, train, swimmer, face, disapp...\n558    [weightlifter', fail, attempt, person, record,...\n559    [midst, soccer, match, unexpect, goal, creat, ...\n560    [seren, beauti, sunset, natur, unfold, canva, ...\n561    [embark, spontan, road, trip, travel, discov, ...\n562    [amidst, bustl, citi, quiet, café, becom, sanc...\n563    [explor, vibrant, street, art, cultur, neighbo...\n564    [world, scienc, breakthrough, discoveri, unfol...\n565    [connect, melodi, live, orchestra, music, enth...\n566    [embrac, aroma, freshli, bake, bread, home, ch...\n567    [wander, histor, museum, histori, enthusiast, ...\n568    [realm, literatur, captiv, novel, transport, r...\n569    [captur, essenc, bustl, market, photograph, fr...\n570    [underneath, citi, light, dancer, express, emo...\n571    [heart, bustl, market, street, food, connoisse...\n572    [first, snowflak, descend, winter, enthusiast,...\n573    [amidst, page, captiv, mysteri, novel, reader,...\n574    [surround, vibrant, color, flower, garden, gar...\n575    [astronomi, observatori, stargaz, marvel, vast...\n576    [engulf, aroma, freshli, brew, coffe, writer, ...\n577    [realm, fashion, design, unveil, collect, tell...\n578    [wave, crash, shore, surfer, embrac, thrill, r...\n579    [explor, histor, architectur, ancient, citi, t...\n580    [success, avoid, eye, contact, crush, hallway,...\n581    [ran, snack, dure, movi, marathon, crisi, leve...\n582    [spent, hour, choos, perfect, filter, selfi, s...\n583    [lost, headphon, vanish, thin, air, #headphone...\n584    [decid, studi, exam, end, make, meme, studi, i...\n585    [got, dress, day, rememb, it', saturday, oop, ...\n586    [surviv, group, project, without, ani, drama, ...\n587    [enter, kitchen, intent, cook, left, bag, chip...\n588    [stare, clock, class, wait, bell, ring, like, ...\n589    [discov, new, book, seri, spent, whole, night,...\n590    [bought, new, video, game, play, hour, forgot,...\n591    [spent, day, binge-watch, new, seri, product, ...\n592    [caught, latest, fashion, trend, plan, shop, s...\n593    [decid, learn, new, instrument, day, one, stil...\n594    [spent, hour, creat, perfect, playlist, everi,...\n595    [success, cook, gourmet, meal, famili, chef, s...\n596    [spontan, book, weekend, getaway, adventur, aw...\n597    [attend, concert, danc, night, away, music, he...\n598    [rediscov, childhood, cartoon, nostalgia-fil, ...\n599    [embark, diy, home, decor, project, let', hope...\n600    [spent, afternoon, museum, pretend, cultur, ar...\n601    [start, blog, random, thought, muse, blog, new...\n602    [relish, peac, afternoon, classic, novel, quie...\n603    [reflect, lifetim, memori, wrinkl, tell, stori...\n604    [explor, world, digit, art, it', never, late, ...\n605    [savor, flavor, home-cook, meal, simpl, joy, h...\n606    [embark, journey, learn, new, languag, mind, s...\n607    [attend, classic, music, concert, feel, timele...\n608    [captur, beauti, natur, photographi, everi, sn...\n609    [reconnect, old, friend, cup, tea, friendship,...\n610    [embark, road, trip, revisit, cherish, place, ...\n611    [join, commun, choir, harmon, fellow, voic, mu...\n612    [explor, art, medit, find, tranquil, still, mi...\n613    [take, stroll, garden, appreci, beauti, bloom,...\n614    [sip, favorit, vintag, wine, sip, tell, stori,...\n615    [particip, commun, art, class, unleash, creati...\n616    [embark, journey, write, memoir, document, lif...\n617    [attend, lectur, histori, alway, fascin, lesso...\n618    [rediscov, joy, cook, tradit, famili, recip, k...\n619    [join, natur, photographi, club, captur, beaut...\n620    [attend, jazz, concert, sway, rhythm, timeless...\n621    [join, write, group, pen, thought, reflect, wr...\n622    [embark, solo, travel, adventur, discov, beaut...\n623    [attend, vintag, car, show, reminisc, classic,...\n624    [start, commun, garden, grow, plant, friendshi...\n625    [host, famili, dinner, laughter, echo, louder,...\n626    [enrol, danc, class, senior, move, rhythm, lif...\n627    [visit, art, galleri, appreci, brushstrok, tel...\n628    [start, book, club, senior, discuss, live, cha...\n629    [host, picnic, park, bask, warmth, friendship,...\n630    [particip, local, theater, product, prove, sta...\n631    [embark, hike, adventur, conquer, trail, relis...\n632    [host, photographi, exhibit, featur, snapshot,...\n633    [join, senior, cycl, club, feel, wind, hair, f...\n634    [attend, wine, tast, event, savor, rich, flavo...\n635    [start, learn, ballroom, danc, glide, grace, a...\n636    [organ, commun, paint, event, turn, blank, can...\n637    [host, 'memori, lane, even, old, friend, remin...\n638    [join, senior, astronomi, club, stargaz, find,...\n639    [attend, local, jazz, festiv, tap, toe, tune, ...\n640    [start, blog, share, wisdom, gain, year, prove...\n641    [particip, chariti, run, prove, age, barrier, ...\n642      [surviv, challeng, physic, exam, equat, defeat]\n643    [explor, world, code, debug, adventur, #coding...\n644    [join, school, debat, team, word, weapon, read...\n645    [start, photographi, club, school, captur, mom...\n646    [daydream, upcom, prom, dress, danc, –, it', f...\n647    [convinc, teacher, class, outdoor, learn, equa...\n648    [accident, spill, paint, art, class, abstract,...\n649    [tri, master, perfect, kickflip, skateboard, s...\n650    [bond, friend, latest, k-pop, sensat, fangirl,...\n651    [spent, hour, perfect, chemistri, experi, mix,...\n652    [success, organ, surpris, birthday, parti, fri...\n653    [join, drama, club, unleash, inner, actor, lig...\n654    [got, hand, latest, fantasi, novel, dive, real...\n655    [master, art, perfect, doodl, dure, bore, clas...\n656    [attempt, break, school, record, longest, hand...\n657    [sneak, snack, class, like, pro, art, snack-sm...\n658    [host, sleepov, friend, thi, weekend, prepar, ...\n659    [spent, hour, tiktok, danc, onli, realiz, two,...\n660    [accident, like, crush', old, photo, stalk, pr...\n661    [tri, impress, crush, smooth, convers, end, sp...\n662    [master, art, creat, paper, airplan, dure, lec...\n663    [tri, set, new, trend, juggl, textbook, class,...\n664    [hide, snack, stash, backpack, emerg, crave, s...\n665    [plan, surpris, scaveng, hunt, friend, anticip...\n666    [danc, rain, celebr, end, exam, rain, danc, un...\n667    [accident, sent, text, meant, friend, class, g...\n668    [tri, magic, trick, impress, classmat, magic, ...\n669    [perfect, art, creat, origami, dure, dull, lec...\n670    [attempt, set, new, record, consecut, hacki, s...\n671    [creat, secret, handshak, friend, friendship, ...\n672    [embark, mission, find, best, burger, joint, t...\n673    [practic, stand-up, comedi, routin, upcom, tal...\n674    [accident, sent, love, letter, wrong, person, ...\n675    [attempt, impress, teacher, elabor, scienc, ex...\n676    [craft, intric, friendship, bracelet, whole, s...\n677    [attempt, beat, record, consecut, cartwheel, c...\n678    [organ, movi, marathon, friend, popcorn, cinem...\n679    [experi, new, hair, color, bold, chang, bold, ...\n680    [build, time, capsul, captur, memori, futur, t...\n681    [accident, walk, wrong, classroom, first, day,...\n682    [tri, new, smoothi, recip, healthi, start, wee...\n683    [reflect, challeng, school, year, feel, bit, o...\n684    [encount, mean-spirit, comment, onlin, deal, o...\n685         [bad, day, school, everyth, seem, go, wrong]\n686        [feel, make, sport, team, disappoint, linger]\n687    [wit, heat, argument, cafeteria, unpleas, atmo...\n688    [receiv, not-so-great, grade, major, project, ...\n689    [deal, person, setback, sometim, life, throw, ...\n690    [feel, lone, saturday, night, sometim, solitud...\n691    [experienc, cyberbulli, hate, messag, onlin, d...\n692    [caught, torrenti, rainstorm, without, umbrell...\n693    [miss, import, event, due, unforeseen, circums...\n694    [deal, unfound, rumor, circul, person, life, r...\n695    [got, flat, tire, way, import, meet, talk, ser...\n696    [feel, sens, empti, close, friend, move, away,...\n697    [face, reject, dream, colleg, dishearten, dete...\n698    [encount, onlin, toxic, dure, game, session, h...\n699    [bad, hair, day, feel, self-consci, bad, hair,...\n700    [feel, sens, despair, major, project, failur, ...\n701    [experienc, hate, comment, express, person, op...\n702    [string, bad, luck, constant, technolog, malfu...\n703    [miss, long-anticip, event, due, unexpect, cir...\n704    [tri, new, studi, techniqu, upcom, exam, explo...\n705    [organ, commun, cleanup, event, cleaner, neigh...\n706    [share, favorit, book, recommend, classmat, bu...\n707    [experi, new, recip, school, bake, sale, bake,...\n708    [collabor, school, project, peer, teamwork, ma...\n709    [attend, school, club, meet, explor, new, inte...\n710    [explor, new, part-tim, job, opportun, gain, w...\n711    [attend, school, assembl, stay, inform, upcom,...\n712    [explor, new, hobbi, photographi, dure, free, ...\n713    [particip, scienc, fair, showcas, uniqu, exper...\n714    [attend, workshop, time, manag, enhanc, organi...\n715    [volunt, local, chariti, event, give, back, co...\n716    [collabor, group, project, promot, teamwork, s...\n717    [particip, debat, club, enhanc, critic, think,...\n718    [celebr, friend', birthday, surpris, parti, jo...\n719    [success, complet, challeng, code, project, ex...\n720    [attend, school, talent, show, support, classm...\n721    [explor, new, hike, trail, friend, weekend, na...\n722    [win, friendli, sport, competit, rival, school...\n723    [receiv, heartfelt, letter, pen, pal, anoth, c...\n724    [creat, beauti, mural, fellow, art, enthusiast...\n725    [particip, school-wid, art, exhibit, wit, crea...\n726    [achiev, person, best, track, field, competit,...\n727    [collabor, scienc, project, receiv, recognit, ...\n728    [attend, surpris, birthday, parti, organ, frie...\n729    [success, fundrais, school, chariti, initi, jo...\n730    [particip, multicultur, festiv, celebr, divers...\n731    [organ, virtual, talent, show, dure, challeng,...\nName: Text, dtype: object\n","output_type":"stream"}],"execution_count":320},{"cell_type":"code","source":"from gensim.models import Word2Vec\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\n\n# Train Word2Vec using skip-gram with increased epochs (50)\nsentences = train_df['Text'].tolist()\nw2v_model = Word2Vec(sentences, vector_size=300, window=7, min_count=2, workers=4, sg=1, negative=10, epochs=50)\nw2v_model.save(\"word2vec.model\")\n\ndef get_sentence_vector(sentence, model, vector_size=300):\n    vectors = [model.wv[word] for word in sentence if word in model.wv]\n    if vectors:\n        vectors = np.array(vectors)\n        avg_vec = np.mean(vectors, axis=0)\n        max_vec = np.max(vectors, axis=0)\n        min_vec = np.min(vectors, axis=0)\n        return np.concatenate([avg_vec, max_vec, min_vec])\n    else:\n        return np.zeros(vector_size * 3)\n\ntrain_df['vector'] = train_df['Text'].apply(lambda x: get_sentence_vector(x, w2v_model))\n\nlabel_encoder = LabelEncoder()\ntrain_df['Sentiment'] = label_encoder.fit_transform(train_df['Sentiment'])\nX = np.vstack(train_df['vector'].values)\ny = train_df['Sentiment'].values.astype(np.int32)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\naccuracies = []\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    model = Sequential([\n        Dense(2048, input_shape=(900,)),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(1024),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(512),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(256),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(128),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(3, activation='softmax')\n    ])\n    \n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n    \n    model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test), callbacks=[lr_scheduler], verbose=1)\n    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n    accuracies.append(accuracy)\n    \nprint(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:02:28.067028Z","iopub.execute_input":"2025-03-13T19:02:28.067551Z","iopub.status.idle":"2025-03-13T19:08:09.348774Z","shell.execute_reply.started":"2025-03-13T19:02:28.067514Z","shell.execute_reply":"2025-03-13T19:08:09.347486Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.3717 - loss: 1.6935 - val_accuracy: 0.4762 - val_loss: 1.0583 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5586 - loss: 1.3134 - val_accuracy: 0.4762 - val_loss: 1.1228 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5615 - loss: 1.2757 - val_accuracy: 0.5034 - val_loss: 1.1097 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6105 - loss: 1.1275\nEpoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6154 - loss: 1.1107 - val_accuracy: 0.4898 - val_loss: 1.1243 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6182 - loss: 0.9780 - val_accuracy: 0.4966 - val_loss: 1.1229 - learning_rate: 5.0000e-04\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6430 - loss: 0.9441 - val_accuracy: 0.5102 - val_loss: 1.0375 - learning_rate: 5.0000e-04\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6892 - loss: 0.7999 - val_accuracy: 0.5034 - val_loss: 1.0429 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6439 - loss: 0.9680 - val_accuracy: 0.5102 - val_loss: 1.0065 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.6647 - loss: 0.8773 - val_accuracy: 0.5238 - val_loss: 1.0005 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.6492 - loss: 0.9042 - val_accuracy: 0.5238 - val_loss: 0.9488 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6489 - loss: 0.9036 - val_accuracy: 0.5714 - val_loss: 0.8964 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6937 - loss: 0.7781 - val_accuracy: 0.6122 - val_loss: 0.8762 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7169 - loss: 0.7606 - val_accuracy: 0.5918 - val_loss: 0.9076 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6994 - loss: 0.7364 - val_accuracy: 0.5986 - val_loss: 0.8946 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7176 - loss: 0.7151 - val_accuracy: 0.6190 - val_loss: 0.8631 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7054 - loss: 0.6892 - val_accuracy: 0.6190 - val_loss: 0.8637 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7150 - loss: 0.7165 - val_accuracy: 0.6327 - val_loss: 0.8614 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6918 - loss: 0.7602 - val_accuracy: 0.6463 - val_loss: 0.8529 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7623 - loss: 0.6073 - val_accuracy: 0.6327 - val_loss: 0.8610 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7418 - loss: 0.6847 - val_accuracy: 0.6259 - val_loss: 0.8627 - learning_rate: 5.0000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7375 - loss: 0.6524 - val_accuracy: 0.6531 - val_loss: 0.8271 - learning_rate: 5.0000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7608 - loss: 0.6469 - val_accuracy: 0.6871 - val_loss: 0.8267 - learning_rate: 5.0000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7496 - loss: 0.6442 - val_accuracy: 0.6939 - val_loss: 0.8222 - learning_rate: 5.0000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7499 - loss: 0.6029 - val_accuracy: 0.6939 - val_loss: 0.7921 - learning_rate: 5.0000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7722 - loss: 0.6020 - val_accuracy: 0.6871 - val_loss: 0.7761 - learning_rate: 5.0000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7585 - loss: 0.5984 - val_accuracy: 0.7007 - val_loss: 0.7867 - learning_rate: 5.0000e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7914 - loss: 0.5289 - val_accuracy: 0.7007 - val_loss: 0.8137 - learning_rate: 5.0000e-04\nEpoch 28/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7501 - loss: 0.5742\nEpoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7498 - loss: 0.5760 - val_accuracy: 0.7007 - val_loss: 0.8394 - learning_rate: 5.0000e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7934 - loss: 0.5410 - val_accuracy: 0.7143 - val_loss: 0.8285 - learning_rate: 2.5000e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7959 - loss: 0.5019 - val_accuracy: 0.7143 - val_loss: 0.8183 - learning_rate: 2.5000e-04\nEpoch 31/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7468 - loss: 0.6406\nEpoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7512 - loss: 0.6253 - val_accuracy: 0.7007 - val_loss: 0.8074 - learning_rate: 2.5000e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7607 - loss: 0.5485 - val_accuracy: 0.7143 - val_loss: 0.8023 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7880 - loss: 0.5385 - val_accuracy: 0.7143 - val_loss: 0.7999 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8274 - loss: 0.4492\nEpoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8258 - loss: 0.4567 - val_accuracy: 0.7007 - val_loss: 0.7988 - learning_rate: 1.2500e-04\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8032 - loss: 0.4839 - val_accuracy: 0.7007 - val_loss: 0.7962 - learning_rate: 6.2500e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8278 - loss: 0.4281 - val_accuracy: 0.7007 - val_loss: 0.7962 - learning_rate: 6.2500e-05\nEpoch 37/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7966 - loss: 0.4927\nEpoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7950 - loss: 0.4971 - val_accuracy: 0.7007 - val_loss: 0.7984 - learning_rate: 6.2500e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8130 - loss: 0.4451 - val_accuracy: 0.7075 - val_loss: 0.8000 - learning_rate: 3.1250e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8080 - loss: 0.5173 - val_accuracy: 0.7075 - val_loss: 0.8034 - learning_rate: 3.1250e-05\nEpoch 40/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7654 - loss: 0.5273\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7683 - loss: 0.5274 - val_accuracy: 0.7143 - val_loss: 0.8066 - learning_rate: 3.1250e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8144 - loss: 0.4464 - val_accuracy: 0.7143 - val_loss: 0.8100 - learning_rate: 1.5625e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7751 - loss: 0.5177 - val_accuracy: 0.7143 - val_loss: 0.8134 - learning_rate: 1.5625e-05\nEpoch 43/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8013 - loss: 0.4739\nEpoch 43: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8011 - loss: 0.4766 - val_accuracy: 0.7143 - val_loss: 0.8180 - learning_rate: 1.5625e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8016 - loss: 0.4640 - val_accuracy: 0.7143 - val_loss: 0.8212 - learning_rate: 7.8125e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7720 - loss: 0.5271 - val_accuracy: 0.7143 - val_loss: 0.8253 - learning_rate: 7.8125e-06\nEpoch 46/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7999 - loss: 0.4811\nEpoch 46: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7987 - loss: 0.4858 - val_accuracy: 0.7143 - val_loss: 0.8297 - learning_rate: 7.8125e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8077 - loss: 0.4923 - val_accuracy: 0.7143 - val_loss: 0.8342 - learning_rate: 3.9063e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7955 - loss: 0.4984 - val_accuracy: 0.7143 - val_loss: 0.8378 - learning_rate: 3.9063e-06\nEpoch 49/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7876 - loss: 0.5318\nEpoch 49: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7892 - loss: 0.5290 - val_accuracy: 0.7211 - val_loss: 0.8426 - learning_rate: 3.9063e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8293 - loss: 0.4203 - val_accuracy: 0.7347 - val_loss: 0.8469 - learning_rate: 1.9531e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8066 - loss: 0.4906 - val_accuracy: 0.7415 - val_loss: 0.8509 - learning_rate: 1.9531e-06\nEpoch 52/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7880 - loss: 0.5002\nEpoch 52: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7880 - loss: 0.5023 - val_accuracy: 0.7415 - val_loss: 0.8561 - learning_rate: 1.9531e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8147 - loss: 0.4870 - val_accuracy: 0.7415 - val_loss: 0.8586 - learning_rate: 1.0000e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8037 - loss: 0.4978 - val_accuracy: 0.7415 - val_loss: 0.8625 - learning_rate: 1.0000e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7962 - loss: 0.4455 - val_accuracy: 0.7483 - val_loss: 0.8662 - learning_rate: 1.0000e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8108 - loss: 0.4723 - val_accuracy: 0.7483 - val_loss: 0.8701 - learning_rate: 1.0000e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8163 - loss: 0.4765 - val_accuracy: 0.7483 - val_loss: 0.8753 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8113 - loss: 0.4765 - val_accuracy: 0.7415 - val_loss: 0.8779 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7562 - loss: 0.5143 - val_accuracy: 0.7415 - val_loss: 0.8831 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8274 - loss: 0.4571 - val_accuracy: 0.7415 - val_loss: 0.8858 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7729 - loss: 0.5669 - val_accuracy: 0.7415 - val_loss: 0.8895 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7957 - loss: 0.5184 - val_accuracy: 0.7415 - val_loss: 0.8935 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8017 - loss: 0.4959 - val_accuracy: 0.7415 - val_loss: 0.8979 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8145 - loss: 0.4604 - val_accuracy: 0.7415 - val_loss: 0.9015 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8349 - loss: 0.4408 - val_accuracy: 0.7415 - val_loss: 0.9059 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8286 - loss: 0.4740 - val_accuracy: 0.7415 - val_loss: 0.9086 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7809 - loss: 0.4878 - val_accuracy: 0.7415 - val_loss: 0.9128 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8278 - loss: 0.4731 - val_accuracy: 0.7415 - val_loss: 0.9159 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7913 - loss: 0.5057 - val_accuracy: 0.7415 - val_loss: 0.9191 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7760 - loss: 0.5231 - val_accuracy: 0.7415 - val_loss: 0.9202 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8216 - loss: 0.4629 - val_accuracy: 0.7415 - val_loss: 0.9237 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8165 - loss: 0.4634 - val_accuracy: 0.7415 - val_loss: 0.9251 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8086 - loss: 0.4460 - val_accuracy: 0.7415 - val_loss: 0.9289 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8101 - loss: 0.4793 - val_accuracy: 0.7415 - val_loss: 0.9303 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8303 - loss: 0.4773 - val_accuracy: 0.7483 - val_loss: 0.9308 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7793 - loss: 0.5363 - val_accuracy: 0.7483 - val_loss: 0.9357 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8211 - loss: 0.4514 - val_accuracy: 0.7483 - val_loss: 0.9369 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8034 - loss: 0.4759 - val_accuracy: 0.7483 - val_loss: 0.9367 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7802 - loss: 0.5109 - val_accuracy: 0.7483 - val_loss: 0.9363 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7878 - loss: 0.4910 - val_accuracy: 0.7483 - val_loss: 0.9375 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7971 - loss: 0.4682 - val_accuracy: 0.7483 - val_loss: 0.9372 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8226 - loss: 0.4420 - val_accuracy: 0.7483 - val_loss: 0.9381 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7954 - loss: 0.5057 - val_accuracy: 0.7483 - val_loss: 0.9387 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7826 - loss: 0.5012 - val_accuracy: 0.7483 - val_loss: 0.9397 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8264 - loss: 0.4920 - val_accuracy: 0.7483 - val_loss: 0.9391 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8164 - loss: 0.4718 - val_accuracy: 0.7415 - val_loss: 0.9386 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7975 - loss: 0.4877 - val_accuracy: 0.7483 - val_loss: 0.9409 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8078 - loss: 0.4739 - val_accuracy: 0.7483 - val_loss: 0.9409 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8216 - loss: 0.4374 - val_accuracy: 0.7483 - val_loss: 0.9430 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8110 - loss: 0.4776 - val_accuracy: 0.7483 - val_loss: 0.9444 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7651 - loss: 0.5437 - val_accuracy: 0.7483 - val_loss: 0.9437 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7700 - loss: 0.5479 - val_accuracy: 0.7483 - val_loss: 0.9449 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8437 - loss: 0.4064 - val_accuracy: 0.7483 - val_loss: 0.9450 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8241 - loss: 0.4213 - val_accuracy: 0.7483 - val_loss: 0.9446 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7961 - loss: 0.4888 - val_accuracy: 0.7415 - val_loss: 0.9444 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7969 - loss: 0.5003 - val_accuracy: 0.7483 - val_loss: 0.9437 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7838 - loss: 0.5079 - val_accuracy: 0.7483 - val_loss: 0.9444 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7827 - loss: 0.5102 - val_accuracy: 0.7483 - val_loss: 0.9469 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8093 - loss: 0.4955 - val_accuracy: 0.7483 - val_loss: 0.9446 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8178 - loss: 0.4686 - val_accuracy: 0.7483 - val_loss: 0.9451 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.3889 - loss: 1.6456 - val_accuracy: 0.5510 - val_loss: 1.0039 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5627 - loss: 1.1977 - val_accuracy: 0.5714 - val_loss: 0.9476 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5705 - loss: 1.1614 - val_accuracy: 0.6259 - val_loss: 0.9039 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6371 - loss: 1.0249 - val_accuracy: 0.6054 - val_loss: 0.9044 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6473 - loss: 0.9468 - val_accuracy: 0.6054 - val_loss: 0.9071 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6166 - loss: 0.9463 - val_accuracy: 0.5714 - val_loss: 0.8923 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6498 - loss: 0.8825 - val_accuracy: 0.6463 - val_loss: 0.8255 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6757 - loss: 0.8234 - val_accuracy: 0.6395 - val_loss: 0.8252 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6552 - loss: 0.9031 - val_accuracy: 0.6531 - val_loss: 0.8121 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6654 - loss: 0.8279 - val_accuracy: 0.6122 - val_loss: 0.8379 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6856 - loss: 0.7465 - val_accuracy: 0.6871 - val_loss: 0.7925 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7061 - loss: 0.7099 - val_accuracy: 0.7075 - val_loss: 0.7680 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6749 - loss: 0.7596 - val_accuracy: 0.6939 - val_loss: 0.7684 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7110 - loss: 0.7042 - val_accuracy: 0.6395 - val_loss: 0.7907 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7334 - loss: 0.6687\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7331 - loss: 0.6716 - val_accuracy: 0.6395 - val_loss: 0.8140 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7435 - loss: 0.6575 - val_accuracy: 0.6327 - val_loss: 0.8068 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7305 - loss: 0.6622 - val_accuracy: 0.6463 - val_loss: 0.7783 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7688 - loss: 0.6043 - val_accuracy: 0.6599 - val_loss: 0.7589 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7423 - loss: 0.6137 - val_accuracy: 0.6667 - val_loss: 0.7504 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7405 - loss: 0.6137 - val_accuracy: 0.6735 - val_loss: 0.7463 - learning_rate: 5.0000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7701 - loss: 0.6064 - val_accuracy: 0.6463 - val_loss: 0.7714 - learning_rate: 5.0000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7738 - loss: 0.5898 - val_accuracy: 0.6667 - val_loss: 0.7577 - learning_rate: 5.0000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7899 - loss: 0.5356 - val_accuracy: 0.6939 - val_loss: 0.7388 - learning_rate: 5.0000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7924 - loss: 0.4898 - val_accuracy: 0.7143 - val_loss: 0.7371 - learning_rate: 5.0000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7646 - loss: 0.5686 - val_accuracy: 0.6939 - val_loss: 0.7254 - learning_rate: 5.0000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7845 - loss: 0.5249 - val_accuracy: 0.6803 - val_loss: 0.7373 - learning_rate: 5.0000e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7690 - loss: 0.5711 - val_accuracy: 0.6871 - val_loss: 0.7391 - learning_rate: 5.0000e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7960 - loss: 0.5252 - val_accuracy: 0.6871 - val_loss: 0.7205 - learning_rate: 5.0000e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7831 - loss: 0.5091 - val_accuracy: 0.6939 - val_loss: 0.7058 - learning_rate: 5.0000e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7716 - loss: 0.5763 - val_accuracy: 0.7075 - val_loss: 0.6907 - learning_rate: 5.0000e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8015 - loss: 0.5350 - val_accuracy: 0.6939 - val_loss: 0.7015 - learning_rate: 5.0000e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7809 - loss: 0.5210 - val_accuracy: 0.7007 - val_loss: 0.7009 - learning_rate: 5.0000e-04\nEpoch 33/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7896 - loss: 0.5308\nEpoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7921 - loss: 0.5257 - val_accuracy: 0.7007 - val_loss: 0.7165 - learning_rate: 5.0000e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8230 - loss: 0.4733 - val_accuracy: 0.7075 - val_loss: 0.7155 - learning_rate: 2.5000e-04\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8190 - loss: 0.4598 - val_accuracy: 0.7075 - val_loss: 0.7221 - learning_rate: 2.5000e-04\nEpoch 36/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7962 - loss: 0.4812\nEpoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7950 - loss: 0.4853 - val_accuracy: 0.7075 - val_loss: 0.7083 - learning_rate: 2.5000e-04\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8048 - loss: 0.4771 - val_accuracy: 0.7075 - val_loss: 0.7035 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7760 - loss: 0.4933 - val_accuracy: 0.7075 - val_loss: 0.7024 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8293 - loss: 0.4188\nEpoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8280 - loss: 0.4262 - val_accuracy: 0.7007 - val_loss: 0.6962 - learning_rate: 1.2500e-04\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8064 - loss: 0.4882 - val_accuracy: 0.6939 - val_loss: 0.6924 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8416 - loss: 0.4156 - val_accuracy: 0.7211 - val_loss: 0.6895 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8321 - loss: 0.4285 - val_accuracy: 0.7279 - val_loss: 0.6873 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8257 - loss: 0.4119 - val_accuracy: 0.7211 - val_loss: 0.6878 - learning_rate: 6.2500e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8382 - loss: 0.3915 - val_accuracy: 0.7347 - val_loss: 0.6860 - learning_rate: 6.2500e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8116 - loss: 0.4472 - val_accuracy: 0.7279 - val_loss: 0.6842 - learning_rate: 6.2500e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8438 - loss: 0.4061 - val_accuracy: 0.7211 - val_loss: 0.6817 - learning_rate: 6.2500e-05\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8529 - loss: 0.3861 - val_accuracy: 0.7279 - val_loss: 0.6856 - learning_rate: 6.2500e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8368 - loss: 0.4000 - val_accuracy: 0.7279 - val_loss: 0.6811 - learning_rate: 6.2500e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8235 - loss: 0.4371 - val_accuracy: 0.7347 - val_loss: 0.6792 - learning_rate: 6.2500e-05\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8256 - loss: 0.4677 - val_accuracy: 0.7347 - val_loss: 0.6793 - learning_rate: 6.2500e-05\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8433 - loss: 0.3861 - val_accuracy: 0.7347 - val_loss: 0.6784 - learning_rate: 6.2500e-05\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8632 - loss: 0.3502 - val_accuracy: 0.7347 - val_loss: 0.6779 - learning_rate: 6.2500e-05\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8275 - loss: 0.4257 - val_accuracy: 0.7347 - val_loss: 0.6777 - learning_rate: 6.2500e-05\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7771 - loss: 0.4540 - val_accuracy: 0.7347 - val_loss: 0.6755 - learning_rate: 6.2500e-05\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8518 - loss: 0.3949 - val_accuracy: 0.7415 - val_loss: 0.6769 - learning_rate: 6.2500e-05\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8025 - loss: 0.4367 - val_accuracy: 0.7483 - val_loss: 0.6771 - learning_rate: 6.2500e-05\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8470 - loss: 0.3930 - val_accuracy: 0.7551 - val_loss: 0.6746 - learning_rate: 6.2500e-05\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8376 - loss: 0.4004 - val_accuracy: 0.7415 - val_loss: 0.6736 - learning_rate: 6.2500e-05\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8270 - loss: 0.4077 - val_accuracy: 0.7415 - val_loss: 0.6696 - learning_rate: 6.2500e-05\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8510 - loss: 0.3693 - val_accuracy: 0.7415 - val_loss: 0.6695 - learning_rate: 6.2500e-05\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8183 - loss: 0.4198 - val_accuracy: 0.7483 - val_loss: 0.6700 - learning_rate: 6.2500e-05\nEpoch 62/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8212 - loss: 0.4179\nEpoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8248 - loss: 0.4141 - val_accuracy: 0.7551 - val_loss: 0.6722 - learning_rate: 6.2500e-05\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8426 - loss: 0.4247 - val_accuracy: 0.7483 - val_loss: 0.6701 - learning_rate: 3.1250e-05\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8297 - loss: 0.3996 - val_accuracy: 0.7551 - val_loss: 0.6698 - learning_rate: 3.1250e-05\nEpoch 65/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8199 - loss: 0.4266\nEpoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8234 - loss: 0.4213 - val_accuracy: 0.7619 - val_loss: 0.6698 - learning_rate: 3.1250e-05\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8267 - loss: 0.4190 - val_accuracy: 0.7619 - val_loss: 0.6736 - learning_rate: 1.5625e-05\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8340 - loss: 0.3861 - val_accuracy: 0.7619 - val_loss: 0.6743 - learning_rate: 1.5625e-05\nEpoch 68/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8617 - loss: 0.3744\nEpoch 68: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8601 - loss: 0.3783 - val_accuracy: 0.7619 - val_loss: 0.6743 - learning_rate: 1.5625e-05\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8390 - loss: 0.3776 - val_accuracy: 0.7619 - val_loss: 0.6769 - learning_rate: 7.8125e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8619 - loss: 0.3673 - val_accuracy: 0.7619 - val_loss: 0.6768 - learning_rate: 7.8125e-06\nEpoch 71/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8299 - loss: 0.4003\nEpoch 71: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8300 - loss: 0.3987 - val_accuracy: 0.7619 - val_loss: 0.6762 - learning_rate: 7.8125e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8440 - loss: 0.3839 - val_accuracy: 0.7619 - val_loss: 0.6781 - learning_rate: 3.9063e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8450 - loss: 0.3871 - val_accuracy: 0.7619 - val_loss: 0.6789 - learning_rate: 3.9063e-06\nEpoch 74/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8365 - loss: 0.4196\nEpoch 74: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8352 - loss: 0.4161 - val_accuracy: 0.7551 - val_loss: 0.6796 - learning_rate: 3.9063e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8447 - loss: 0.3716 - val_accuracy: 0.7483 - val_loss: 0.6807 - learning_rate: 1.9531e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8350 - loss: 0.3887 - val_accuracy: 0.7483 - val_loss: 0.6814 - learning_rate: 1.9531e-06\nEpoch 77/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8622 - loss: 0.3778\nEpoch 77: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8580 - loss: 0.3820 - val_accuracy: 0.7483 - val_loss: 0.6824 - learning_rate: 1.9531e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8527 - loss: 0.3730 - val_accuracy: 0.7483 - val_loss: 0.6816 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8346 - loss: 0.3918 - val_accuracy: 0.7483 - val_loss: 0.6831 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8305 - loss: 0.3582 - val_accuracy: 0.7483 - val_loss: 0.6819 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8077 - loss: 0.4474 - val_accuracy: 0.7551 - val_loss: 0.6802 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8598 - loss: 0.3662 - val_accuracy: 0.7551 - val_loss: 0.6803 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8486 - loss: 0.4033 - val_accuracy: 0.7619 - val_loss: 0.6799 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8585 - loss: 0.3620 - val_accuracy: 0.7551 - val_loss: 0.6801 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8150 - loss: 0.4383 - val_accuracy: 0.7551 - val_loss: 0.6783 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8447 - loss: 0.4192 - val_accuracy: 0.7551 - val_loss: 0.6782 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8251 - loss: 0.4326 - val_accuracy: 0.7551 - val_loss: 0.6780 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8820 - loss: 0.3135 - val_accuracy: 0.7551 - val_loss: 0.6782 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8467 - loss: 0.3595 - val_accuracy: 0.7551 - val_loss: 0.6816 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8599 - loss: 0.3369 - val_accuracy: 0.7551 - val_loss: 0.6805 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8648 - loss: 0.3726 - val_accuracy: 0.7551 - val_loss: 0.6823 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8593 - loss: 0.3748 - val_accuracy: 0.7551 - val_loss: 0.6807 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8397 - loss: 0.3956 - val_accuracy: 0.7551 - val_loss: 0.6800 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8336 - loss: 0.4174 - val_accuracy: 0.7619 - val_loss: 0.6788 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8397 - loss: 0.4106 - val_accuracy: 0.7619 - val_loss: 0.6769 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8395 - loss: 0.3849 - val_accuracy: 0.7619 - val_loss: 0.6765 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8382 - loss: 0.3822 - val_accuracy: 0.7619 - val_loss: 0.6763 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8460 - loss: 0.3976 - val_accuracy: 0.7551 - val_loss: 0.6772 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8446 - loss: 0.4024 - val_accuracy: 0.7619 - val_loss: 0.6748 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8670 - loss: 0.3598 - val_accuracy: 0.7619 - val_loss: 0.6755 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.3587 - loss: 1.8074 - val_accuracy: 0.6507 - val_loss: 0.9533 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5051 - loss: 1.2955 - val_accuracy: 0.6370 - val_loss: 0.9356 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5340 - loss: 1.2255 - val_accuracy: 0.6096 - val_loss: 0.9053 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5595 - loss: 1.2170 - val_accuracy: 0.5959 - val_loss: 0.8921 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5804 - loss: 1.0573 - val_accuracy: 0.6370 - val_loss: 0.8414 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5820 - loss: 1.0517 - val_accuracy: 0.6781 - val_loss: 0.8136 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6317 - loss: 0.8975 - val_accuracy: 0.6370 - val_loss: 0.7985 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6221 - loss: 1.0461 - val_accuracy: 0.6027 - val_loss: 0.8306 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6387 - loss: 0.9316 - val_accuracy: 0.5890 - val_loss: 0.8307 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6551 - loss: 0.9536 - val_accuracy: 0.6781 - val_loss: 0.7361 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6968 - loss: 0.7946 - val_accuracy: 0.6918 - val_loss: 0.7334 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7152 - loss: 0.8281 - val_accuracy: 0.6301 - val_loss: 0.7663 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6795 - loss: 0.8100 - val_accuracy: 0.6644 - val_loss: 0.7431 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7189 - loss: 0.6970 - val_accuracy: 0.7192 - val_loss: 0.7224 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7334 - loss: 0.6501 - val_accuracy: 0.7123 - val_loss: 0.7272 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7037 - loss: 0.7432 - val_accuracy: 0.7055 - val_loss: 0.7069 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7115 - loss: 0.6656 - val_accuracy: 0.7192 - val_loss: 0.7285 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7403 - loss: 0.6428 - val_accuracy: 0.6781 - val_loss: 0.7310 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7429 - loss: 0.7013 - val_accuracy: 0.7329 - val_loss: 0.6921 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7530 - loss: 0.6366 - val_accuracy: 0.7397 - val_loss: 0.6497 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7511 - loss: 0.6505 - val_accuracy: 0.7123 - val_loss: 0.6636 - learning_rate: 0.0010\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7660 - loss: 0.5641 - val_accuracy: 0.7534 - val_loss: 0.6278 - learning_rate: 0.0010\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7399 - loss: 0.6285 - val_accuracy: 0.7671 - val_loss: 0.6249 - learning_rate: 0.0010\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7657 - loss: 0.5529 - val_accuracy: 0.7740 - val_loss: 0.6194 - learning_rate: 0.0010\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7460 - loss: 0.6553 - val_accuracy: 0.7603 - val_loss: 0.6089 - learning_rate: 0.0010\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7542 - loss: 0.5640 - val_accuracy: 0.7466 - val_loss: 0.5973 - learning_rate: 0.0010\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7694 - loss: 0.6090 - val_accuracy: 0.7192 - val_loss: 0.6330 - learning_rate: 0.0010\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8077 - loss: 0.5030 - val_accuracy: 0.7055 - val_loss: 0.6860 - learning_rate: 0.0010\nEpoch 29/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7736 - loss: 0.5395\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7745 - loss: 0.5385 - val_accuracy: 0.7260 - val_loss: 0.6607 - learning_rate: 0.0010\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7844 - loss: 0.5189 - val_accuracy: 0.7397 - val_loss: 0.6281 - learning_rate: 5.0000e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8209 - loss: 0.4927 - val_accuracy: 0.7397 - val_loss: 0.6267 - learning_rate: 5.0000e-04\nEpoch 32/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8164 - loss: 0.4826\nEpoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8147 - loss: 0.4824 - val_accuracy: 0.7329 - val_loss: 0.6174 - learning_rate: 5.0000e-04\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8080 - loss: 0.4642 - val_accuracy: 0.7329 - val_loss: 0.6077 - learning_rate: 2.5000e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8241 - loss: 0.4671 - val_accuracy: 0.7329 - val_loss: 0.6013 - learning_rate: 2.5000e-04\nEpoch 35/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8134 - loss: 0.4583\nEpoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8151 - loss: 0.4559 - val_accuracy: 0.7397 - val_loss: 0.5981 - learning_rate: 2.5000e-04\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8515 - loss: 0.3940 - val_accuracy: 0.7466 - val_loss: 0.6013 - learning_rate: 1.2500e-04\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7969 - loss: 0.4608 - val_accuracy: 0.7397 - val_loss: 0.6085 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8282 - loss: 0.4615\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8337 - loss: 0.4474 - val_accuracy: 0.7397 - val_loss: 0.6140 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7959 - loss: 0.4810 - val_accuracy: 0.7397 - val_loss: 0.6145 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8483 - loss: 0.4042 - val_accuracy: 0.7397 - val_loss: 0.6132 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8460 - loss: 0.3977\nEpoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8451 - loss: 0.3984 - val_accuracy: 0.7397 - val_loss: 0.6128 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8517 - loss: 0.3804 - val_accuracy: 0.7397 - val_loss: 0.6106 - learning_rate: 3.1250e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8340 - loss: 0.4044 - val_accuracy: 0.7329 - val_loss: 0.6114 - learning_rate: 3.1250e-05\nEpoch 44/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8657 - loss: 0.3592\nEpoch 44: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8631 - loss: 0.3639 - val_accuracy: 0.7260 - val_loss: 0.6103 - learning_rate: 3.1250e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8211 - loss: 0.4166 - val_accuracy: 0.7329 - val_loss: 0.6100 - learning_rate: 1.5625e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8485 - loss: 0.3895 - val_accuracy: 0.7260 - val_loss: 0.6125 - learning_rate: 1.5625e-05\nEpoch 47/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8471 - loss: 0.3752\nEpoch 47: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8470 - loss: 0.3769 - val_accuracy: 0.7260 - val_loss: 0.6124 - learning_rate: 1.5625e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8196 - loss: 0.4140 - val_accuracy: 0.7260 - val_loss: 0.6124 - learning_rate: 7.8125e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8743 - loss: 0.3709 - val_accuracy: 0.7192 - val_loss: 0.6125 - learning_rate: 7.8125e-06\nEpoch 50/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8487 - loss: 0.4149\nEpoch 50: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8473 - loss: 0.4163 - val_accuracy: 0.7192 - val_loss: 0.6110 - learning_rate: 7.8125e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8315 - loss: 0.4049 - val_accuracy: 0.7192 - val_loss: 0.6112 - learning_rate: 3.9063e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8483 - loss: 0.3923 - val_accuracy: 0.7192 - val_loss: 0.6116 - learning_rate: 3.9063e-06\nEpoch 53/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8328 - loss: 0.3990\nEpoch 53: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8343 - loss: 0.3972 - val_accuracy: 0.7260 - val_loss: 0.6101 - learning_rate: 3.9063e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8504 - loss: 0.3841 - val_accuracy: 0.7192 - val_loss: 0.6110 - learning_rate: 1.9531e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8511 - loss: 0.4025 - val_accuracy: 0.7329 - val_loss: 0.6110 - learning_rate: 1.9531e-06\nEpoch 56/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8343 - loss: 0.4058\nEpoch 56: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8334 - loss: 0.4081 - val_accuracy: 0.7329 - val_loss: 0.6107 - learning_rate: 1.9531e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8611 - loss: 0.3752 - val_accuracy: 0.7397 - val_loss: 0.6119 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8478 - loss: 0.4149 - val_accuracy: 0.7329 - val_loss: 0.6129 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8366 - loss: 0.4501 - val_accuracy: 0.7397 - val_loss: 0.6118 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8348 - loss: 0.3887 - val_accuracy: 0.7466 - val_loss: 0.6108 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8414 - loss: 0.3956 - val_accuracy: 0.7397 - val_loss: 0.6114 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8361 - loss: 0.4088 - val_accuracy: 0.7534 - val_loss: 0.6097 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8562 - loss: 0.4125 - val_accuracy: 0.7534 - val_loss: 0.6106 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8648 - loss: 0.3551 - val_accuracy: 0.7466 - val_loss: 0.6114 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7684 - loss: 0.4681 - val_accuracy: 0.7466 - val_loss: 0.6129 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8224 - loss: 0.4262 - val_accuracy: 0.7534 - val_loss: 0.6116 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8539 - loss: 0.3743 - val_accuracy: 0.7534 - val_loss: 0.6113 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8372 - loss: 0.4186 - val_accuracy: 0.7534 - val_loss: 0.6136 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8690 - loss: 0.3370 - val_accuracy: 0.7534 - val_loss: 0.6137 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8304 - loss: 0.4220 - val_accuracy: 0.7534 - val_loss: 0.6138 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8315 - loss: 0.4382 - val_accuracy: 0.7534 - val_loss: 0.6149 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8517 - loss: 0.4083 - val_accuracy: 0.7534 - val_loss: 0.6146 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8394 - loss: 0.4042 - val_accuracy: 0.7534 - val_loss: 0.6147 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8451 - loss: 0.4282 - val_accuracy: 0.7534 - val_loss: 0.6143 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8182 - loss: 0.4263 - val_accuracy: 0.7534 - val_loss: 0.6138 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8474 - loss: 0.3825 - val_accuracy: 0.7534 - val_loss: 0.6144 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8007 - loss: 0.4662 - val_accuracy: 0.7534 - val_loss: 0.6163 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8519 - loss: 0.3805 - val_accuracy: 0.7534 - val_loss: 0.6166 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8641 - loss: 0.3975 - val_accuracy: 0.7534 - val_loss: 0.6168 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8569 - loss: 0.4108 - val_accuracy: 0.7534 - val_loss: 0.6160 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8301 - loss: 0.4007 - val_accuracy: 0.7534 - val_loss: 0.6174 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8414 - loss: 0.4148 - val_accuracy: 0.7534 - val_loss: 0.6167 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8600 - loss: 0.3834 - val_accuracy: 0.7534 - val_loss: 0.6177 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8194 - loss: 0.4396 - val_accuracy: 0.7534 - val_loss: 0.6165 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8026 - loss: 0.4812 - val_accuracy: 0.7534 - val_loss: 0.6158 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8117 - loss: 0.4550 - val_accuracy: 0.7534 - val_loss: 0.6174 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8469 - loss: 0.3905 - val_accuracy: 0.7534 - val_loss: 0.6168 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8511 - loss: 0.3726 - val_accuracy: 0.7534 - val_loss: 0.6167 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8293 - loss: 0.4088 - val_accuracy: 0.7603 - val_loss: 0.6168 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8726 - loss: 0.3669 - val_accuracy: 0.7534 - val_loss: 0.6168 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8513 - loss: 0.3850 - val_accuracy: 0.7534 - val_loss: 0.6165 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8424 - loss: 0.4050 - val_accuracy: 0.7534 - val_loss: 0.6170 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8287 - loss: 0.4336 - val_accuracy: 0.7534 - val_loss: 0.6175 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7989 - loss: 0.4894 - val_accuracy: 0.7534 - val_loss: 0.6173 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8515 - loss: 0.3913 - val_accuracy: 0.7603 - val_loss: 0.6175 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8291 - loss: 0.4306 - val_accuracy: 0.7603 - val_loss: 0.6182 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8263 - loss: 0.4279 - val_accuracy: 0.7603 - val_loss: 0.6169 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8325 - loss: 0.4221 - val_accuracy: 0.7603 - val_loss: 0.6169 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8162 - loss: 0.4379 - val_accuracy: 0.7603 - val_loss: 0.6171 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8327 - loss: 0.4481 - val_accuracy: 0.7603 - val_loss: 0.6155 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.4124 - loss: 1.5863 - val_accuracy: 0.6233 - val_loss: 0.9978 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5409 - loss: 1.2940 - val_accuracy: 0.6164 - val_loss: 0.9290 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5076 - loss: 1.2315 - val_accuracy: 0.6301 - val_loss: 0.9063 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6078 - loss: 1.0454 - val_accuracy: 0.6164 - val_loss: 0.9455 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6079 - loss: 1.0900 - val_accuracy: 0.5685 - val_loss: 1.0452 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6322 - loss: 0.9380\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6311 - loss: 0.9370 - val_accuracy: 0.5616 - val_loss: 1.0118 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6673 - loss: 0.9328 - val_accuracy: 0.5616 - val_loss: 0.9834 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6682 - loss: 0.8533 - val_accuracy: 0.5822 - val_loss: 0.9598 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6549 - loss: 0.7975 - val_accuracy: 0.6027 - val_loss: 0.8844 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.6776 - loss: 0.7665 - val_accuracy: 0.6301 - val_loss: 0.8490 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6911 - loss: 0.8189 - val_accuracy: 0.6370 - val_loss: 0.8411 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6755 - loss: 0.7892 - val_accuracy: 0.5959 - val_loss: 0.8551 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6910 - loss: 0.7589 - val_accuracy: 0.6164 - val_loss: 0.8351 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6774 - loss: 0.7254 - val_accuracy: 0.6096 - val_loss: 0.8195 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7236 - loss: 0.7324 - val_accuracy: 0.6164 - val_loss: 0.8061 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7503 - loss: 0.6181 - val_accuracy: 0.6233 - val_loss: 0.8034 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7557 - loss: 0.6218 - val_accuracy: 0.6301 - val_loss: 0.7971 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7327 - loss: 0.6472 - val_accuracy: 0.6507 - val_loss: 0.7800 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6999 - loss: 0.7536 - val_accuracy: 0.6438 - val_loss: 0.7647 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7620 - loss: 0.5725 - val_accuracy: 0.6438 - val_loss: 0.7571 - learning_rate: 5.0000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7519 - loss: 0.6446 - val_accuracy: 0.6712 - val_loss: 0.7657 - learning_rate: 5.0000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7682 - loss: 0.5805 - val_accuracy: 0.6986 - val_loss: 0.7635 - learning_rate: 5.0000e-04\nEpoch 23/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7400 - loss: 0.5718\nEpoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7383 - loss: 0.5804 - val_accuracy: 0.6918 - val_loss: 0.7592 - learning_rate: 5.0000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7484 - loss: 0.5490 - val_accuracy: 0.6918 - val_loss: 0.7543 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7856 - loss: 0.5777 - val_accuracy: 0.6781 - val_loss: 0.7414 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7930 - loss: 0.5293 - val_accuracy: 0.6781 - val_loss: 0.7332 - learning_rate: 2.5000e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7950 - loss: 0.5859 - val_accuracy: 0.6849 - val_loss: 0.7296 - learning_rate: 2.5000e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8029 - loss: 0.5303 - val_accuracy: 0.6781 - val_loss: 0.7376 - learning_rate: 2.5000e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7557 - loss: 0.5826 - val_accuracy: 0.6849 - val_loss: 0.7503 - learning_rate: 2.5000e-04\nEpoch 30/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7899 - loss: 0.5225\nEpoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7905 - loss: 0.5213 - val_accuracy: 0.6644 - val_loss: 0.7601 - learning_rate: 2.5000e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7809 - loss: 0.5613 - val_accuracy: 0.6712 - val_loss: 0.7545 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8147 - loss: 0.4946 - val_accuracy: 0.6781 - val_loss: 0.7507 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8071 - loss: 0.5146\nEpoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8081 - loss: 0.5148 - val_accuracy: 0.6781 - val_loss: 0.7572 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8031 - loss: 0.4717 - val_accuracy: 0.6781 - val_loss: 0.7617 - learning_rate: 6.2500e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7900 - loss: 0.5349 - val_accuracy: 0.6849 - val_loss: 0.7640 - learning_rate: 6.2500e-05\nEpoch 36/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7748 - loss: 0.5761\nEpoch 36: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7776 - loss: 0.5668 - val_accuracy: 0.6849 - val_loss: 0.7615 - learning_rate: 6.2500e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8287 - loss: 0.4140 - val_accuracy: 0.6849 - val_loss: 0.7612 - learning_rate: 3.1250e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8210 - loss: 0.4528 - val_accuracy: 0.6849 - val_loss: 0.7622 - learning_rate: 3.1250e-05\nEpoch 39/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7948 - loss: 0.5104\nEpoch 39: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7983 - loss: 0.5071 - val_accuracy: 0.6849 - val_loss: 0.7629 - learning_rate: 3.1250e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8106 - loss: 0.4544 - val_accuracy: 0.6849 - val_loss: 0.7647 - learning_rate: 1.5625e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7808 - loss: 0.5582 - val_accuracy: 0.6849 - val_loss: 0.7670 - learning_rate: 1.5625e-05\nEpoch 42/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7812 - loss: 0.5461\nEpoch 42: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7822 - loss: 0.5460 - val_accuracy: 0.6849 - val_loss: 0.7694 - learning_rate: 1.5625e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7942 - loss: 0.5143 - val_accuracy: 0.6781 - val_loss: 0.7735 - learning_rate: 7.8125e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7801 - loss: 0.5539 - val_accuracy: 0.6781 - val_loss: 0.7758 - learning_rate: 7.8125e-06\nEpoch 45/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8190 - loss: 0.4974\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8166 - loss: 0.4984 - val_accuracy: 0.6849 - val_loss: 0.7796 - learning_rate: 7.8125e-06\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8150 - loss: 0.4614 - val_accuracy: 0.6849 - val_loss: 0.7822 - learning_rate: 3.9063e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8029 - loss: 0.4353 - val_accuracy: 0.6849 - val_loss: 0.7846 - learning_rate: 3.9063e-06\nEpoch 48/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8189 - loss: 0.4565\nEpoch 48: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8131 - loss: 0.4687 - val_accuracy: 0.6849 - val_loss: 0.7867 - learning_rate: 3.9063e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8361 - loss: 0.4298 - val_accuracy: 0.6781 - val_loss: 0.7895 - learning_rate: 1.9531e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8087 - loss: 0.4891 - val_accuracy: 0.6781 - val_loss: 0.7912 - learning_rate: 1.9531e-06\nEpoch 51/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8010 - loss: 0.5547\nEpoch 51: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8015 - loss: 0.5480 - val_accuracy: 0.6781 - val_loss: 0.7929 - learning_rate: 1.9531e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8028 - loss: 0.4828 - val_accuracy: 0.6781 - val_loss: 0.7965 - learning_rate: 1.0000e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7971 - loss: 0.5230 - val_accuracy: 0.6781 - val_loss: 0.7984 - learning_rate: 1.0000e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8245 - loss: 0.4963 - val_accuracy: 0.6781 - val_loss: 0.8008 - learning_rate: 1.0000e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7798 - loss: 0.5178 - val_accuracy: 0.6781 - val_loss: 0.8018 - learning_rate: 1.0000e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8006 - loss: 0.4927 - val_accuracy: 0.6781 - val_loss: 0.8038 - learning_rate: 1.0000e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8242 - loss: 0.5060 - val_accuracy: 0.6781 - val_loss: 0.8066 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7934 - loss: 0.5570 - val_accuracy: 0.6781 - val_loss: 0.8088 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8093 - loss: 0.4580 - val_accuracy: 0.6781 - val_loss: 0.8123 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8003 - loss: 0.4997 - val_accuracy: 0.6781 - val_loss: 0.8152 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8107 - loss: 0.4965 - val_accuracy: 0.6781 - val_loss: 0.8153 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7908 - loss: 0.5072 - val_accuracy: 0.6781 - val_loss: 0.8170 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7967 - loss: 0.5062 - val_accuracy: 0.6781 - val_loss: 0.8208 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8167 - loss: 0.4468 - val_accuracy: 0.6781 - val_loss: 0.8236 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7931 - loss: 0.5053 - val_accuracy: 0.6781 - val_loss: 0.8255 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7861 - loss: 0.5174 - val_accuracy: 0.6781 - val_loss: 0.8268 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8147 - loss: 0.4540 - val_accuracy: 0.6781 - val_loss: 0.8277 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8053 - loss: 0.5027 - val_accuracy: 0.6781 - val_loss: 0.8298 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7814 - loss: 0.5214 - val_accuracy: 0.6781 - val_loss: 0.8305 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8255 - loss: 0.4618 - val_accuracy: 0.6781 - val_loss: 0.8305 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7927 - loss: 0.5335 - val_accuracy: 0.6849 - val_loss: 0.8330 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8010 - loss: 0.5046 - val_accuracy: 0.6849 - val_loss: 0.8334 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7902 - loss: 0.5088 - val_accuracy: 0.6849 - val_loss: 0.8363 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7974 - loss: 0.4526 - val_accuracy: 0.6849 - val_loss: 0.8374 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8263 - loss: 0.4469 - val_accuracy: 0.6781 - val_loss: 0.8368 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8199 - loss: 0.4776 - val_accuracy: 0.6849 - val_loss: 0.8385 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8157 - loss: 0.4673 - val_accuracy: 0.6849 - val_loss: 0.8394 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7843 - loss: 0.5514 - val_accuracy: 0.6849 - val_loss: 0.8418 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8043 - loss: 0.4894 - val_accuracy: 0.6849 - val_loss: 0.8435 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8119 - loss: 0.4809 - val_accuracy: 0.6781 - val_loss: 0.8412 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8262 - loss: 0.4475 - val_accuracy: 0.6781 - val_loss: 0.8418 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8008 - loss: 0.4862 - val_accuracy: 0.6781 - val_loss: 0.8427 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7858 - loss: 0.4959 - val_accuracy: 0.6781 - val_loss: 0.8436 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8189 - loss: 0.4747 - val_accuracy: 0.6849 - val_loss: 0.8438 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8162 - loss: 0.4558 - val_accuracy: 0.6781 - val_loss: 0.8433 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7870 - loss: 0.5003 - val_accuracy: 0.6849 - val_loss: 0.8433 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8294 - loss: 0.4609 - val_accuracy: 0.6849 - val_loss: 0.8456 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8359 - loss: 0.4386 - val_accuracy: 0.6849 - val_loss: 0.8464 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8148 - loss: 0.5160 - val_accuracy: 0.6849 - val_loss: 0.8463 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7933 - loss: 0.5516 - val_accuracy: 0.6849 - val_loss: 0.8469 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7900 - loss: 0.5211 - val_accuracy: 0.6781 - val_loss: 0.8456 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8039 - loss: 0.4702 - val_accuracy: 0.6781 - val_loss: 0.8463 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8187 - loss: 0.4265 - val_accuracy: 0.6781 - val_loss: 0.8471 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8222 - loss: 0.4718 - val_accuracy: 0.6712 - val_loss: 0.8467 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7954 - loss: 0.4997 - val_accuracy: 0.6781 - val_loss: 0.8464 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7906 - loss: 0.5442 - val_accuracy: 0.6781 - val_loss: 0.8462 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7781 - loss: 0.6039 - val_accuracy: 0.6781 - val_loss: 0.8451 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7947 - loss: 0.5131 - val_accuracy: 0.6781 - val_loss: 0.8449 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8162 - loss: 0.4610 - val_accuracy: 0.6781 - val_loss: 0.8438 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8264 - loss: 0.4563 - val_accuracy: 0.6781 - val_loss: 0.8416 - learning_rate: 1.0000e-06\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.3868 - loss: 1.7798 - val_accuracy: 0.6233 - val_loss: 1.0115 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5294 - loss: 1.2346 - val_accuracy: 0.6575 - val_loss: 0.9280 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5928 - loss: 1.0792 - val_accuracy: 0.6096 - val_loss: 0.8976 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6429 - loss: 1.0294 - val_accuracy: 0.6164 - val_loss: 0.8734 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6467 - loss: 0.9295 - val_accuracy: 0.5685 - val_loss: 0.9022 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6256 - loss: 0.9492 - val_accuracy: 0.6233 - val_loss: 0.8522 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7125 - loss: 0.8123 - val_accuracy: 0.5959 - val_loss: 0.8514 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6757 - loss: 0.8191 - val_accuracy: 0.6507 - val_loss: 0.8263 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7071 - loss: 0.7845 - val_accuracy: 0.6438 - val_loss: 0.8128 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6779 - loss: 0.8288 - val_accuracy: 0.6712 - val_loss: 0.7788 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7070 - loss: 0.7906 - val_accuracy: 0.6849 - val_loss: 0.7728 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7212 - loss: 0.7281 - val_accuracy: 0.6781 - val_loss: 0.7636 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7320 - loss: 0.6912 - val_accuracy: 0.6575 - val_loss: 0.7448 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7442 - loss: 0.7075 - val_accuracy: 0.6644 - val_loss: 0.7651 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7103 - loss: 0.7203 - val_accuracy: 0.6507 - val_loss: 0.7598 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6857 - loss: 0.7449 - val_accuracy: 0.6781 - val_loss: 0.7213 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7204 - loss: 0.6712 - val_accuracy: 0.6233 - val_loss: 0.7311 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7560 - loss: 0.6208 - val_accuracy: 0.6164 - val_loss: 0.7841 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7588 - loss: 0.6469\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7583 - loss: 0.6457 - val_accuracy: 0.6370 - val_loss: 0.7472 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7274 - loss: 0.6437 - val_accuracy: 0.6438 - val_loss: 0.7405 - learning_rate: 5.0000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7741 - loss: 0.5653 - val_accuracy: 0.6438 - val_loss: 0.7306 - learning_rate: 5.0000e-04\nEpoch 22/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7266 - loss: 0.6338\nEpoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7288 - loss: 0.6299 - val_accuracy: 0.6507 - val_loss: 0.7307 - learning_rate: 5.0000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7623 - loss: 0.5867 - val_accuracy: 0.6507 - val_loss: 0.7318 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7652 - loss: 0.5554 - val_accuracy: 0.6507 - val_loss: 0.7367 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7811 - loss: 0.5286\nEpoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7790 - loss: 0.5353 - val_accuracy: 0.6849 - val_loss: 0.7334 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8061 - loss: 0.5179 - val_accuracy: 0.6644 - val_loss: 0.7262 - learning_rate: 1.2500e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7848 - loss: 0.5282 - val_accuracy: 0.6507 - val_loss: 0.7193 - learning_rate: 1.2500e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8133 - loss: 0.4983 - val_accuracy: 0.6507 - val_loss: 0.7169 - learning_rate: 1.2500e-04\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7972 - loss: 0.4763 - val_accuracy: 0.6712 - val_loss: 0.7144 - learning_rate: 1.2500e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8018 - loss: 0.5088 - val_accuracy: 0.6781 - val_loss: 0.7116 - learning_rate: 1.2500e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7968 - loss: 0.5092 - val_accuracy: 0.6849 - val_loss: 0.7091 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8002 - loss: 0.5202 - val_accuracy: 0.6918 - val_loss: 0.7091 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7933 - loss: 0.4888 - val_accuracy: 0.6918 - val_loss: 0.7101 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7979 - loss: 0.4912 - val_accuracy: 0.6918 - val_loss: 0.7019 - learning_rate: 1.2500e-04\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8048 - loss: 0.4686 - val_accuracy: 0.6918 - val_loss: 0.6998 - learning_rate: 1.2500e-04\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7823 - loss: 0.5289 - val_accuracy: 0.6918 - val_loss: 0.7032 - learning_rate: 1.2500e-04\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8499 - loss: 0.4142 - val_accuracy: 0.6918 - val_loss: 0.7024 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7980 - loss: 0.5240\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7991 - loss: 0.5210 - val_accuracy: 0.6918 - val_loss: 0.7034 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8159 - loss: 0.4520 - val_accuracy: 0.6849 - val_loss: 0.7046 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8018 - loss: 0.4979 - val_accuracy: 0.6849 - val_loss: 0.7051 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8222 - loss: 0.4613\nEpoch 41: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8213 - loss: 0.4617 - val_accuracy: 0.6849 - val_loss: 0.7097 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7721 - loss: 0.5349 - val_accuracy: 0.6781 - val_loss: 0.7066 - learning_rate: 3.1250e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7846 - loss: 0.5011 - val_accuracy: 0.6849 - val_loss: 0.7056 - learning_rate: 3.1250e-05\nEpoch 44/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8017 - loss: 0.4750\nEpoch 44: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8036 - loss: 0.4717 - val_accuracy: 0.6781 - val_loss: 0.7033 - learning_rate: 3.1250e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8067 - loss: 0.4615 - val_accuracy: 0.6918 - val_loss: 0.7001 - learning_rate: 1.5625e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8029 - loss: 0.4639 - val_accuracy: 0.6986 - val_loss: 0.6995 - learning_rate: 1.5625e-05\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8070 - loss: 0.4672 - val_accuracy: 0.7055 - val_loss: 0.6990 - learning_rate: 1.5625e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8132 - loss: 0.4472 - val_accuracy: 0.7055 - val_loss: 0.6981 - learning_rate: 1.5625e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7828 - loss: 0.5029 - val_accuracy: 0.7055 - val_loss: 0.6945 - learning_rate: 1.5625e-05\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8142 - loss: 0.4701 - val_accuracy: 0.7055 - val_loss: 0.6932 - learning_rate: 1.5625e-05\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8053 - loss: 0.4733 - val_accuracy: 0.7123 - val_loss: 0.6931 - learning_rate: 1.5625e-05\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8099 - loss: 0.4731 - val_accuracy: 0.7192 - val_loss: 0.6929 - learning_rate: 1.5625e-05\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8164 - loss: 0.4696 - val_accuracy: 0.7192 - val_loss: 0.6924 - learning_rate: 1.5625e-05\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8176 - loss: 0.4314 - val_accuracy: 0.7192 - val_loss: 0.6916 - learning_rate: 1.5625e-05\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7832 - loss: 0.4508 - val_accuracy: 0.7123 - val_loss: 0.6923 - learning_rate: 1.5625e-05\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8090 - loss: 0.4686 - val_accuracy: 0.7123 - val_loss: 0.6919 - learning_rate: 1.5625e-05\nEpoch 57/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8181 - loss: 0.4496\nEpoch 57: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8164 - loss: 0.4538 - val_accuracy: 0.7123 - val_loss: 0.6921 - learning_rate: 1.5625e-05\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7905 - loss: 0.4877 - val_accuracy: 0.7123 - val_loss: 0.6920 - learning_rate: 7.8125e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8024 - loss: 0.4597 - val_accuracy: 0.7123 - val_loss: 0.6934 - learning_rate: 7.8125e-06\nEpoch 60/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8144 - loss: 0.4220\nEpoch 60: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8125 - loss: 0.4260 - val_accuracy: 0.7123 - val_loss: 0.6933 - learning_rate: 7.8125e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8494 - loss: 0.3899 - val_accuracy: 0.7123 - val_loss: 0.6941 - learning_rate: 3.9063e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8181 - loss: 0.4562 - val_accuracy: 0.7123 - val_loss: 0.6955 - learning_rate: 3.9063e-06\nEpoch 63/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8123 - loss: 0.4568\nEpoch 63: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8148 - loss: 0.4537 - val_accuracy: 0.7123 - val_loss: 0.6960 - learning_rate: 3.9063e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8224 - loss: 0.4496 - val_accuracy: 0.7123 - val_loss: 0.6965 - learning_rate: 1.9531e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8137 - loss: 0.4367 - val_accuracy: 0.7123 - val_loss: 0.6970 - learning_rate: 1.9531e-06\nEpoch 66/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8159 - loss: 0.4509\nEpoch 66: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8137 - loss: 0.4545 - val_accuracy: 0.7123 - val_loss: 0.6976 - learning_rate: 1.9531e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8078 - loss: 0.4264 - val_accuracy: 0.7123 - val_loss: 0.6982 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8257 - loss: 0.4187 - val_accuracy: 0.7123 - val_loss: 0.6981 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7927 - loss: 0.5189 - val_accuracy: 0.7123 - val_loss: 0.6989 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8283 - loss: 0.4463 - val_accuracy: 0.7123 - val_loss: 0.6980 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7866 - loss: 0.5357 - val_accuracy: 0.7123 - val_loss: 0.6991 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8167 - loss: 0.4621 - val_accuracy: 0.7055 - val_loss: 0.6992 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8066 - loss: 0.4895 - val_accuracy: 0.7055 - val_loss: 0.6999 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8113 - loss: 0.4541 - val_accuracy: 0.7055 - val_loss: 0.6999 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8129 - loss: 0.4590 - val_accuracy: 0.7055 - val_loss: 0.7012 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8253 - loss: 0.4224 - val_accuracy: 0.7055 - val_loss: 0.7023 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8152 - loss: 0.4524 - val_accuracy: 0.7123 - val_loss: 0.7038 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8260 - loss: 0.4904 - val_accuracy: 0.7123 - val_loss: 0.7037 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8239 - loss: 0.4087 - val_accuracy: 0.7123 - val_loss: 0.7042 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.7882 - loss: 0.4896 - val_accuracy: 0.7192 - val_loss: 0.7047 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8597 - loss: 0.4018 - val_accuracy: 0.7260 - val_loss: 0.7065 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8209 - loss: 0.4620 - val_accuracy: 0.7192 - val_loss: 0.7067 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7981 - loss: 0.4840 - val_accuracy: 0.7192 - val_loss: 0.7075 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7935 - loss: 0.5057 - val_accuracy: 0.7192 - val_loss: 0.7075 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8117 - loss: 0.4783 - val_accuracy: 0.7192 - val_loss: 0.7081 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7999 - loss: 0.4766 - val_accuracy: 0.7192 - val_loss: 0.7080 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8342 - loss: 0.4097 - val_accuracy: 0.7192 - val_loss: 0.7084 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8250 - loss: 0.4382 - val_accuracy: 0.7192 - val_loss: 0.7083 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8179 - loss: 0.4705 - val_accuracy: 0.7192 - val_loss: 0.7097 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7953 - loss: 0.4875 - val_accuracy: 0.7192 - val_loss: 0.7091 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7999 - loss: 0.4734 - val_accuracy: 0.7260 - val_loss: 0.7086 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8203 - loss: 0.4263 - val_accuracy: 0.7192 - val_loss: 0.7081 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8091 - loss: 0.4387 - val_accuracy: 0.7192 - val_loss: 0.7080 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8185 - loss: 0.4397 - val_accuracy: 0.7192 - val_loss: 0.7087 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8375 - loss: 0.4169 - val_accuracy: 0.7192 - val_loss: 0.7087 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7776 - loss: 0.5119 - val_accuracy: 0.7192 - val_loss: 0.7087 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8038 - loss: 0.4479 - val_accuracy: 0.7192 - val_loss: 0.7090 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8115 - loss: 0.4750 - val_accuracy: 0.7192 - val_loss: 0.7098 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8415 - loss: 0.4177 - val_accuracy: 0.7192 - val_loss: 0.7099 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8187 - loss: 0.4635 - val_accuracy: 0.7192 - val_loss: 0.7104 - learning_rate: 1.0000e-06\nMean Accuracy: 0.7335\n","output_type":"stream"}],"execution_count":322}]}