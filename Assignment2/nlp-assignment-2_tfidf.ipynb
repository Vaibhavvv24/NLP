{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316566,"sourceType":"datasetVersion","datasetId":4245661}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # Optional: Improves WordNet performance\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:34.371381Z","iopub.execute_input":"2025-03-13T19:16:34.371838Z","iopub.status.idle":"2025-03-13T19:16:34.402593Z","shell.execute_reply.started":"2025-03-13T19:16:34.371805Z","shell.execute_reply":"2025-03-13T19:16:34.401399Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\n","output_type":"stream"}],"execution_count":323},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:34.404442Z","iopub.execute_input":"2025-03-13T19:16:34.404838Z","iopub.status.idle":"2025-03-13T19:16:34.420554Z","shell.execute_reply.started":"2025-03-13T19:16:34.404796Z","shell.execute_reply":"2025-03-13T19:16:34.419372Z"}},"outputs":[],"execution_count":324},{"cell_type":"code","source":"import nltk\nimport subprocess\n\nnltk.download('wordnet', download_dir='/kaggle/working/')\nnltk.download('omw-1.4', download_dir='/kaggle/working/')\n\ncommand = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\nsubprocess.run(command.split())\n\nnltk.data.path.append('/kaggle/working/')\n\nlemmatizer = WordNetLemmatizer()\n\ntrain_df['Sentiment'] = train_df['Sentiment'].astype(str).str.strip().str.lower().apply(lemmatizer.lemmatize)\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:34.422697Z","iopub.execute_input":"2025-03-13T19:16:34.423057Z","iopub.status.idle":"2025-03-13T19:16:34.530097Z","shell.execute_reply.started":"2025-03-13T19:16:34.423025Z","shell.execute_reply":"2025-03-13T19:16:34.528775Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /kaggle/working/...\n[nltk_data]   Package omw-1.4 is already up-to-date!\nSentiment\npositive                45\njoy                     44\nexcitement              37\ncontentment             19\nneutral                 18\ngratitude               18\ncuriosity               16\nserenity                15\nhappy                   14\nnostalgia               11\ndespair                 11\ngrief                    9\nawe                      9\nsad                      9\nhopeful                  9\nloneliness               9\nembarrassed              8\nacceptance               8\nconfusion                8\neuphoria                 7\nelation                  7\nenthusiasm               7\npride                    7\ndetermination            7\nregret                   6\nfrustration              6\nambivalence              6\nmelancholy               6\nnumbness                 6\nplayful                  6\nindifference             6\nbad                      6\nhate                     6\nsurprise                 6\ninspiration              6\nbitterness               5\nfrustrated               5\nbetrayal                 5\nhope                     5\nhappiness                5\ndisgust                  5\ninspired                 5\nempowerment              5\nproud                    4\ngrateful                 4\nthrill                   4\noverwhelmed              4\ncompassionate            4\nreflection               4\nenchantment              4\ndesolation               4\nnegative                 4\nadmiration               4\nboredom                  4\ncalmness                 4\nreverence                4\nfulfillment              4\ncompassion               4\narousal                  4\ntenderness               4\namusement                3\nanticipation             3\nenvious                  3\ndismissive               3\nbitter                   3\nheartbreak               3\nadventure                3\ndevastated               3\nsatisfaction             3\nwonder                   3\naccomplishment           3\ncreativity               3\nharmony                  3\nkind                     3\njealous                  3\nlove                     3\nfearful                  3\nconfident                3\nfree-spirited            3\nresentment               3\nempathetic               3\nshame                    3\njealousy                 3\nsorrow                   2\nexploration              2\ncaptivation              2\ntranquility              2\nradiance                 2\nloss                     2\nmischievous              2\nrejuvenation             2\nresilience               2\nemotion                  2\ndisappointment           2\nisolation                2\ncoziness                 2\nwhimsy                   2\nintimidation             2\ncontemplation            2\nanxiety                  2\nhelplessness             2\nenvy                     2\nanger                    2\nzest                     2\nyearning                 2\napprehensive             2\nfear                     2\nsadness                  2\nenjoyment                2\nadoration                2\naffection                2\ndisappointed             2\nengagement               1\nobstacle                 1\nheartwarming             1\ntriumph                  1\nsuspense                 1\ntouched                  1\nrunway creativity        1\nsympathy                 1\niconic                   1\nconnection               1\nhypnotic                 1\ncolorful                 1\necstasy                  1\ncharm                    1\njourney                  1\npressure                 1\nocean's freedom          1\nrelief                   1\ncreative inspiration     1\ncelestial wonder         1\nnature's beauty          1\nthrilling journey        1\nwinter magic             1\nculinary adventure       1\nmesmerizing              1\nvibrancy                 1\nimagination              1\nenvisioning history      1\njoy in baking            1\nbreakthrough             1\nsolace                   1\ncelebration              1\nmiscalculation           1\nrenewed effort           1\nwhispers of the past     1\nchallenge                1\nmindfulness              1\nenergy                   1\nmelodic                  1\nmotivation               1\nculinaryodyssey          1\nartisticburst            1\nadrenaline               1\ndazzle                   1\nfreedom                  1\ninnerjourney             1\nfestivejoy               1\njoyfulreunion            1\ngrandeur                 1\nblessed                  1\nappreciation             1\nconfidence               1\nwonderment               1\noptimism                 1\npensive                  1\nplayfuljoy               1\nelegance                 1\nimmersion                1\nspark                    1\nmarvel                   1\noverjoyed                1\ndreamchaser              1\nromance                  1\namazement                1\nsuccess                  1\nfriendship               1\nkindness                 1\npositivity               1\nsolitude                 1\nheartache                1\nruin                     1\ndesperation              1\ndarkness                 1\nexhaustion               1\nlostlove                 1\nemotionalstorm           1\nsuffering                1\nbittersweet              1\nintrigue                 1\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":325},{"cell_type":"code","source":"unique_values = set()\nunique_values.update(train_df['Sentiment'])\nunique_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:34.531416Z","iopub.execute_input":"2025-03-13T19:16:34.531767Z","iopub.status.idle":"2025-03-13T19:16:34.541864Z","shell.execute_reply.started":"2025-03-13T19:16:34.531727Z","shell.execute_reply":"2025-03-13T19:16:34.540635Z"}},"outputs":[{"execution_count":326,"output_type":"execute_result","data":{"text/plain":"{'acceptance',\n 'accomplishment',\n 'admiration',\n 'adoration',\n 'adrenaline',\n 'adventure',\n 'affection',\n 'amazement',\n 'ambivalence',\n 'amusement',\n 'anger',\n 'anticipation',\n 'anxiety',\n 'appreciation',\n 'apprehensive',\n 'arousal',\n 'artisticburst',\n 'awe',\n 'bad',\n 'betrayal',\n 'bitter',\n 'bitterness',\n 'bittersweet',\n 'blessed',\n 'boredom',\n 'breakthrough',\n 'calmness',\n 'captivation',\n 'celebration',\n 'celestial wonder',\n 'challenge',\n 'charm',\n 'colorful',\n 'compassion',\n 'compassionate',\n 'confidence',\n 'confident',\n 'confusion',\n 'connection',\n 'contemplation',\n 'contentment',\n 'coziness',\n 'creative inspiration',\n 'creativity',\n 'culinary adventure',\n 'culinaryodyssey',\n 'curiosity',\n 'darkness',\n 'dazzle',\n 'desolation',\n 'despair',\n 'desperation',\n 'determination',\n 'devastated',\n 'disappointed',\n 'disappointment',\n 'disgust',\n 'dismissive',\n 'dreamchaser',\n 'ecstasy',\n 'elation',\n 'elegance',\n 'embarrassed',\n 'emotion',\n 'emotionalstorm',\n 'empathetic',\n 'empowerment',\n 'enchantment',\n 'energy',\n 'engagement',\n 'enjoyment',\n 'enthusiasm',\n 'envious',\n 'envisioning history',\n 'envy',\n 'euphoria',\n 'excitement',\n 'exhaustion',\n 'exploration',\n 'fear',\n 'fearful',\n 'festivejoy',\n 'free-spirited',\n 'freedom',\n 'friendship',\n 'frustrated',\n 'frustration',\n 'fulfillment',\n 'grandeur',\n 'grateful',\n 'gratitude',\n 'grief',\n 'happiness',\n 'happy',\n 'harmony',\n 'hate',\n 'heartache',\n 'heartbreak',\n 'heartwarming',\n 'helplessness',\n 'hope',\n 'hopeful',\n 'hypnotic',\n 'iconic',\n 'imagination',\n 'immersion',\n 'indifference',\n 'innerjourney',\n 'inspiration',\n 'inspired',\n 'intimidation',\n 'intrigue',\n 'isolation',\n 'jealous',\n 'jealousy',\n 'journey',\n 'joy',\n 'joy in baking',\n 'joyfulreunion',\n 'kind',\n 'kindness',\n 'loneliness',\n 'loss',\n 'lostlove',\n 'love',\n 'marvel',\n 'melancholy',\n 'melodic',\n 'mesmerizing',\n 'mindfulness',\n 'miscalculation',\n 'mischievous',\n 'motivation',\n \"nature's beauty\",\n 'negative',\n 'neutral',\n 'nostalgia',\n 'numbness',\n 'obstacle',\n \"ocean's freedom\",\n 'optimism',\n 'overjoyed',\n 'overwhelmed',\n 'pensive',\n 'playful',\n 'playfuljoy',\n 'positive',\n 'positivity',\n 'pressure',\n 'pride',\n 'proud',\n 'radiance',\n 'reflection',\n 'regret',\n 'rejuvenation',\n 'relief',\n 'renewed effort',\n 'resentment',\n 'resilience',\n 'reverence',\n 'romance',\n 'ruin',\n 'runway creativity',\n 'sad',\n 'sadness',\n 'satisfaction',\n 'serenity',\n 'shame',\n 'solace',\n 'solitude',\n 'sorrow',\n 'spark',\n 'success',\n 'suffering',\n 'surprise',\n 'suspense',\n 'sympathy',\n 'tenderness',\n 'thrill',\n 'thrilling journey',\n 'touched',\n 'tranquility',\n 'triumph',\n 'vibrancy',\n 'whimsy',\n 'whispers of the past',\n 'winter magic',\n 'wonder',\n 'wonderment',\n 'yearning',\n 'zest'}"},"metadata":{}}],"execution_count":326},{"cell_type":"code","source":"import spacy\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nnlp = spacy.load(\"en_core_web_md\")\n\nref_words = {\n    \"Positive\": \"positive\",\n    \"Negative\": \"negative\",\n    \"Neutral\": \"neutral\"\n}\n\nref_vectors = {category: nlp(word).vector for category, word in ref_words.items()}\n\ndef assign_sentiment_category(sentiment):\n    word_vector = nlp(sentiment).vector.reshape(1, -1)\n    \n    similarities = {}\n    for category, ref_vec in ref_vectors.items():\n        ref_vec = ref_vec.reshape(1, -1)\n        sim = cosine_similarity(word_vector, ref_vec)[0][0]\n        similarities[category] = sim\n\n    return max(similarities, key=similarities.get)\n\ntrain_df['Sentiment'] = train_df['Sentiment'].apply(assign_sentiment_category)\n\nprint(train_df['Sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:34.543042Z","iopub.execute_input":"2025-03-13T19:16:34.543354Z","iopub.status.idle":"2025-03-13T19:16:42.240190Z","shell.execute_reply.started":"2025-03-13T19:16:34.543325Z","shell.execute_reply":"2025-03-13T19:16:42.238402Z"}},"outputs":[{"name":"stdout","text":"Sentiment\nPositive    364\nNegative    290\nNeutral      78\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":327},{"cell_type":"code","source":"!pip install nltk  \n\nimport nltk\nnltk.download('stopwords')  \nfrom nltk.corpus import stopwords\nimport string\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom nltk.stem import PorterStemmer\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer()\n\nemoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  \n                           u\"\\U0001F300-\\U0001F5FF\"  \n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F700-\\U0001F77F\" \n                           u\"\\U0001F780-\\U0001F7FF\"  \n                           u\"\\U0001F800-\\U0001F8FF\" \n                           u\"\\U0001F900-\\U0001F9FF\" \n                           u\"\\U0001FA00-\\U0001FA6F\" \n                           u\"\\U0001FA70-\\U0001FAFF\" \n                           u\"\\U00002702-\\U000027B0\" \n                           u\"\\U000024C2-\\U0001F251\" \n                           \"]+\", flags=re.UNICODE)\n\ndef split_and_remove_stopwords(text):\n    text = emoji_pattern.sub(r'', text)\n    tokens = text.split()\n\n    filtered_tokens = [\n        stemmer.stem(lemmatizer.lemmatize(word.lower().rstrip(string.punctuation)))\n        for word in tokens if stemmer.stem(word.lower().rstrip(string.punctuation)) not in stop_words\n    ]\n\n    return filtered_tokens\n\ntrain_df['Text'] = train_df['Text'].apply(split_and_remove_stopwords)\n\nprint(train_df['Text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:16:42.241329Z","iopub.execute_input":"2025-03-13T19:16:42.241773Z","iopub.status.idle":"2025-03-13T19:16:47.240693Z","shell.execute_reply.started":"2025-03-13T19:16:42.241727Z","shell.execute_reply":"2025-03-13T19:16:47.239122Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n0                             [enjoy, beauti, day, park]\n1                      [traffic, wa, terribl, thi, morn]\n2                                [finish, amaz, workout]\n3                       [excit, upcom, weekend, getaway]\n4                     [tri, new, recip, dinner, tonight]\n5                      [feel, grate, littl, thing, life]\n6          [raini, day, call, cozi, blanket, hot, cocoa]\n7                        [new, movi, releas, must-watch]\n8                        [polit, discuss, heat, timelin]\n9                       [miss, summer, vibe, beach, day]\n10                     [publish, new, blog, post, check]\n11                           [feel, bit, weather, today]\n12                          [explor, city', hidden, gem]\n13                           [new, year, new, fit, goal]\n14                         [technolog, chang, way, live]\n15                          [reflect, past, look, ahead]\n16                          [adopt, cute, furri, friend]\n17                   [late-night, game, session, friend]\n18                         [attend, virtual, confer, ai]\n19                        [winter, blue, got, feel, low]\n20                       [sip, coffe, enjoy, good, book]\n21                     [explor, world, virtual, realiti]\n22                     [product, day, tick, to-do, list]\n23                   [finish, challeng, workout, routin]\n24                              [celebr, mileston, work]\n25                              [sunday, brunch, friend]\n26                 [learn, new, languag, person, growth]\n27                             [quiet, even, good, book]\n28                     [reflect, import, mental, health]\n29                                [new, paint, progress]\n30           [weekend, road, trip, explor, scenic, view]\n31                      [enjoy, cup, tea, watch, sunset]\n32                      [code, new, project, enthusiasm]\n33                      [feel, inspir, attend, workshop]\n34                     [winter, sport, day, local, park]\n35                 [qualiti, time, famili, thi, weekend]\n36               [attend, live, music, concert, tonight]\n37                                [practic, mind, medit]\n38                            [tri, new, dessert, recip]\n39                      [excit, upcom, game, tournament]\n40                        [plan, garden, makeov, spring]\n41                  [celebr, friend', birthday, tonight]\n42                      [feel, accomplish, product, day]\n43                              [cozi, even, good, movi]\n44           [explor, local, art, galleri, thi, weekend]\n45                  [new, book, releas, favorit, author]\n46                    [attend, virtual, realiti, meetup]\n47                              [reflect, beauti, natur]\n48                    [cook, special, dinner, love, one]\n49                         [feel, optimist, week, ahead]\n50                 [start, new, fit, challeng, tomorrow]\n51                   [sunday, bike, ride, scenic, trail]\n52            [can't, believ, injustic, happen, societi]\n53             [feel, sens, fear, watch, thriller, movi]\n54              [heartbroken, hear, news, natur, disast]\n55                     [state, world', environ, disgust]\n56             [pure, happi, celebr, love, one', achiev]\n57        [laughter, best, medicine—enjoy, comedi, show]\n58                   [share, love, posit, vibe, everyon]\n59                          [amus, incid, brighten, day]\n60                       [enjoy, quiet, even, book, tea]\n61              [admir, beauti, natur, dure, peac, hike]\n62                       [send, affection, vibe, follow]\n63                   [experienc, awe, breathtak, sunset]\n64                  [disappoint, servic, local, restaur]\n65                    [surpris, gift, friend, made, day]\n66                [find, accept, midst, life', challeng]\n67                           [overflow, ador, ador, pet]\n68               [anticip, thrill, adventur, come, week]\n69               [bitter, experi, turn, valuabl, lesson]\n70                        [find, calm, midst, busi, day]\n71                   [confus, cloud, mind, navig, decis]\n72                          [excit, build, upcom, vacat]\n73              [kind, wit, today, restor, faith, human]\n74                     [pride, achiev, person, mileston]\n75                      [moment, shame, stand, injustic]\n76                         [fume, anger, heat, argument]\n77                          [fear, unknown, keep, night]\n78          [heartfelt, sad, bid, farewel, dear, friend]\n79           [state, corrupt, societi, utterli, disgust]\n80        [overflow, happi, welcom, new, famili, member]\n81     [laughter, key, joy—attend, stand-up, comedi, ...\n82                [send, love, follow, thi, beauti, day]\n83                    [amus, antic, pet—it', pure, amus]\n84          [enjoy, everi, moment, thi, trip—pur, enjoy]\n85                [admir, dedic, volunt, local, chariti]\n86               [send, affection, vibe, friend, famili]\n87                      [awe-struck, beauti, night, sky]\n88         [disappoint, lack, progress, person, project]\n89     [surpris, visit, old, friend, brought, tear, joy]\n90                               [embrac, accept, life']\n91                  [overflow, ador, cute, rescu, puppi]\n92                   [anticip, releas, much-await, movi]\n93              [bitter, experi, custom, servic, depart]\n94               [find, calm, amidst, chao, daili, life]\n95       [confus, reign, tri, make, sens, recent, event]\n96              [excit, build, surpris, birthday, parti]\n97                           [wit, act, kind, made, day]\n98             [pride, complet, challeng, fit, challeng]\n99                      [moment, shame, speak, injustic]\n100                     [reflect, beauti, divers, world]\n101                     [excit, quiet, even, good, book]\n102                     [feel, bitter, unfair, workplac]\n103                       [calm, prevail, practic, mind]\n104              [confus, surround, navig, life', choic]\n105     [excit, weekend, road, trip, explor, new, place]\n106             [kind, wit, today, restor, faith, human]\n107        [pride, accomplish, person, profession, goal]\n108               [shame, true, valu, difficult, situat]\n109             [revisit, old, memori, feel, sens, elat]\n110             [victori, team, brought, euphoria, citi]\n111             [embrac, beauti, natur, moment, content]\n112              [medit, seren, lake, find, inner, peac]\n113                   [overflow, gratitud, life', bless]\n114         [hope, brighter, tomorrow, despit, challeng]\n115                        [empow, make, differ, commun]\n116    [compass, action, support, local, chariti, event]\n117                 [moment, tender, connect, love, one]\n118              [arous, excit, await, special, announc]\n119                     [enthusiast, dive, new, project]\n120                [feel, sens, fulfil, reach, mileston]\n121                    [rever, beauti, histor, landmark]\n122                [elat, surpris, reunion, old, friend]\n123               [euphoria, live, music, concert, star]\n124                    [content, simplic, quiet, sunday]\n125                  [seren, found, page, favorit, book]\n126       [gratitud, support, receiv, dure, tough, time]\n127                        [hope, possibl, new, journey]\n128                     [empower, learn, person, growth]\n129               [compass, toward, need, dure, holiday]\n130                 [tender, warmth, cozi, winter, even]\n131                      [arous, excit, upcom, adventur]\n132                 [enthusiasm, creativ, project, make]\n133         [fulfil, complet, challeng, workout, routin]\n134                   [rever, artistri, display, museum]\n135                         [elat, achiev, person, goal]\n136                    [elat, discov, hidden, gem, citi]\n137                [euphoria, surpris, birthday, celebr]\n138                  [content, simplic, home-cook, meal]\n139                  [seren, found, melodi, peac, piano]\n140                  [gratitud, support, commun, around]\n141                  [hope, prospect, new, busi, ventur]\n142                              [empower, mentor, guid]\n143                  [compass, shown, act, kind, commun]\n144               [tender, heartfelt, messag, love, one]\n145              [arous, excit, befor, much-await, trip]\n146             [enthusiasm, new, artist, project, work]\n147                           [feel, sens, fulfil, help]\n148                  [rever, histor, signific, landmark]\n149                        [elat, achiev, fit, mileston]\n150                 [euphoria, success, product, launch]\n151                         [content, embrac, love, one]\n152                  [seren, found, beauti, sunset, sea]\n153                   [gratitud, small, joy, day, bring]\n154                      [hope, potenti, person, growth]\n155                         [empower, learn, new, skill]\n156                    [compass, volunt, local, chariti]\n157                  [tender, quiet, moment, share, pet]\n158                        [arous, excit, upcom, festiv]\n159             [enthusiasm, diy, home, improv, project]\n160                   [fulfil, complet, challeng, puzzl]\n161                  [rever, wonder, natur, hike, trail]\n162          [elat, surpris, reunion, childhood, friend]\n163                    [suffer, despair, anoth, setback]\n164          [overwhelm, grief, miss, love, one, dearli]\n165                 [loneli, creep, night, grow, colder]\n166                     [jealousi, consum, wit, success]\n167                        [resent, build, past, betray]\n168              [frustrat, mount, obstacl, block, path]\n169           [boredom, set, day, feel, endlessli, dull]\n170        [anxieti, grip, heart, worri, cloud, thought]\n171                     [intimid, unknown, futur, ahead]\n172                     [helpless, sink, challeng, pile]\n173                      [envi, eat, away, see, prosper]\n174             [regret, miss, opportun, haunt, thought]\n175                  [disgust, sight, injustic, cruelti]\n176                 [drown, despair, hope, slip, finger]\n177     [grief, weigh, heavi, tear, constant, companion]\n178          [loneli, crowd, room, silent, cri, connect]\n179                [jealousi, gnaw, confid, toxic, emot]\n180               [resent, fester, poison, relationship]\n181                [frustrat, boil, volcan, erupt, emot]\n182     [boredom, settl, like, dust, life, feel, mundan]\n183    [anxieti, grip, chest, relentless, grip, thought]\n184         [intimid, challeng, ahead, fear, take, hold]\n185              [helpless, engulf, drown, sea, problem]\n186              [envi, poison, thought, covet, success]\n187                  [regret, decis, led, pain, present]\n188                   [disgust, corrupt, stain, societi]\n189                   [sink, despair, day, darker, last]\n190              [grief, overwhelm, storm, emot, within]\n191         [loneli, echo, empti, space, yearn, connect]\n192    [jealousi, poison, thought, resent, brew, within]\n193                 [resent, fester, wound, refus, heal]\n194                [frustrat, escal, thunderstorm, emot]\n195          [boredom, linger, stagnant, pool, indiffer]\n196    [embark, journey, discoveri, fuel, curios, thi...\n197    [lost, vast, sea, inform, indiffer, wave, digi...\n198    [complex, puzzl, life, leaf, state, perpetu, c...\n199    [numb, settl, shield, overwhelm, emot, life, t...\n200    [gaze, sunset, melanchol, long, moment, slip, ...\n201    [revisit, old, photograph, caught, embrac, nos...\n202    [torn, conflict, emot, ambival, paint, decis, ...\n203    [embrac, ebb, flow, life, find, accept, danc, ...\n204    [face, challeng, head-on, determin, fuel, fire...\n205    [seren, found, still, natur, tranquil, retreat...\n206    [curios, lead, rabbit, hole, knowledg, perpetu...\n207    [float, day, air, indiffer, detach, mundan, ha...\n208    [entangl, web, thought, confus, reign, navig, ...\n209    [numb, chao, emot, lock, away, stoic, facad, c...\n210    [melancholi, whisper, breez, silent, convers, ...\n211    [stumbl, upon, old, journal, nostalgia, flood,...\n212    [tapestri, conflict, feel, weav, uncertainti, ...\n213    [embrac, flaw, find, accept, imperfect, journe...\n214    [determin, burn, like, wildfir, overcom, obsta...\n215    [tranquil, moment, ocean, seren, wash, peac, r...\n216    [explor, new, horizon, spark, curios, adventur...\n217    [drift, day, nonchal, demeanor, embrac, art, i...\n218    [wrestl, thought, perplex, mind, lost, labyrin...\n219    [immers, state, emot, numb, shield, storm, dai...\n220    [melanchol, symphoni, play, background, soundt...\n221    [flip, page, old, yearbook, nostalgia, paint, ...\n222    [torn, oppos, emot, ambival, color, decis, sha...\n223    [embrac, life', imperfect, find, accept, journ...\n224    [fieri, determin, burn, within, fuel, vision, ...\n225    [bask, seren, quiet, forest, whisper, natur, b...\n226    [indiffer, nois, world, silent, observ, midst,...\n227    [navig, labyrinth, thought, confus, constant, ...\n228    [impenetr, numb, shield, emot, storm, fortress...\n229    [melancholi, paint, world, hue, nostalgia, can...\n230    [journey, past, flip, page, old, diari, nostal...\n231    [ambival, cloud, decis, caught, crossroad, con...\n232    [embrac, imperfect, find, accept, mosaic, life...\n233    [determin, drive, forc, propel, forward, path,...\n234    [seek, seren, melodi, raindrop, tranquil, esca...\n235    [curios, drive, explor, unknown, seeker, knowl...\n236    [drift, day, air, nonchal, indiffer, trivial, ...\n237    [lost, labyrinth, thought, confus, cast, shado...\n238    [wrap, cloak, emot, numb, shield, storm, life'...\n239    [melancholi, companion, paint, canva, life, br...\n240    [leaf, page, old, photo, album, nostalgia, wea...\n241    [ambival, air, caught, crossroad, conflict, em...\n242    [embrac, beauti, imperfect, find, accept, mosa...\n243    [determin, ablaz, forg, path, challeng, sculpt...\n244    [immers, seren, moonlit, night, quiet, whisper...\n245    [fuel, curios, ventur, unchart, realm, fearles...\n246    [wrap, cloak, emot, numb, shield, storm, life'...\n247    [danc, life, exuber, carefre, spirit, embrac, ...\n248    [bask, golden, glow, content, seren, river, fl...\n249    [gaze, toward, horizon, hope, eye, paint, canv...\n250    [stand, tall, proud, oak, branch, achiev, reac...\n251    [heart, overflow, gratitud, garden, appreci, b...\n252    [extend, hand, empathet, thread, weav, tapestr...\n253    [compassion, cloud, heavi, care, shower, empat...\n254    [play, danc, rain, laughter, whimsic, spirit, ...\n255    [soar, wing, free, spirit, unburden, chain, co...\n256    [bath, glow, inspir, creativ, phoenix, rise, a...\n257    [navig, sea, hope, sail, toward, sunris, possi...\n258    [stride, confid, footprint, self-assured, impr...\n259    [lost, symphoni, night, moonlit, serenad, whis...\n260    [unveil, layer, curios, labyrinth, question, l...\n261    [embrac, autumn, breez, leaf, ambival, danc, w...\n262    [gratitud, guid, star, navig, constel, bless, ...\n263    [zest, heart, sprint, field, enthusiasm, chase...\n264    [compassion, rain, tear, empathi, fall, gentli...\n265    [proudli, scale, peak, achiev, mountain, conqu...\n266    [embrac, hope, dawn, garden, sow, seed, optim,...\n267    [play, escapad, carniv, life, carousel, laught...\n268    [float, cloud, inspir, artist, paint, sky, str...\n269    [navig, river, content, seren, boat, cruis, tr...\n270    [empathi, lantern, wander, dark, alley, sorrow...\n271    [free, spirit, soar, wing, dream, leav, trail,...\n272    [bath, golden, hue, grate, sunset, appreci, ca...\n273    [confid, stride, danc, life, ballroom, self-as...\n274    [hope, whisper, wind, carri, promis, brighter,...\n275    [play, juggl, respons, circu, perform, balanc,...\n276    [whisper, tale, inspir, star, storytel, craft,...\n277    [chart, cours, wave, hope, anticip, sailor, st...\n278    [compassion, rain, tear, empathi, fall, gentli...\n279    [proudli, scale, peak, achiev, mountain, conqu...\n280    [embrac, hope, dawn, garden, sow, seed, optim,...\n281    [play, escapad, carniv, life, carousel, laught...\n282    [float, cloud, inspir, artist, paint, sky, str...\n283    [navig, river, content, seren, boat, cruis, tr...\n284    [empathi, lantern, wander, dark, alley, sorrow...\n285    [free, spirit, soar, wing, dream, leav, trail,...\n286    [bath, golden, hue, grate, sunset, appreci, ca...\n287    [confid, stride, danc, life, ballroom, self-as...\n288    [hope, whisper, wind, carri, promis, brighter,...\n289    [play, juggl, respons, circu, perform, balanc,...\n290    [whisper, tale, inspir, star, storytel, craft,...\n291    [chart, cours, wave, hope, anticip, sailor, st...\n292    [compassion, rain, tear, empathi, fall, gentli...\n293    [proudli, scale, peak, achiev, mountain, conqu...\n294    [embrac, hope, dawn, garden, sow, seed, optim,...\n295    [play, escapad, carniv, life, carousel, laught...\n296    [drown, abyss, despair, heart, shatter, fragme...\n297    [bitter, fester, like, venom, vine, entwin, so...\n298    [wander, desert, loneli, step, heavi, sigh, mi...\n299    [yearn, touch, that', echo, distant, warmth, h...\n300    [eye, wide, open, night, fear, shadow, danc, w...\n301    [apprehens, step, tightrop, uncertainti, balan...\n302    [overwhelm, weight, world, atla, trembl, shoul...\n303    [jealousi, green-ey, monster, lurk, shadow, ca...\n304    [devast, storm, betray, wreckag, trust, scatte...\n305    [frustrat, finger, tap, keyboard, symphoni, an...\n306    [enviou, eye, fixat, gild, prize, heartach, fu...\n307    [dismiss, glanc, fortress, built, indiffer, wa...\n308    [shatter, dream, lie, floor, like, fragment, g...\n309    [loneli, silent, companion, night, onli, echo,...\n310    [fear, whisper, dark, mind, haunt, specter, un...\n311    [bitter, bitter, aftertast, linger, tongu, wor...\n312    [overwhelm, cacophoni, expect, drown, soul, te...\n313    [jealousi, venom, seep, vein, poison, heart, t...\n314    [devast, revel, betray, trust, shatter, like, ...\n315    [frustrat, attempt, mend, broken, connect, thr...\n316    [enviou, gaze, cast, upon, podium, success, bi...\n317    [dismiss, gestur, curtain, drawn, shield, vuln...\n318    [despair, like, heavi, fog, envelop, everi, th...\n319    [bitter, bitter, chill, air, freez, moment, ic...\n320    [loneli, solitari, moon, starless, sky, cast, ...\n321    [yearn, warmth, vanish, sun, heartach, paint, ...\n322    [fear, eye, scan, shadow, prison, night, terro...\n323    [apprehens, whisper, wind, forecast, uncertain...\n324    [overwhelm, maze, expect, minotaur, pressur, l...\n325    [jealousi, fester, wound, pain, intensifi, gla...\n326    [devast, heart, ruin, echo, shatter, dream, re...\n327    [frustrat, attempt, untangl, knot, confus, thr...\n328    [enviou, eye, lock, treasur, chest, opportun, ...\n329    [dismiss, gestur, curtain, drawn, shield, vuln...\n330    [shatter, dream, lie, floor, like, fragment, g...\n331    [loneli, silent, companion, night, onli, echo,...\n332            [awe-struck, breathtak, sunris, mountain]\n333                          [navig, challeng, determin]\n334            [nostalgia, hit, flip, old, photo, album]\n335              [thrill, wit, grandeur, cultur, festiv]\n336           [calm, found, rhythm, raindrop, windowpan]\n337    [overwhelm, support, receiv, dure, person, cha...\n338    [excit, build, countdown, long-await, vacat, b...\n339      [reflect, life', journey, grate, lesson, learn]\n340    [bittersweet, emot, aris, bid, farewel, dear, ...\n341      [curios, spark, explor, mysteri, ancient, ruin]\n342       [admir, intric, detail, handcraft, masterpiec]\n343      [overjoy, warmth, cozi, fireplac, winter, even]\n344     [inspir, strike, observ, color, vibrant, sunset]\n345         [motiv, achiev, fit, goal, invigor, workout]\n346      [gratitud, simpl, joy, found, cup, morn, coffe]\n347        [feel, empow, conquer, challeng, hike, trail]\n348           [amus, antic, play, kitten, dure, playtim]\n349       [contempl, life', mysteri, starri, night, sky]\n350       [joy, reunion, long-lost, friend, year, separ]\n351              [excit, build, prepar, surpris, celebr]\n352    [satisfact, deriv, success, complet, diy, proj...\n353           [feel, bless, support, commun, time, need]\n354       [captiv, seren, tranquil, garden, full, bloom]\n355             [anticip, upcom, adventur, exot, destin]\n356      [reflect, person, growth, achiev, life, experi]\n357    [nostalg, memori, flood, revisit, childhood, f...\n358    [appreci, vibrant, cultur, experienc, dure, tr...\n359      [confid, soar, overcom, public, speak, anxieti]\n360     [content, midst, famili, gather, fill, laughter]\n361    [enthusiasm, learn, new, skill, expand, knowledg]\n362        [surpris, delight, discov, hidden, gem, citi]\n363       [sens, accomplish, complet, challeng, workout]\n364               [wonder, beauti, doubl, rainbow, rain]\n365       [optim, bright, futur, amidst, challeng, time]\n366    [pride, achiev, person, mileston, career, prog...\n367     [happi, bloom, like, flower, garden, sunni, day]\n368         [elat, discov, rare, book, quaint, bookstor]\n369    [curios, piqu, mysteri, ancient, archaeolog, s...\n370      [mesmer, cosmic, danc, firefli, moonlit, night]\n371    [intrigu, symphoni, color, abstract, art, exhi...\n372    [giggl, joy, echo, air, dure, children', playdat]\n373                [envelop, seren, practic, mind, lake]\n374    [chase, dream, like, kite, soar, high, vast, o...\n375    [spellbound, eleg, ballroom, danc, crystal, ch...\n376    [whimsic, delight, world, fairi, tale, magic, ...\n377    [pensiv, contempl, amid, ancient, ruin, forgot...\n378    [embrac, thrill, speed, rollercoaster', exhila...\n379    [harmoni, reson, musician, play, melodi, uniti...\n380    [burst, creativ, quiet, solitud, artist', studio]\n381    [radiant, joy, akin, bloom, flower, sun-kiss, ...\n382          [sens, wonder, vast, cosmo, stargaz, night]\n383         [rejuven, salti, breez, sound, wave, seasid]\n384        [whisper, inspir, rustl, leaf, seren, forest]\n385    [savor, warmth, cup, cocoa, chilli, winter, even]\n386    [heartfelt, gratitud, laughter, share, dure, f...\n387    [embark, culinari, adventur, savor, exot, flav...\n388    [euphoria, flood, final, puzzl, piec, click, p...\n389    [awe-inspir, grandeur, ancient, cathedral', in...\n390        [captiv, ether, beauti, field, fill, firefli]\n391    [immers, enchant, melodi, street, musician', v...\n392         [joy, laughter, reson, live, summer, carniv]\n393    [explor, univers, within, dure, mind, medit, s...\n394     [soar, like, free, spirit, wind, coastal, cliff]\n395       [dazzl, eleg, masquerad, ball', dazzl, costum]\n396      [whimsic, delight, world, whimsic, fairi, tale]\n397      [reflect, contempl, amid, ruin, forgotten, era]\n398    [ride, adrenalin, rush, rollercoaster', wild, ...\n399    [harmoni, reson, musician, play, symphoni, uniti]\n400    [burst, artist, creativ, quietud, artist', stu...\n401    [radiant, joy, akin, blossom, flower, sunlit, ...\n402            [awe-inspir, vast, cosmo, stargaz, night]\n403         [rejuven, salti, breez, sound, wave, seasid]\n404        [whisper, inspir, rustl, leaf, seren, forest]\n405    [savor, warmth, cup, cocoa, chilli, winter, even]\n406    [heartfelt, gratitud, laughter, share, dure, f...\n407    [embark, culinari, odyssey, savor, flavor, aro...\n408    [euphoria, flood, final, puzzl, piec, fit, per...\n409    [awe-struck, grandeur, ancient, cathedral', in...\n410    [curios, awaken, mysteri, ancient, archaeolog,...\n411           [giddi, excit, first, snowflak, danc, sky]\n412    [content, envelop, aroma, freshli, bake, bread...\n413     [inspir, resili, lone, tree, stand, tall, storm]\n414    [lost, page, captiv, novel, transport, anoth, ...\n415    [drench, nostalgia, flip, old, famili, photo, ...\n416    [spark, inspir, ignit, like, shoot, star, nigh...\n417     [imbu, gratitud, simpl, pleasur, warm, cup, tea]\n418    [marvel, kaleidoscop, color, vibrant, street, ...\n419    [awash, seren, sun, set, tranquil, lakesid, re...\n420        [drown, sorrow, memori, lost, love, resurfac]\n421           [numb, set, weight, loneli, grow, heavier]\n422    [tear, fall, like, raindrop, mourn, end, cheri...\n423    [despair, cloud, mind, feel, adrift, endless, ...\n424    [shatter, betray, trust, crumbl, like, fragil,...\n425    [ach, heart, symphoni, pain, play, silenc, sol...\n426    [emot, storm, whirlwind, sad, engulf, everi, t...\n427    [haunt, regret, ghost, past, linger, relentles...\n428     [torn, apart, grief, echo, loss, reverber, soul]\n429    [isol, deepen, emot, winter, warmth, distant, ...\n430    [soul-crush, disappoint, hope, shatter, like, ...\n431    [pain, echo, love, onc, cherish, lost, abyss, ...\n432    [heartach, deepen, solitari, journey, abyss, d...\n433    [melancholi, linger, bittersweet, serenad, qui...\n434    [bitter, like, poison, seep, everi, crevic, wo...\n435    [emot, exhaust, weight, world, crush, weari, s...\n436    [sorrow, echo, symphoni, pain, play, string, l...\n437       [dark, descend, engulf, soul, shadow, despair]\n438    [desper, whisper, silent, plea, glimmer, hope,...\n439    [heart, ruin, remnant, shatter, dream, scatter...\n440    [shatter, echo, shatter, dream, fragment, hope...\n441    [avoid, thorn, regret, walk, barefoot, path, r...\n442    [labyrinth, grief, wall, echo, footstep, lost,...\n443    [soul, adrift, sea, solitud, wave, loneli, cra...\n444    [bitter, betray, tast, linger, stain, palat, t...\n445    [ruin, hope, echo, shatter, dream, whisper, ta...\n446    [sink, like, stone, ocean, heartbreak, rippl, ...\n447    [tear, ink, stain, page, journal, testament, s...\n448    [wasteland, lost, trust, echo, broken, promis,...\n449    [avoid, shard, shatter, dream, walk, tightrop,...\n450    [suffoc, silenc, solitud, echo, laughter, onc,...\n451    [haunt, specter, lost, possibl, ghost, refus, ...\n452    [labyrinth, despair, echo, broken, heart, reve...\n453    [sink, like, autumn, leaf, river, sorrow, carr...\n454    [garden, broken, dream, petal, fall, silent, t...\n455    [tear, currenc, grief, spent, marketplac, lost...\n456    [wander, maze, betray, wall, close, everi, wro...\n457    [soul, weather, storm, heartbreak, seek, refug...\n458    [tapestri, despair, thread, hope, unravel, lea...\n459    [like, wither, rose, garden, love, petal, fall...\n460    [void, heartach, echo, love, song, play, note,...\n461    [nostalgia, bittersweet, danc, moonlit, ballro...\n462    [symphoni, grief, tear, note, compos, melancho...\n463    [betray, venom, serpent, slither, garden, trus...\n464    [sink, quicksand, despair, harder, fight, deep...\n465    [wander, cemeteri, lost, dream, tombston, mark...\n466    [swept, away, river, regret, current, past, re...\n467    [whisper, lost, love, linger, attic, heart, fo...\n468    [galleri, broken, promis, shatter, vow, frame,...\n469       [echo, solitud, silent, convers, soul, shadow]\n470    [danc, sunshin, step, celebr, joy, found, simp...\n471    [laughter, echo, air, choru, happi, lift, spir...\n472    [garden, content, bloom, whisper, tale, inner,...\n473    [chase, dream, vibrant, sky, journey, fuel, ho...\n474    [serenad, star, heart, full, gratitud, melodi,...\n475    [bask, glow, accomplish, mileston, step, stone...\n476    [danc, posit, everi, step, rhythm, uplift, sou...\n477    [overflow, joy, cup, laughter, share, friend, ...\n478    [drape, warmth, kind, quilt, compass, stitch, ...\n479    [garden, friendship, bloom, testament, beauti,...\n480    [embrac, love, heartbeat, melodi, danc, rhythm...\n481    [surround, color, joy, canva, paint, laughter,...\n482    [symphoni, excit, note, burst, energi, ignit, ...\n483    [surpris, gift, wrap, anticip, unfold, moment,...\n484    [lost, maze, curios, twist, turn, unveil, trea...\n485    [float, cloud, gratitud, raindrop, bless, show...\n486    [like, comet, inspir, streak, sky, creativ, le...\n487    [celebr, success, firework, accomplish, light,...\n488    [symphoni, laughter, note, key, unlock, door, ...\n489    [carniv, emot, rollercoast, thrill, send, hear...\n490    [stand, befor, grandeur, eiffel, tower, moment...\n491    [lost, enchant, disneyland, ride, journey, rea...\n492    [explor, wonder, ferrari, world, roar, engin, ...\n493    [amidst, tulip, field, keukenhof, tapestri, co...\n494    [wander, histor, street, kyoto, step, journey,...\n495    [embrac, grand, canyon, nature', masterpiec, m...\n496    [journey, seren, santorini, sunset, paint, sky...\n497    [amaz, architectur, marvel, petra, stone, tell...\n498    [embark, gondola, ride, venic, canal, reflect,...\n499    [summit, machu, picchu, breathtak, panorama, w...\n500    [heart, new, york, citi, time, squar, dazzl, l...\n501    [captiv, histor, charm, colosseum, stone, echo...\n502    [sail, azur, water, maldiv, wave, whisper, ser...\n503    [midst, amazon, rainforest, symphoni, wildlif,...\n504    [walk, great, wall, china, step, testament, an...\n505    [summit, mount, fuji, breathtak, sunris, paint...\n506    [explor, ancient, ruin, angkor, wat, stone, wh...\n507    [ski, slope, swiss, alp, turn, danc, majesti, ...\n508    [tranquil, kyoto', bamboo, forest, whisper, an...\n509    [cruis, fjord, norway, ici, landscap, breathta...\n510    [front, row, adele', concert, note, 'someon, l...\n511    [danc, star, beyoncé', live, show, feel, power...\n512    [crowd, taylor, swift, concert, lyric, 'love, ...\n513    [rock, guitar, solo, queen, tribut, concert, j...\n514    [sway, ed, sheeran', acoust, melodi, seren, ev...\n515    [immers, pulsat, beat, bruno, mar, concert, 'u...\n516    [michael, jackson, tribut, show, moonwalk, hit...\n517    [swing, rhythm, frank, sinatra, tribut, feel, ...\n518    [mosh, pit, metallica, concert, thunder, chord...\n519    [experienc, magic, coldplay, concert, 'fix, be...\n520    [justin, bieber, concert, infecti, beat, 'babi...\n521    [spotlight, ladi, gaga, show, costum, chang, m...\n522    [immers, soul, melodi, adel, tear, flow, freel...\n523    [drench, confetti, kati, perri, concert, kalei...\n524    [audienc, jay-z, perform, lyric, 'empir, state...\n525    [danc, shakira', rhythmic, beat, hip, sway, hy...\n526    [u2, concert, anthem, chord, 'with, without, c...\n527    [rock, gun, n, rose, show, icon, riff, 'sweet,...\n528    [crowd, ariana, grand, concert, high, note, 'i...\n529    [sway, regga, vibe, bob, marley', tribut, conc...\n530    [captiv, spellbind, plot, twist, audienc, appl...\n531    [credit, roll, profound, sens, nostalgia, wash...\n532    [stream, latest, web, seri, viewer, engross, c...\n533    [film, festiv, indi, filmmaker', creation, rec...\n534    [watch, heartwarm, famili, drama, tear, flow, ...\n535    [oscar, actor, gracious, accept, award, radiat...\n536    [discov, hidden, gem, world, documentari, view...\n537    [movi, credit, roll, viewer, experi, mix, awe,...\n538    [binge-watch, thrill, crime, seri, suspens, ke...\n539    [close, scene, unfold, sens, satisfact, wash, ...\n540    [celebr, histor, victori, world, cup, nation, ...\n541    [olymp, athlete', persever, shine, earn, gold,...\n542    [cricket, championship, nail-bit, finish, leaf...\n543    [wit, record-break, marathon, spectat, fill, a...\n544    [tenni, grand, slam, fierc, rivalri, unfold, c...\n545    [cheer, underdog, basketbal, final, crowd, eru...\n546    [golf, tournament, golfer', precis, focu, lead...\n547    [experienc, thrill, high-spe, formula, 1, race...\n548    [cycl, world, championship, climber, conquer, ...\n549    [wit, heartwarm, comeback, hockey, final, fan,...\n550    [seri, defeat, soccer, team, face, disappoint,...\n551    [tenni, tournament, highli, anticip, player, e...\n552    [face, defeat, championship, boxer, reflect, c...\n553    [midst, cycl, race, tire, blowout, lead, frust...\n554    [gymnast', unexpect, fall, dure, routin, spark...\n555    [golf, tournament, miss, crucial, putt, result...\n556    [experienc, seri, loss, basketbal, season, tea...\n557    [despit, meticul, train, swimmer, face, disapp...\n558    [weightlifter', fail, attempt, person, record,...\n559    [midst, soccer, match, unexpect, goal, creat, ...\n560    [seren, beauti, sunset, natur, unfold, canva, ...\n561    [embark, spontan, road, trip, travel, discov, ...\n562    [amidst, bustl, citi, quiet, café, becom, sanc...\n563    [explor, vibrant, street, art, cultur, neighbo...\n564    [world, scienc, breakthrough, discoveri, unfol...\n565    [connect, melodi, live, orchestra, music, enth...\n566    [embrac, aroma, freshli, bake, bread, home, ch...\n567    [wander, histor, museum, histori, enthusiast, ...\n568    [realm, literatur, captiv, novel, transport, r...\n569    [captur, essenc, bustl, market, photograph, fr...\n570    [underneath, citi, light, dancer, express, emo...\n571    [heart, bustl, market, street, food, connoisse...\n572    [first, snowflak, descend, winter, enthusiast,...\n573    [amidst, page, captiv, mysteri, novel, reader,...\n574    [surround, vibrant, color, flower, garden, gar...\n575    [astronomi, observatori, stargaz, marvel, vast...\n576    [engulf, aroma, freshli, brew, coffe, writer, ...\n577    [realm, fashion, design, unveil, collect, tell...\n578    [wave, crash, shore, surfer, embrac, thrill, r...\n579    [explor, histor, architectur, ancient, citi, t...\n580    [success, avoid, eye, contact, crush, hallway,...\n581    [ran, snack, dure, movi, marathon, crisi, leve...\n582    [spent, hour, choos, perfect, filter, selfi, s...\n583    [lost, headphon, vanish, thin, air, #headphone...\n584    [decid, studi, exam, end, make, meme, studi, i...\n585    [got, dress, day, rememb, it', saturday, oop, ...\n586    [surviv, group, project, without, ani, drama, ...\n587    [enter, kitchen, intent, cook, left, bag, chip...\n588    [stare, clock, class, wait, bell, ring, like, ...\n589    [discov, new, book, seri, spent, whole, night,...\n590    [bought, new, video, game, play, hour, forgot,...\n591    [spent, day, binge-watch, new, seri, product, ...\n592    [caught, latest, fashion, trend, plan, shop, s...\n593    [decid, learn, new, instrument, day, one, stil...\n594    [spent, hour, creat, perfect, playlist, everi,...\n595    [success, cook, gourmet, meal, famili, chef, s...\n596    [spontan, book, weekend, getaway, adventur, aw...\n597    [attend, concert, danc, night, away, music, he...\n598    [rediscov, childhood, cartoon, nostalgia-fil, ...\n599    [embark, diy, home, decor, project, let', hope...\n600    [spent, afternoon, museum, pretend, cultur, ar...\n601    [start, blog, random, thought, muse, blog, new...\n602    [relish, peac, afternoon, classic, novel, quie...\n603    [reflect, lifetim, memori, wrinkl, tell, stori...\n604    [explor, world, digit, art, it', never, late, ...\n605    [savor, flavor, home-cook, meal, simpl, joy, h...\n606    [embark, journey, learn, new, languag, mind, s...\n607    [attend, classic, music, concert, feel, timele...\n608    [captur, beauti, natur, photographi, everi, sn...\n609    [reconnect, old, friend, cup, tea, friendship,...\n610    [embark, road, trip, revisit, cherish, place, ...\n611    [join, commun, choir, harmon, fellow, voic, mu...\n612    [explor, art, medit, find, tranquil, still, mi...\n613    [take, stroll, garden, appreci, beauti, bloom,...\n614    [sip, favorit, vintag, wine, sip, tell, stori,...\n615    [particip, commun, art, class, unleash, creati...\n616    [embark, journey, write, memoir, document, lif...\n617    [attend, lectur, histori, alway, fascin, lesso...\n618    [rediscov, joy, cook, tradit, famili, recip, k...\n619    [join, natur, photographi, club, captur, beaut...\n620    [attend, jazz, concert, sway, rhythm, timeless...\n621    [join, write, group, pen, thought, reflect, wr...\n622    [embark, solo, travel, adventur, discov, beaut...\n623    [attend, vintag, car, show, reminisc, classic,...\n624    [start, commun, garden, grow, plant, friendshi...\n625    [host, famili, dinner, laughter, echo, louder,...\n626    [enrol, danc, class, senior, move, rhythm, lif...\n627    [visit, art, galleri, appreci, brushstrok, tel...\n628    [start, book, club, senior, discuss, live, cha...\n629    [host, picnic, park, bask, warmth, friendship,...\n630    [particip, local, theater, product, prove, sta...\n631    [embark, hike, adventur, conquer, trail, relis...\n632    [host, photographi, exhibit, featur, snapshot,...\n633    [join, senior, cycl, club, feel, wind, hair, f...\n634    [attend, wine, tast, event, savor, rich, flavo...\n635    [start, learn, ballroom, danc, glide, grace, a...\n636    [organ, commun, paint, event, turn, blank, can...\n637    [host, 'memori, lane, even, old, friend, remin...\n638    [join, senior, astronomi, club, stargaz, find,...\n639    [attend, local, jazz, festiv, tap, toe, tune, ...\n640    [start, blog, share, wisdom, gain, year, prove...\n641    [particip, chariti, run, prove, age, barrier, ...\n642      [surviv, challeng, physic, exam, equat, defeat]\n643    [explor, world, code, debug, adventur, #coding...\n644    [join, school, debat, team, word, weapon, read...\n645    [start, photographi, club, school, captur, mom...\n646    [daydream, upcom, prom, dress, danc, –, it', f...\n647    [convinc, teacher, class, outdoor, learn, equa...\n648    [accident, spill, paint, art, class, abstract,...\n649    [tri, master, perfect, kickflip, skateboard, s...\n650    [bond, friend, latest, k-pop, sensat, fangirl,...\n651    [spent, hour, perfect, chemistri, experi, mix,...\n652    [success, organ, surpris, birthday, parti, fri...\n653    [join, drama, club, unleash, inner, actor, lig...\n654    [got, hand, latest, fantasi, novel, dive, real...\n655    [master, art, perfect, doodl, dure, bore, clas...\n656    [attempt, break, school, record, longest, hand...\n657    [sneak, snack, class, like, pro, art, snack-sm...\n658    [host, sleepov, friend, thi, weekend, prepar, ...\n659    [spent, hour, tiktok, danc, onli, realiz, two,...\n660    [accident, like, crush', old, photo, stalk, pr...\n661    [tri, impress, crush, smooth, convers, end, sp...\n662    [master, art, creat, paper, airplan, dure, lec...\n663    [tri, set, new, trend, juggl, textbook, class,...\n664    [hide, snack, stash, backpack, emerg, crave, s...\n665    [plan, surpris, scaveng, hunt, friend, anticip...\n666    [danc, rain, celebr, end, exam, rain, danc, un...\n667    [accident, sent, text, meant, friend, class, g...\n668    [tri, magic, trick, impress, classmat, magic, ...\n669    [perfect, art, creat, origami, dure, dull, lec...\n670    [attempt, set, new, record, consecut, hacki, s...\n671    [creat, secret, handshak, friend, friendship, ...\n672    [embark, mission, find, best, burger, joint, t...\n673    [practic, stand-up, comedi, routin, upcom, tal...\n674    [accident, sent, love, letter, wrong, person, ...\n675    [attempt, impress, teacher, elabor, scienc, ex...\n676    [craft, intric, friendship, bracelet, whole, s...\n677    [attempt, beat, record, consecut, cartwheel, c...\n678    [organ, movi, marathon, friend, popcorn, cinem...\n679    [experi, new, hair, color, bold, chang, bold, ...\n680    [build, time, capsul, captur, memori, futur, t...\n681    [accident, walk, wrong, classroom, first, day,...\n682    [tri, new, smoothi, recip, healthi, start, wee...\n683    [reflect, challeng, school, year, feel, bit, o...\n684    [encount, mean-spirit, comment, onlin, deal, o...\n685         [bad, day, school, everyth, seem, go, wrong]\n686        [feel, make, sport, team, disappoint, linger]\n687    [wit, heat, argument, cafeteria, unpleas, atmo...\n688    [receiv, not-so-great, grade, major, project, ...\n689    [deal, person, setback, sometim, life, throw, ...\n690    [feel, lone, saturday, night, sometim, solitud...\n691    [experienc, cyberbulli, hate, messag, onlin, d...\n692    [caught, torrenti, rainstorm, without, umbrell...\n693    [miss, import, event, due, unforeseen, circums...\n694    [deal, unfound, rumor, circul, person, life, r...\n695    [got, flat, tire, way, import, meet, talk, ser...\n696    [feel, sens, empti, close, friend, move, away,...\n697    [face, reject, dream, colleg, dishearten, dete...\n698    [encount, onlin, toxic, dure, game, session, h...\n699    [bad, hair, day, feel, self-consci, bad, hair,...\n700    [feel, sens, despair, major, project, failur, ...\n701    [experienc, hate, comment, express, person, op...\n702    [string, bad, luck, constant, technolog, malfu...\n703    [miss, long-anticip, event, due, unexpect, cir...\n704    [tri, new, studi, techniqu, upcom, exam, explo...\n705    [organ, commun, cleanup, event, cleaner, neigh...\n706    [share, favorit, book, recommend, classmat, bu...\n707    [experi, new, recip, school, bake, sale, bake,...\n708    [collabor, school, project, peer, teamwork, ma...\n709    [attend, school, club, meet, explor, new, inte...\n710    [explor, new, part-tim, job, opportun, gain, w...\n711    [attend, school, assembl, stay, inform, upcom,...\n712    [explor, new, hobbi, photographi, dure, free, ...\n713    [particip, scienc, fair, showcas, uniqu, exper...\n714    [attend, workshop, time, manag, enhanc, organi...\n715    [volunt, local, chariti, event, give, back, co...\n716    [collabor, group, project, promot, teamwork, s...\n717    [particip, debat, club, enhanc, critic, think,...\n718    [celebr, friend', birthday, surpris, parti, jo...\n719    [success, complet, challeng, code, project, ex...\n720    [attend, school, talent, show, support, classm...\n721    [explor, new, hike, trail, friend, weekend, na...\n722    [win, friendli, sport, competit, rival, school...\n723    [receiv, heartfelt, letter, pen, pal, anoth, c...\n724    [creat, beauti, mural, fellow, art, enthusiast...\n725    [particip, school-wid, art, exhibit, wit, crea...\n726    [achiev, person, best, track, field, competit,...\n727    [collabor, scienc, project, receiv, recognit, ...\n728    [attend, surpris, birthday, parti, organ, frie...\n729    [success, fundrais, school, chariti, initi, jo...\n730    [particip, multicultur, festiv, celebr, divers...\n731    [organ, virtual, talent, show, dure, challeng,...\nName: Text, dtype: object\n","output_type":"stream"}],"execution_count":328},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Assume train_df is already loaded with at least the columns \"Text\" and \"Sentiment\"\n# For example, train_df might look like:\n#    Text                                               Sentiment\n# 0  \"Enjoying a beautiful day at the park!\"            Positive\n# 1  \"Traffic was terrible this morning.\"               Negative\n# ...\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Ensure that each document is a string (join list back into a sentence)\ntrain_df['Text'] = train_df['Text'].apply(lambda x: \" \".join(x) if isinstance(x, list) else x)\n\n# Use TF-IDF Vectorizer (limit features to 900 for better performance)\nvectorizer = TfidfVectorizer(max_features=900)\nX = vectorizer.fit_transform(train_df['Text']).toarray()\n\nprint(\"TF-IDF feature matrix shape:\", X.shape)\n\n\n# -----------------------------\n# Step 2. Encode Sentiment Labels\n# -----------------------------\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(train_df['Sentiment'])\nprint(\"Number of classes:\", len(np.unique(y)))\n\n# -----------------------------\n# Step 3. K-Fold Cross Validation\n# -----------------------------\nn_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\naccuracies = []\nfold = 1\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    # -----------------------------\n    # Step 4. Build the Neural Network Model\n    # -----------------------------\n    model = Sequential([\n        Input(shape=(X.shape[1],)),\n        Dense(2048),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(1024),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(512),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(256),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(128),\n        LeakyReLU(alpha=0.1),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(len(np.unique(y)), activation='softmax')\n    ])\n    \n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, \n                  loss='sparse_categorical_crossentropy', \n                  metrics=['accuracy'])\n    \n    # Learning rate scheduler to reduce LR when validation loss plateaus.\n    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n                                     verbose=1, min_lr=1e-6)\n    \n    # -----------------------------\n    # Step 5. Train the Model\n    # -----------------------------\n    model.fit(X_train, y_train, epochs=100, batch_size=64, \n              validation_data=(X_test, y_test), callbacks=[lr_scheduler], verbose=1)\n    \n    # Evaluate the model on the test fold.\n    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n    accuracies.append(accuracy)\n    fold += 1\n\n# -----------------------------\n# Step 6. Print the Average Accuracy\n# -----------------------------\nprint(f\"Mean Accuracy over {n_splits} folds: {np.mean(accuracies):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T19:18:04.678843Z","iopub.execute_input":"2025-03-13T19:18:04.679308Z","iopub.status.idle":"2025-03-13T19:23:35.266344Z","shell.execute_reply.started":"2025-03-13T19:18:04.679274Z","shell.execute_reply":"2025-03-13T19:23:35.265094Z"}},"outputs":[{"name":"stdout","text":"TF-IDF feature matrix shape: (732, 900)\nNumber of classes: 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.3635 - loss: 1.8176 - val_accuracy: 0.4762 - val_loss: 1.0568 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4598 - loss: 1.4035 - val_accuracy: 0.5442 - val_loss: 1.0211 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5130 - loss: 1.1344 - val_accuracy: 0.4694 - val_loss: 0.9912 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6150 - loss: 0.9228 - val_accuracy: 0.4626 - val_loss: 0.9684 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7017 - loss: 0.7472 - val_accuracy: 0.5782 - val_loss: 0.9340 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7837 - loss: 0.5246 - val_accuracy: 0.5510 - val_loss: 0.9073 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8458 - loss: 0.3679 - val_accuracy: 0.6327 - val_loss: 0.8795 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9172 - loss: 0.2291 - val_accuracy: 0.6803 - val_loss: 0.8578 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9154 - loss: 0.2406 - val_accuracy: 0.6259 - val_loss: 0.8489 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9110 - loss: 0.2380 - val_accuracy: 0.6463 - val_loss: 0.8347 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9567 - loss: 0.1347 - val_accuracy: 0.6939 - val_loss: 0.8198 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9593 - loss: 0.1114 - val_accuracy: 0.7075 - val_loss: 0.8062 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9795 - loss: 0.0835 - val_accuracy: 0.7143 - val_loss: 0.8033 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9862 - loss: 0.0664 - val_accuracy: 0.7075 - val_loss: 0.8037 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9867 - loss: 0.0566 - val_accuracy: 0.7075 - val_loss: 0.8087 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9758 - loss: 0.0755\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9768 - loss: 0.0734 - val_accuracy: 0.7075 - val_loss: 0.8073 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9712 - loss: 0.0955 - val_accuracy: 0.7211 - val_loss: 0.8060 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9726 - loss: 0.0942 - val_accuracy: 0.7211 - val_loss: 0.8047 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9930 - loss: 0.0353\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9927 - loss: 0.0355 - val_accuracy: 0.7279 - val_loss: 0.8066 - learning_rate: 5.0000e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9860 - loss: 0.0370 - val_accuracy: 0.7211 - val_loss: 0.8056 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9893 - loss: 0.0372 - val_accuracy: 0.7075 - val_loss: 0.8044 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9890 - loss: 0.0396 - val_accuracy: 0.7143 - val_loss: 0.8026 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9850 - loss: 0.0506 - val_accuracy: 0.7143 - val_loss: 0.8016 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9947 - loss: 0.0276 - val_accuracy: 0.7143 - val_loss: 0.8016 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.7143 - val_loss: 0.8003 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9904 - loss: 0.0408 - val_accuracy: 0.7211 - val_loss: 0.7984 - learning_rate: 2.5000e-04\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9933 - loss: 0.0271 - val_accuracy: 0.7143 - val_loss: 0.8004 - learning_rate: 2.5000e-04\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9964 - loss: 0.0218 - val_accuracy: 0.7075 - val_loss: 0.8000 - learning_rate: 2.5000e-04\nEpoch 29/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9919 - loss: 0.0345\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9925 - loss: 0.0339 - val_accuracy: 0.7075 - val_loss: 0.8072 - learning_rate: 2.5000e-04\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9953 - loss: 0.0229 - val_accuracy: 0.7007 - val_loss: 0.8089 - learning_rate: 1.2500e-04\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9962 - loss: 0.0223 - val_accuracy: 0.7007 - val_loss: 0.8067 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9921 - loss: 0.0249\nEpoch 32: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9923 - loss: 0.0247 - val_accuracy: 0.7075 - val_loss: 0.8029 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.7075 - val_loss: 0.8017 - learning_rate: 6.2500e-05\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9952 - loss: 0.0218 - val_accuracy: 0.7075 - val_loss: 0.7977 - learning_rate: 6.2500e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9917 - loss: 0.0291 - val_accuracy: 0.7075 - val_loss: 0.7972 - learning_rate: 6.2500e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.7007 - val_loss: 0.7946 - learning_rate: 6.2500e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9971 - loss: 0.0170 - val_accuracy: 0.7075 - val_loss: 0.7941 - learning_rate: 6.2500e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9992 - loss: 0.0240 - val_accuracy: 0.7143 - val_loss: 0.7933 - learning_rate: 6.2500e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9997 - loss: 0.0184 - val_accuracy: 0.7143 - val_loss: 0.7922 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9966 - loss: 0.0206 - val_accuracy: 0.7075 - val_loss: 0.7940 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9949 - loss: 0.0299 - val_accuracy: 0.7075 - val_loss: 0.7958 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9968 - loss: 0.0214\nEpoch 42: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9965 - loss: 0.0220 - val_accuracy: 0.7075 - val_loss: 0.7976 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9895 - loss: 0.0321 - val_accuracy: 0.7075 - val_loss: 0.7999 - learning_rate: 3.1250e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9954 - loss: 0.0239 - val_accuracy: 0.7075 - val_loss: 0.8011 - learning_rate: 3.1250e-05\nEpoch 45/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9865 - loss: 0.0407\nEpoch 45: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9867 - loss: 0.0389 - val_accuracy: 0.7075 - val_loss: 0.8028 - learning_rate: 3.1250e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9967 - loss: 0.0225 - val_accuracy: 0.7075 - val_loss: 0.8059 - learning_rate: 1.5625e-05\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9942 - loss: 0.0277 - val_accuracy: 0.7075 - val_loss: 0.8099 - learning_rate: 1.5625e-05\nEpoch 48/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0146\nEpoch 48: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.7075 - val_loss: 0.8125 - learning_rate: 1.5625e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9887 - loss: 0.0267 - val_accuracy: 0.7211 - val_loss: 0.8175 - learning_rate: 7.8125e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9928 - loss: 0.0302 - val_accuracy: 0.7143 - val_loss: 0.8208 - learning_rate: 7.8125e-06\nEpoch 51/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9992 - loss: 0.0205\nEpoch 51: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9984 - loss: 0.0227 - val_accuracy: 0.7211 - val_loss: 0.8269 - learning_rate: 7.8125e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9948 - loss: 0.0199 - val_accuracy: 0.7143 - val_loss: 0.8312 - learning_rate: 3.9063e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9989 - loss: 0.0128 - val_accuracy: 0.7143 - val_loss: 0.8367 - learning_rate: 3.9063e-06\nEpoch 54/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9987 - loss: 0.0226\nEpoch 54: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0221 - val_accuracy: 0.7143 - val_loss: 0.8455 - learning_rate: 3.9063e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9876 - loss: 0.0433 - val_accuracy: 0.7211 - val_loss: 0.8546 - learning_rate: 1.9531e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9922 - loss: 0.0210 - val_accuracy: 0.7347 - val_loss: 0.8599 - learning_rate: 1.9531e-06\nEpoch 57/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9923 - loss: 0.0286\nEpoch 57: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9924 - loss: 0.0278 - val_accuracy: 0.7347 - val_loss: 0.8654 - learning_rate: 1.9531e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9974 - loss: 0.0185 - val_accuracy: 0.7347 - val_loss: 0.8728 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9982 - loss: 0.0223 - val_accuracy: 0.7347 - val_loss: 0.8801 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9875 - loss: 0.0489 - val_accuracy: 0.7347 - val_loss: 0.8863 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9966 - loss: 0.0254 - val_accuracy: 0.7347 - val_loss: 0.8943 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0170 - val_accuracy: 0.7483 - val_loss: 0.9024 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9972 - loss: 0.0283 - val_accuracy: 0.7483 - val_loss: 0.9125 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9986 - loss: 0.0135 - val_accuracy: 0.7483 - val_loss: 0.9217 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9913 - loss: 0.0255 - val_accuracy: 0.7483 - val_loss: 0.9316 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9865 - loss: 0.0426 - val_accuracy: 0.7483 - val_loss: 0.9404 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9973 - loss: 0.0210 - val_accuracy: 0.7483 - val_loss: 0.9480 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9980 - loss: 0.0181 - val_accuracy: 0.7483 - val_loss: 0.9580 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9917 - loss: 0.0408 - val_accuracy: 0.7483 - val_loss: 0.9652 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9869 - loss: 0.0311 - val_accuracy: 0.7483 - val_loss: 0.9742 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9978 - loss: 0.0235 - val_accuracy: 0.7483 - val_loss: 0.9834 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9957 - loss: 0.0263 - val_accuracy: 0.7483 - val_loss: 0.9913 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0186 - val_accuracy: 0.7551 - val_loss: 0.9973 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9962 - loss: 0.0186 - val_accuracy: 0.7551 - val_loss: 1.0050 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9962 - loss: 0.0203 - val_accuracy: 0.7551 - val_loss: 1.0106 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9931 - loss: 0.0244 - val_accuracy: 0.7551 - val_loss: 1.0165 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9983 - loss: 0.0176 - val_accuracy: 0.7551 - val_loss: 1.0223 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.7483 - val_loss: 1.0271 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9870 - loss: 0.0325 - val_accuracy: 0.7483 - val_loss: 1.0346 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9989 - loss: 0.0138 - val_accuracy: 0.7483 - val_loss: 1.0395 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9962 - loss: 0.0244 - val_accuracy: 0.7483 - val_loss: 1.0462 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9869 - loss: 0.0385 - val_accuracy: 0.7483 - val_loss: 1.0517 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9916 - loss: 0.0283 - val_accuracy: 0.7483 - val_loss: 1.0557 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9936 - loss: 0.0251 - val_accuracy: 0.7483 - val_loss: 1.0570 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9942 - loss: 0.0263 - val_accuracy: 0.7483 - val_loss: 1.0603 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9964 - loss: 0.0315 - val_accuracy: 0.7483 - val_loss: 1.0615 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9908 - loss: 0.0241 - val_accuracy: 0.7483 - val_loss: 1.0667 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9967 - loss: 0.0181 - val_accuracy: 0.7483 - val_loss: 1.0706 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9889 - loss: 0.0262 - val_accuracy: 0.7483 - val_loss: 1.0708 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9970 - loss: 0.0176 - val_accuracy: 0.7551 - val_loss: 1.0734 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9940 - loss: 0.0228 - val_accuracy: 0.7483 - val_loss: 1.0755 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9939 - loss: 0.0308 - val_accuracy: 0.7551 - val_loss: 1.0799 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9967 - loss: 0.0177 - val_accuracy: 0.7551 - val_loss: 1.0829 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9964 - loss: 0.0207 - val_accuracy: 0.7551 - val_loss: 1.0833 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9906 - loss: 0.0271 - val_accuracy: 0.7483 - val_loss: 1.0845 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9992 - loss: 0.0128 - val_accuracy: 0.7551 - val_loss: 1.0850 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9966 - loss: 0.0199 - val_accuracy: 0.7551 - val_loss: 1.0873 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9967 - loss: 0.0218 - val_accuracy: 0.7483 - val_loss: 1.0882 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9997 - loss: 0.0161 - val_accuracy: 0.7551 - val_loss: 1.0896 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9910 - loss: 0.0371 - val_accuracy: 0.7551 - val_loss: 1.0874 - learning_rate: 1.0000e-06\nFold 1 Accuracy: 0.7551\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.3521 - loss: 1.6835 - val_accuracy: 0.3878 - val_loss: 1.0520 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.4585 - loss: 1.3341 - val_accuracy: 0.3878 - val_loss: 1.0125 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5848 - loss: 1.0326 - val_accuracy: 0.3878 - val_loss: 0.9836 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6472 - loss: 0.7808 - val_accuracy: 0.4014 - val_loss: 0.9626 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7621 - loss: 0.6088 - val_accuracy: 0.5374 - val_loss: 0.9383 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8201 - loss: 0.4184 - val_accuracy: 0.6531 - val_loss: 0.9164 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8840 - loss: 0.2952 - val_accuracy: 0.7007 - val_loss: 0.9003 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8985 - loss: 0.2739 - val_accuracy: 0.7415 - val_loss: 0.8846 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9229 - loss: 0.1927 - val_accuracy: 0.7007 - val_loss: 0.8735 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9367 - loss: 0.1603 - val_accuracy: 0.6122 - val_loss: 0.8739 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9566 - loss: 0.1358 - val_accuracy: 0.6190 - val_loss: 0.8750 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9697 - loss: 0.1045\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9696 - loss: 0.1052 - val_accuracy: 0.5782 - val_loss: 0.8879 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9809 - loss: 0.0787 - val_accuracy: 0.5782 - val_loss: 0.8898 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9715 - loss: 0.0741 - val_accuracy: 0.5782 - val_loss: 0.8931 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9773 - loss: 0.0771\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9780 - loss: 0.0762 - val_accuracy: 0.5850 - val_loss: 0.8996 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9808 - loss: 0.0708 - val_accuracy: 0.5782 - val_loss: 0.9094 - learning_rate: 2.5000e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9840 - loss: 0.0447 - val_accuracy: 0.5782 - val_loss: 0.9147 - learning_rate: 2.5000e-04\nEpoch 18/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9706 - loss: 0.0876\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9719 - loss: 0.0849 - val_accuracy: 0.5782 - val_loss: 0.9189 - learning_rate: 2.5000e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9886 - loss: 0.0446 - val_accuracy: 0.5850 - val_loss: 0.9240 - learning_rate: 1.2500e-04\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9847 - loss: 0.0506 - val_accuracy: 0.5918 - val_loss: 0.9153 - learning_rate: 1.2500e-04\nEpoch 21/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9938 - loss: 0.0434\nEpoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9925 - loss: 0.0475 - val_accuracy: 0.5918 - val_loss: 0.9144 - learning_rate: 1.2500e-04\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9894 - loss: 0.0581 - val_accuracy: 0.6122 - val_loss: 0.9055 - learning_rate: 6.2500e-05\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9787 - loss: 0.0717 - val_accuracy: 0.6122 - val_loss: 0.9048 - learning_rate: 6.2500e-05\nEpoch 24/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9954 - loss: 0.0400\nEpoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9950 - loss: 0.0416 - val_accuracy: 0.6122 - val_loss: 0.8999 - learning_rate: 6.2500e-05\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9780 - loss: 0.0641 - val_accuracy: 0.6190 - val_loss: 0.8925 - learning_rate: 3.1250e-05\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9748 - loss: 0.0869 - val_accuracy: 0.6190 - val_loss: 0.8891 - learning_rate: 3.1250e-05\nEpoch 27/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9923 - loss: 0.0459\nEpoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9903 - loss: 0.0486 - val_accuracy: 0.6190 - val_loss: 0.8854 - learning_rate: 3.1250e-05\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9932 - loss: 0.0400 - val_accuracy: 0.6463 - val_loss: 0.8807 - learning_rate: 1.5625e-05\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9861 - loss: 0.0427 - val_accuracy: 0.6531 - val_loss: 0.8694 - learning_rate: 1.5625e-05\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9863 - loss: 0.0487 - val_accuracy: 0.6803 - val_loss: 0.8593 - learning_rate: 1.5625e-05\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9935 - loss: 0.0365 - val_accuracy: 0.6871 - val_loss: 0.8517 - learning_rate: 1.5625e-05\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9911 - loss: 0.0411 - val_accuracy: 0.6871 - val_loss: 0.8455 - learning_rate: 1.5625e-05\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9846 - loss: 0.0443 - val_accuracy: 0.6803 - val_loss: 0.8365 - learning_rate: 1.5625e-05\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9836 - loss: 0.0625 - val_accuracy: 0.6939 - val_loss: 0.8312 - learning_rate: 1.5625e-05\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9842 - loss: 0.0554 - val_accuracy: 0.7075 - val_loss: 0.8213 - learning_rate: 1.5625e-05\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9871 - loss: 0.0484 - val_accuracy: 0.7007 - val_loss: 0.8142 - learning_rate: 1.5625e-05\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9894 - loss: 0.0427 - val_accuracy: 0.7007 - val_loss: 0.8070 - learning_rate: 1.5625e-05\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9921 - loss: 0.0336 - val_accuracy: 0.7143 - val_loss: 0.7997 - learning_rate: 1.5625e-05\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9836 - loss: 0.0588 - val_accuracy: 0.7143 - val_loss: 0.7901 - learning_rate: 1.5625e-05\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9866 - loss: 0.0473 - val_accuracy: 0.7143 - val_loss: 0.7851 - learning_rate: 1.5625e-05\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9869 - loss: 0.0460 - val_accuracy: 0.7143 - val_loss: 0.7771 - learning_rate: 1.5625e-05\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9947 - loss: 0.0378 - val_accuracy: 0.7211 - val_loss: 0.7692 - learning_rate: 1.5625e-05\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9910 - loss: 0.0370 - val_accuracy: 0.7279 - val_loss: 0.7613 - learning_rate: 1.5625e-05\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9806 - loss: 0.0540 - val_accuracy: 0.7279 - val_loss: 0.7554 - learning_rate: 1.5625e-05\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9876 - loss: 0.0374 - val_accuracy: 0.7279 - val_loss: 0.7482 - learning_rate: 1.5625e-05\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9775 - loss: 0.0531 - val_accuracy: 0.7483 - val_loss: 0.7419 - learning_rate: 1.5625e-05\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9771 - loss: 0.0725 - val_accuracy: 0.7551 - val_loss: 0.7378 - learning_rate: 1.5625e-05\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9925 - loss: 0.0402 - val_accuracy: 0.7551 - val_loss: 0.7358 - learning_rate: 1.5625e-05\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9951 - loss: 0.0308 - val_accuracy: 0.7347 - val_loss: 0.7330 - learning_rate: 1.5625e-05\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9941 - loss: 0.0418 - val_accuracy: 0.7347 - val_loss: 0.7312 - learning_rate: 1.5625e-05\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9924 - loss: 0.0412 - val_accuracy: 0.7347 - val_loss: 0.7297 - learning_rate: 1.5625e-05\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9749 - loss: 0.0613 - val_accuracy: 0.7415 - val_loss: 0.7275 - learning_rate: 1.5625e-05\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9834 - loss: 0.0534 - val_accuracy: 0.7415 - val_loss: 0.7279 - learning_rate: 1.5625e-05\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9939 - loss: 0.0357 - val_accuracy: 0.7483 - val_loss: 0.7287 - learning_rate: 1.5625e-05\nEpoch 55/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9922 - loss: 0.0352\nEpoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9915 - loss: 0.0362 - val_accuracy: 0.7483 - val_loss: 0.7306 - learning_rate: 1.5625e-05\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9900 - loss: 0.0338 - val_accuracy: 0.7483 - val_loss: 0.7329 - learning_rate: 7.8125e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9927 - loss: 0.0427 - val_accuracy: 0.7483 - val_loss: 0.7358 - learning_rate: 7.8125e-06\nEpoch 58/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9859 - loss: 0.0395\nEpoch 58: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9866 - loss: 0.0393 - val_accuracy: 0.7619 - val_loss: 0.7400 - learning_rate: 7.8125e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9971 - loss: 0.0261 - val_accuracy: 0.7619 - val_loss: 0.7454 - learning_rate: 3.9063e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9896 - loss: 0.0313 - val_accuracy: 0.7687 - val_loss: 0.7507 - learning_rate: 3.9063e-06\nEpoch 61/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9782 - loss: 0.0654\nEpoch 61: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9784 - loss: 0.0643 - val_accuracy: 0.7755 - val_loss: 0.7570 - learning_rate: 3.9063e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9932 - loss: 0.0443 - val_accuracy: 0.7755 - val_loss: 0.7634 - learning_rate: 1.9531e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9846 - loss: 0.0682 - val_accuracy: 0.7687 - val_loss: 0.7689 - learning_rate: 1.9531e-06\nEpoch 64/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9860 - loss: 0.0444\nEpoch 64: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9864 - loss: 0.0438 - val_accuracy: 0.7619 - val_loss: 0.7750 - learning_rate: 1.9531e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9883 - loss: 0.0449 - val_accuracy: 0.7619 - val_loss: 0.7832 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9796 - loss: 0.0491 - val_accuracy: 0.7619 - val_loss: 0.7890 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9925 - loss: 0.0405 - val_accuracy: 0.7619 - val_loss: 0.7950 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9921 - loss: 0.0367 - val_accuracy: 0.7551 - val_loss: 0.8029 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9901 - loss: 0.0384 - val_accuracy: 0.7551 - val_loss: 0.8101 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9829 - loss: 0.0602 - val_accuracy: 0.7551 - val_loss: 0.8192 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9918 - loss: 0.0478 - val_accuracy: 0.7551 - val_loss: 0.8252 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9827 - loss: 0.0533 - val_accuracy: 0.7551 - val_loss: 0.8330 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9929 - loss: 0.0308 - val_accuracy: 0.7551 - val_loss: 0.8412 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9952 - loss: 0.0303 - val_accuracy: 0.7755 - val_loss: 0.8478 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9802 - loss: 0.0637 - val_accuracy: 0.7755 - val_loss: 0.8552 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9854 - loss: 0.0501 - val_accuracy: 0.7687 - val_loss: 0.8617 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9902 - loss: 0.0500 - val_accuracy: 0.7755 - val_loss: 0.8647 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9901 - loss: 0.0345 - val_accuracy: 0.7551 - val_loss: 0.8716 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9957 - loss: 0.0300 - val_accuracy: 0.7551 - val_loss: 0.8749 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9866 - loss: 0.0461 - val_accuracy: 0.7687 - val_loss: 0.8789 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9932 - loss: 0.0413 - val_accuracy: 0.7687 - val_loss: 0.8823 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9891 - loss: 0.0387 - val_accuracy: 0.7551 - val_loss: 0.8876 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9780 - loss: 0.0571 - val_accuracy: 0.7551 - val_loss: 0.8917 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9766 - loss: 0.0612 - val_accuracy: 0.7619 - val_loss: 0.8910 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9798 - loss: 0.0700 - val_accuracy: 0.7551 - val_loss: 0.8999 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9870 - loss: 0.0501 - val_accuracy: 0.7551 - val_loss: 0.9029 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9908 - loss: 0.0293 - val_accuracy: 0.7619 - val_loss: 0.9026 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9921 - loss: 0.0307 - val_accuracy: 0.7551 - val_loss: 0.9040 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9864 - loss: 0.0485 - val_accuracy: 0.7551 - val_loss: 0.9057 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9918 - loss: 0.0389 - val_accuracy: 0.7619 - val_loss: 0.9078 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9895 - loss: 0.0471 - val_accuracy: 0.7619 - val_loss: 0.9100 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9834 - loss: 0.0450 - val_accuracy: 0.7619 - val_loss: 0.9112 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9960 - loss: 0.0271 - val_accuracy: 0.7619 - val_loss: 0.9109 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9845 - loss: 0.0430 - val_accuracy: 0.7619 - val_loss: 0.9108 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9912 - loss: 0.0369 - val_accuracy: 0.7687 - val_loss: 0.9132 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9869 - loss: 0.0395 - val_accuracy: 0.7619 - val_loss: 0.9162 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9832 - loss: 0.0464 - val_accuracy: 0.7551 - val_loss: 0.9172 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9886 - loss: 0.0425 - val_accuracy: 0.7619 - val_loss: 0.9185 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9826 - loss: 0.0446 - val_accuracy: 0.7619 - val_loss: 0.9188 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9886 - loss: 0.0374 - val_accuracy: 0.7619 - val_loss: 0.9205 - learning_rate: 1.0000e-06\nFold 2 Accuracy: 0.7619\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.3489 - loss: 1.7154 - val_accuracy: 0.5068 - val_loss: 1.0544 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4354 - loss: 1.3559 - val_accuracy: 0.5068 - val_loss: 1.0238 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.4996 - loss: 1.2541 - val_accuracy: 0.5068 - val_loss: 0.9985 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6530 - loss: 0.8559 - val_accuracy: 0.5068 - val_loss: 0.9667 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7346 - loss: 0.6648 - val_accuracy: 0.5068 - val_loss: 0.9461 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8044 - loss: 0.5235 - val_accuracy: 0.5068 - val_loss: 0.9489 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8940 - loss: 0.2997 - val_accuracy: 0.5068 - val_loss: 0.9522 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8985 - loss: 0.2791\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8987 - loss: 0.2787 - val_accuracy: 0.5068 - val_loss: 0.9896 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9260 - loss: 0.1982 - val_accuracy: 0.5068 - val_loss: 1.0141 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9183 - loss: 0.1926 - val_accuracy: 0.5068 - val_loss: 1.0323 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9429 - loss: 0.1277\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9446 - loss: 0.1274 - val_accuracy: 0.5068 - val_loss: 1.0343 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9493 - loss: 0.1520 - val_accuracy: 0.5068 - val_loss: 1.0481 - learning_rate: 2.5000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9659 - loss: 0.1246 - val_accuracy: 0.5068 - val_loss: 1.0438 - learning_rate: 2.5000e-04\nEpoch 14/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9691 - loss: 0.1010\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9670 - loss: 0.1047 - val_accuracy: 0.5068 - val_loss: 1.0456 - learning_rate: 2.5000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9621 - loss: 0.1177 - val_accuracy: 0.5068 - val_loss: 1.0426 - learning_rate: 1.2500e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9665 - loss: 0.1058 - val_accuracy: 0.5068 - val_loss: 1.0352 - learning_rate: 1.2500e-04\nEpoch 17/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9631 - loss: 0.1118\nEpoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9633 - loss: 0.1122 - val_accuracy: 0.5068 - val_loss: 1.0389 - learning_rate: 1.2500e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9773 - loss: 0.0790 - val_accuracy: 0.5068 - val_loss: 1.0472 - learning_rate: 6.2500e-05\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9651 - loss: 0.1062 - val_accuracy: 0.5068 - val_loss: 1.0402 - learning_rate: 6.2500e-05\nEpoch 20/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9668 - loss: 0.1199\nEpoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9657 - loss: 0.1199 - val_accuracy: 0.5068 - val_loss: 1.0324 - learning_rate: 6.2500e-05\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9683 - loss: 0.1064 - val_accuracy: 0.5068 - val_loss: 1.0323 - learning_rate: 3.1250e-05\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9768 - loss: 0.0762 - val_accuracy: 0.5068 - val_loss: 1.0300 - learning_rate: 3.1250e-05\nEpoch 23/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9478 - loss: 0.1259\nEpoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9495 - loss: 0.1247 - val_accuracy: 0.5068 - val_loss: 1.0223 - learning_rate: 3.1250e-05\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9729 - loss: 0.0976 - val_accuracy: 0.5137 - val_loss: 1.0016 - learning_rate: 1.5625e-05\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9787 - loss: 0.0890 - val_accuracy: 0.5205 - val_loss: 0.9882 - learning_rate: 1.5625e-05\nEpoch 26/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9692 - loss: 0.0810\nEpoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9692 - loss: 0.0828 - val_accuracy: 0.5205 - val_loss: 0.9715 - learning_rate: 1.5625e-05\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9685 - loss: 0.0998 - val_accuracy: 0.5205 - val_loss: 0.9630 - learning_rate: 7.8125e-06\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9857 - loss: 0.0794 - val_accuracy: 0.5205 - val_loss: 0.9471 - learning_rate: 7.8125e-06\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9748 - loss: 0.0732 - val_accuracy: 0.5479 - val_loss: 0.9285 - learning_rate: 7.8125e-06\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9735 - loss: 0.0835 - val_accuracy: 0.5548 - val_loss: 0.9202 - learning_rate: 7.8125e-06\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9668 - loss: 0.0921 - val_accuracy: 0.5548 - val_loss: 0.9186 - learning_rate: 7.8125e-06\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9744 - loss: 0.0878 - val_accuracy: 0.5616 - val_loss: 0.9010 - learning_rate: 7.8125e-06\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9635 - loss: 0.0904 - val_accuracy: 0.5685 - val_loss: 0.8839 - learning_rate: 7.8125e-06\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9779 - loss: 0.0764 - val_accuracy: 0.5890 - val_loss: 0.8712 - learning_rate: 7.8125e-06\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9709 - loss: 0.0978 - val_accuracy: 0.6027 - val_loss: 0.8540 - learning_rate: 7.8125e-06\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9655 - loss: 0.0942 - val_accuracy: 0.6164 - val_loss: 0.8380 - learning_rate: 7.8125e-06\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9869 - loss: 0.0703 - val_accuracy: 0.6233 - val_loss: 0.8255 - learning_rate: 7.8125e-06\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9727 - loss: 0.0937 - val_accuracy: 0.6301 - val_loss: 0.8063 - learning_rate: 7.8125e-06\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9867 - loss: 0.0714 - val_accuracy: 0.6438 - val_loss: 0.7896 - learning_rate: 7.8125e-06\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9807 - loss: 0.0817 - val_accuracy: 0.6575 - val_loss: 0.7690 - learning_rate: 7.8125e-06\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9826 - loss: 0.0764 - val_accuracy: 0.6644 - val_loss: 0.7509 - learning_rate: 7.8125e-06\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9656 - loss: 0.0971 - val_accuracy: 0.6781 - val_loss: 0.7386 - learning_rate: 7.8125e-06\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9737 - loss: 0.1004 - val_accuracy: 0.6849 - val_loss: 0.7275 - learning_rate: 7.8125e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9781 - loss: 0.0806 - val_accuracy: 0.6918 - val_loss: 0.7195 - learning_rate: 7.8125e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9687 - loss: 0.0879 - val_accuracy: 0.6986 - val_loss: 0.7028 - learning_rate: 7.8125e-06\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9717 - loss: 0.0867 - val_accuracy: 0.7123 - val_loss: 0.6892 - learning_rate: 7.8125e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9852 - loss: 0.0722 - val_accuracy: 0.7260 - val_loss: 0.6782 - learning_rate: 7.8125e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9754 - loss: 0.0733 - val_accuracy: 0.7329 - val_loss: 0.6675 - learning_rate: 7.8125e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9669 - loss: 0.1114 - val_accuracy: 0.7397 - val_loss: 0.6576 - learning_rate: 7.8125e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9709 - loss: 0.0961 - val_accuracy: 0.7466 - val_loss: 0.6485 - learning_rate: 7.8125e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9768 - loss: 0.0871 - val_accuracy: 0.7466 - val_loss: 0.6414 - learning_rate: 7.8125e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9783 - loss: 0.0759 - val_accuracy: 0.7603 - val_loss: 0.6301 - learning_rate: 7.8125e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9916 - loss: 0.0705 - val_accuracy: 0.7603 - val_loss: 0.6190 - learning_rate: 7.8125e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9661 - loss: 0.0885 - val_accuracy: 0.7671 - val_loss: 0.6098 - learning_rate: 7.8125e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9694 - loss: 0.0904 - val_accuracy: 0.7671 - val_loss: 0.6012 - learning_rate: 7.8125e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9878 - loss: 0.0657 - val_accuracy: 0.7740 - val_loss: 0.5945 - learning_rate: 7.8125e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9800 - loss: 0.0649 - val_accuracy: 0.7740 - val_loss: 0.5885 - learning_rate: 7.8125e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9719 - loss: 0.0832 - val_accuracy: 0.7740 - val_loss: 0.5847 - learning_rate: 7.8125e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9775 - loss: 0.0653 - val_accuracy: 0.7877 - val_loss: 0.5774 - learning_rate: 7.8125e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9809 - loss: 0.0612 - val_accuracy: 0.7945 - val_loss: 0.5711 - learning_rate: 7.8125e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9720 - loss: 0.0743 - val_accuracy: 0.7945 - val_loss: 0.5693 - learning_rate: 7.8125e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9778 - loss: 0.0770 - val_accuracy: 0.7945 - val_loss: 0.5657 - learning_rate: 7.8125e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9810 - loss: 0.0729 - val_accuracy: 0.8014 - val_loss: 0.5635 - learning_rate: 7.8125e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9594 - loss: 0.0921 - val_accuracy: 0.8014 - val_loss: 0.5626 - learning_rate: 7.8125e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9722 - loss: 0.0895 - val_accuracy: 0.8082 - val_loss: 0.5578 - learning_rate: 7.8125e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9901 - loss: 0.0559 - val_accuracy: 0.8082 - val_loss: 0.5553 - learning_rate: 7.8125e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9636 - loss: 0.1094 - val_accuracy: 0.7945 - val_loss: 0.5524 - learning_rate: 7.8125e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9777 - loss: 0.0921 - val_accuracy: 0.7945 - val_loss: 0.5548 - learning_rate: 7.8125e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9803 - loss: 0.0584 - val_accuracy: 0.7945 - val_loss: 0.5557 - learning_rate: 7.8125e-06\nEpoch 70/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9864 - loss: 0.0781\nEpoch 70: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9857 - loss: 0.0775 - val_accuracy: 0.7945 - val_loss: 0.5550 - learning_rate: 7.8125e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9823 - loss: 0.0810 - val_accuracy: 0.7877 - val_loss: 0.5534 - learning_rate: 3.9063e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9688 - loss: 0.0924 - val_accuracy: 0.7808 - val_loss: 0.5541 - learning_rate: 3.9063e-06\nEpoch 73/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9777 - loss: 0.0833\nEpoch 73: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9768 - loss: 0.0836 - val_accuracy: 0.7808 - val_loss: 0.5556 - learning_rate: 3.9063e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9662 - loss: 0.0917 - val_accuracy: 0.7877 - val_loss: 0.5547 - learning_rate: 1.9531e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9782 - loss: 0.0697 - val_accuracy: 0.7945 - val_loss: 0.5558 - learning_rate: 1.9531e-06\nEpoch 76/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9796 - loss: 0.0778\nEpoch 76: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9786 - loss: 0.0804 - val_accuracy: 0.8014 - val_loss: 0.5553 - learning_rate: 1.9531e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9820 - loss: 0.0770 - val_accuracy: 0.8014 - val_loss: 0.5548 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9593 - loss: 0.0939 - val_accuracy: 0.8014 - val_loss: 0.5562 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9708 - loss: 0.0896 - val_accuracy: 0.8014 - val_loss: 0.5584 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9790 - loss: 0.0713 - val_accuracy: 0.8014 - val_loss: 0.5599 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9634 - loss: 0.0889 - val_accuracy: 0.8082 - val_loss: 0.5600 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9723 - loss: 0.0967 - val_accuracy: 0.8082 - val_loss: 0.5621 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9713 - loss: 0.0874 - val_accuracy: 0.8082 - val_loss: 0.5643 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9750 - loss: 0.0715 - val_accuracy: 0.8014 - val_loss: 0.5659 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9708 - loss: 0.0999 - val_accuracy: 0.8014 - val_loss: 0.5674 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9785 - loss: 0.0706 - val_accuracy: 0.8014 - val_loss: 0.5701 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9751 - loss: 0.0781 - val_accuracy: 0.8014 - val_loss: 0.5703 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.0884 - val_accuracy: 0.8014 - val_loss: 0.5707 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9815 - loss: 0.0906 - val_accuracy: 0.8014 - val_loss: 0.5705 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9783 - loss: 0.0866 - val_accuracy: 0.8014 - val_loss: 0.5708 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9787 - loss: 0.0761 - val_accuracy: 0.7945 - val_loss: 0.5707 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9593 - loss: 0.0889 - val_accuracy: 0.7945 - val_loss: 0.5711 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9646 - loss: 0.0785 - val_accuracy: 0.7945 - val_loss: 0.5715 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9762 - loss: 0.0843 - val_accuracy: 0.7945 - val_loss: 0.5726 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9761 - loss: 0.0887 - val_accuracy: 0.8014 - val_loss: 0.5736 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9733 - loss: 0.0859 - val_accuracy: 0.8014 - val_loss: 0.5742 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9781 - loss: 0.0698 - val_accuracy: 0.7945 - val_loss: 0.5743 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9714 - loss: 0.0901 - val_accuracy: 0.7945 - val_loss: 0.5746 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9806 - loss: 0.0713 - val_accuracy: 0.7945 - val_loss: 0.5747 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9755 - loss: 0.0851 - val_accuracy: 0.7945 - val_loss: 0.5757 - learning_rate: 1.0000e-06\nFold 3 Accuracy: 0.7945\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.3460 - loss: 1.8956 - val_accuracy: 0.4795 - val_loss: 1.0430 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4841 - loss: 1.4108 - val_accuracy: 0.5137 - val_loss: 1.0057 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5530 - loss: 1.0734 - val_accuracy: 0.5616 - val_loss: 0.9781 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6337 - loss: 0.9374 - val_accuracy: 0.5685 - val_loss: 0.9581 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7314 - loss: 0.7150 - val_accuracy: 0.5342 - val_loss: 0.9446 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.8235 - loss: 0.4818 - val_accuracy: 0.5274 - val_loss: 0.9364 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.8845 - loss: 0.3077 - val_accuracy: 0.4726 - val_loss: 0.9523 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8971 - loss: 0.3029 - val_accuracy: 0.4726 - val_loss: 0.9682 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9326 - loss: 0.1890\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9318 - loss: 0.1914 - val_accuracy: 0.4726 - val_loss: 0.9865 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9436 - loss: 0.1503 - val_accuracy: 0.4726 - val_loss: 0.9913 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9410 - loss: 0.1512 - val_accuracy: 0.4795 - val_loss: 0.9993 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9619 - loss: 0.1317\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9614 - loss: 0.1320 - val_accuracy: 0.4795 - val_loss: 1.0081 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9573 - loss: 0.1093 - val_accuracy: 0.4795 - val_loss: 1.0152 - learning_rate: 2.5000e-04\nEpoch 14/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9733 - loss: 0.1010 - val_accuracy: 0.4795 - val_loss: 1.0254 - learning_rate: 2.5000e-04\nEpoch 15/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9698 - loss: 0.0838\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9688 - loss: 0.0865 - val_accuracy: 0.4795 - val_loss: 1.0275 - learning_rate: 2.5000e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9706 - loss: 0.0926 - val_accuracy: 0.4795 - val_loss: 1.0312 - learning_rate: 1.2500e-04\nEpoch 17/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9623 - loss: 0.1190 - val_accuracy: 0.4863 - val_loss: 1.0345 - learning_rate: 1.2500e-04\nEpoch 18/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9813 - loss: 0.0714\nEpoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9800 - loss: 0.0740 - val_accuracy: 0.4863 - val_loss: 1.0370 - learning_rate: 1.2500e-04\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9892 - loss: 0.0626 - val_accuracy: 0.5068 - val_loss: 1.0310 - learning_rate: 6.2500e-05\nEpoch 20/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9762 - loss: 0.0800 - val_accuracy: 0.5137 - val_loss: 1.0300 - learning_rate: 6.2500e-05\nEpoch 21/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9566 - loss: 0.0985\nEpoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9580 - loss: 0.0989 - val_accuracy: 0.5137 - val_loss: 1.0260 - learning_rate: 6.2500e-05\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9739 - loss: 0.0744 - val_accuracy: 0.5274 - val_loss: 1.0227 - learning_rate: 3.1250e-05\nEpoch 23/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9725 - loss: 0.0851 - val_accuracy: 0.5411 - val_loss: 1.0171 - learning_rate: 3.1250e-05\nEpoch 24/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9810 - loss: 0.0559\nEpoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9804 - loss: 0.0574 - val_accuracy: 0.5753 - val_loss: 1.0117 - learning_rate: 3.1250e-05\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9660 - loss: 0.0794 - val_accuracy: 0.5959 - val_loss: 1.0064 - learning_rate: 1.5625e-05\nEpoch 26/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9808 - loss: 0.0782 - val_accuracy: 0.5959 - val_loss: 1.0006 - learning_rate: 1.5625e-05\nEpoch 27/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9818 - loss: 0.0685\nEpoch 27: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9811 - loss: 0.0683 - val_accuracy: 0.6027 - val_loss: 0.9991 - learning_rate: 1.5625e-05\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9723 - loss: 0.0881 - val_accuracy: 0.6233 - val_loss: 0.9922 - learning_rate: 7.8125e-06\nEpoch 29/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9858 - loss: 0.0628 - val_accuracy: 0.6301 - val_loss: 0.9879 - learning_rate: 7.8125e-06\nEpoch 30/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9662 - loss: 0.0931\nEpoch 30: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9661 - loss: 0.0933 - val_accuracy: 0.6301 - val_loss: 0.9846 - learning_rate: 7.8125e-06\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9750 - loss: 0.0800 - val_accuracy: 0.6438 - val_loss: 0.9768 - learning_rate: 3.9063e-06\nEpoch 32/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9754 - loss: 0.0793 - val_accuracy: 0.6438 - val_loss: 0.9695 - learning_rate: 3.9063e-06\nEpoch 33/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9787 - loss: 0.0773\nEpoch 33: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9770 - loss: 0.0811 - val_accuracy: 0.6370 - val_loss: 0.9608 - learning_rate: 3.9063e-06\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9751 - loss: 0.0689 - val_accuracy: 0.6370 - val_loss: 0.9553 - learning_rate: 1.9531e-06\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9757 - loss: 0.0932 - val_accuracy: 0.6438 - val_loss: 0.9486 - learning_rate: 1.9531e-06\nEpoch 36/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9773 - loss: 0.0781\nEpoch 36: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9774 - loss: 0.0775 - val_accuracy: 0.6507 - val_loss: 0.9391 - learning_rate: 1.9531e-06\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9710 - loss: 0.0801 - val_accuracy: 0.6507 - val_loss: 0.9302 - learning_rate: 1.0000e-06\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9869 - loss: 0.0692 - val_accuracy: 0.6712 - val_loss: 0.9231 - learning_rate: 1.0000e-06\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9747 - loss: 0.0672 - val_accuracy: 0.6712 - val_loss: 0.9129 - learning_rate: 1.0000e-06\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9734 - loss: 0.0827 - val_accuracy: 0.6712 - val_loss: 0.9055 - learning_rate: 1.0000e-06\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9881 - loss: 0.0607 - val_accuracy: 0.6849 - val_loss: 0.8976 - learning_rate: 1.0000e-06\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9685 - loss: 0.0853 - val_accuracy: 0.6849 - val_loss: 0.8911 - learning_rate: 1.0000e-06\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9767 - loss: 0.0876 - val_accuracy: 0.6849 - val_loss: 0.8872 - learning_rate: 1.0000e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9622 - loss: 0.1011 - val_accuracy: 0.6849 - val_loss: 0.8806 - learning_rate: 1.0000e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9672 - loss: 0.0752 - val_accuracy: 0.6849 - val_loss: 0.8771 - learning_rate: 1.0000e-06\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9801 - loss: 0.0655 - val_accuracy: 0.6849 - val_loss: 0.8729 - learning_rate: 1.0000e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9839 - loss: 0.0661 - val_accuracy: 0.6849 - val_loss: 0.8686 - learning_rate: 1.0000e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9829 - loss: 0.0612 - val_accuracy: 0.6918 - val_loss: 0.8624 - learning_rate: 1.0000e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9664 - loss: 0.0871 - val_accuracy: 0.6849 - val_loss: 0.8576 - learning_rate: 1.0000e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9668 - loss: 0.0888 - val_accuracy: 0.6918 - val_loss: 0.8517 - learning_rate: 1.0000e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9725 - loss: 0.0681 - val_accuracy: 0.7055 - val_loss: 0.8453 - learning_rate: 1.0000e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9673 - loss: 0.0891 - val_accuracy: 0.7055 - val_loss: 0.8423 - learning_rate: 1.0000e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9774 - loss: 0.0811 - val_accuracy: 0.7055 - val_loss: 0.8401 - learning_rate: 1.0000e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9767 - loss: 0.0710 - val_accuracy: 0.6986 - val_loss: 0.8369 - learning_rate: 1.0000e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9674 - loss: 0.1006 - val_accuracy: 0.6986 - val_loss: 0.8360 - learning_rate: 1.0000e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9809 - loss: 0.0623 - val_accuracy: 0.6918 - val_loss: 0.8340 - learning_rate: 1.0000e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9808 - loss: 0.0736 - val_accuracy: 0.6918 - val_loss: 0.8352 - learning_rate: 1.0000e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9808 - loss: 0.0677 - val_accuracy: 0.6986 - val_loss: 0.8360 - learning_rate: 1.0000e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9812 - loss: 0.0712 - val_accuracy: 0.7055 - val_loss: 0.8366 - learning_rate: 1.0000e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9711 - loss: 0.0943 - val_accuracy: 0.7123 - val_loss: 0.8386 - learning_rate: 1.0000e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9806 - loss: 0.0898 - val_accuracy: 0.7123 - val_loss: 0.8390 - learning_rate: 1.0000e-06\nEpoch 62/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9913 - loss: 0.0691 - val_accuracy: 0.7123 - val_loss: 0.8419 - learning_rate: 1.0000e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9622 - loss: 0.0976 - val_accuracy: 0.7123 - val_loss: 0.8432 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9838 - loss: 0.0633 - val_accuracy: 0.7260 - val_loss: 0.8432 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9770 - loss: 0.0910 - val_accuracy: 0.7123 - val_loss: 0.8438 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9808 - loss: 0.0716 - val_accuracy: 0.7123 - val_loss: 0.8433 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9844 - loss: 0.0576 - val_accuracy: 0.7123 - val_loss: 0.8473 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9850 - loss: 0.0511 - val_accuracy: 0.7123 - val_loss: 0.8506 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9852 - loss: 0.0660 - val_accuracy: 0.7192 - val_loss: 0.8532 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9735 - loss: 0.0699 - val_accuracy: 0.7192 - val_loss: 0.8570 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9748 - loss: 0.0919 - val_accuracy: 0.7192 - val_loss: 0.8608 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9785 - loss: 0.0691 - val_accuracy: 0.7192 - val_loss: 0.8642 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9734 - loss: 0.0883 - val_accuracy: 0.7192 - val_loss: 0.8663 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9867 - loss: 0.0581 - val_accuracy: 0.7192 - val_loss: 0.8694 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9706 - loss: 0.1025 - val_accuracy: 0.7192 - val_loss: 0.8704 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9723 - loss: 0.0736 - val_accuracy: 0.7192 - val_loss: 0.8722 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9732 - loss: 0.0795 - val_accuracy: 0.7192 - val_loss: 0.8751 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9842 - loss: 0.0598 - val_accuracy: 0.7192 - val_loss: 0.8774 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9830 - loss: 0.0798 - val_accuracy: 0.7260 - val_loss: 0.8793 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9780 - loss: 0.0903 - val_accuracy: 0.7260 - val_loss: 0.8858 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9727 - loss: 0.0992 - val_accuracy: 0.7260 - val_loss: 0.8901 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9787 - loss: 0.0757 - val_accuracy: 0.7260 - val_loss: 0.8913 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9837 - loss: 0.0621 - val_accuracy: 0.7260 - val_loss: 0.8940 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9866 - loss: 0.0619 - val_accuracy: 0.7260 - val_loss: 0.8951 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9810 - loss: 0.0753 - val_accuracy: 0.7260 - val_loss: 0.8973 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9856 - loss: 0.0827 - val_accuracy: 0.7329 - val_loss: 0.8980 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9731 - loss: 0.0835 - val_accuracy: 0.7329 - val_loss: 0.8978 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9600 - loss: 0.1193 - val_accuracy: 0.7329 - val_loss: 0.8992 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9760 - loss: 0.0695 - val_accuracy: 0.7329 - val_loss: 0.9000 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9828 - loss: 0.0681 - val_accuracy: 0.7329 - val_loss: 0.9017 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9807 - loss: 0.0711 - val_accuracy: 0.7329 - val_loss: 0.9020 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9766 - loss: 0.0696 - val_accuracy: 0.7329 - val_loss: 0.9035 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9747 - loss: 0.0938 - val_accuracy: 0.7329 - val_loss: 0.9053 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9920 - loss: 0.0518 - val_accuracy: 0.7329 - val_loss: 0.9062 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9836 - loss: 0.0569 - val_accuracy: 0.7329 - val_loss: 0.9086 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9560 - loss: 0.0945 - val_accuracy: 0.7329 - val_loss: 0.9082 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9874 - loss: 0.0636 - val_accuracy: 0.7329 - val_loss: 0.9066 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9792 - loss: 0.0701 - val_accuracy: 0.7329 - val_loss: 0.9048 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9804 - loss: 0.0635 - val_accuracy: 0.7329 - val_loss: 0.9055 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9790 - loss: 0.0698 - val_accuracy: 0.7329 - val_loss: 0.9072 - learning_rate: 1.0000e-06\nFold 4 Accuracy: 0.7329\nEpoch 1/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.4059 - loss: 1.6448 - val_accuracy: 0.3630 - val_loss: 1.0767 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.4622 - loss: 1.3570 - val_accuracy: 0.3630 - val_loss: 1.0613 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5873 - loss: 1.0768 - val_accuracy: 0.3630 - val_loss: 1.0484 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.6994 - loss: 0.7783 - val_accuracy: 0.3630 - val_loss: 1.0460 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7859 - loss: 0.5497 - val_accuracy: 0.3630 - val_loss: 1.0374 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8057 - loss: 0.4805 - val_accuracy: 0.3630 - val_loss: 1.0394 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8867 - loss: 0.3206 - val_accuracy: 0.3630 - val_loss: 1.0529 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9272 - loss: 0.1864\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9271 - loss: 0.1871 - val_accuracy: 0.3630 - val_loss: 1.0545 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9543 - loss: 0.1339 - val_accuracy: 0.3630 - val_loss: 1.0641 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9459 - loss: 0.1760 - val_accuracy: 0.3630 - val_loss: 1.0806 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9523 - loss: 0.1525\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9526 - loss: 0.1506 - val_accuracy: 0.3630 - val_loss: 1.0833 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9668 - loss: 0.1203 - val_accuracy: 0.3630 - val_loss: 1.1057 - learning_rate: 2.5000e-04\nEpoch 13/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9569 - loss: 0.1142 - val_accuracy: 0.3630 - val_loss: 1.1187 - learning_rate: 2.5000e-04\nEpoch 14/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9593 - loss: 0.0981\nEpoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9596 - loss: 0.0978 - val_accuracy: 0.3630 - val_loss: 1.1417 - learning_rate: 2.5000e-04\nEpoch 15/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9718 - loss: 0.1209 - val_accuracy: 0.3630 - val_loss: 1.1439 - learning_rate: 1.2500e-04\nEpoch 16/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9822 - loss: 0.0695 - val_accuracy: 0.3630 - val_loss: 1.1397 - learning_rate: 1.2500e-04\nEpoch 17/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9755 - loss: 0.0683\nEpoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9747 - loss: 0.0706 - val_accuracy: 0.3630 - val_loss: 1.1480 - learning_rate: 1.2500e-04\nEpoch 18/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9785 - loss: 0.0795 - val_accuracy: 0.3630 - val_loss: 1.1524 - learning_rate: 6.2500e-05\nEpoch 19/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9830 - loss: 0.0797 - val_accuracy: 0.3630 - val_loss: 1.1485 - learning_rate: 6.2500e-05\nEpoch 20/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9716 - loss: 0.0729\nEpoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9721 - loss: 0.0739 - val_accuracy: 0.3630 - val_loss: 1.1437 - learning_rate: 6.2500e-05\nEpoch 21/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9711 - loss: 0.0861 - val_accuracy: 0.3630 - val_loss: 1.1486 - learning_rate: 3.1250e-05\nEpoch 22/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9824 - loss: 0.0630 - val_accuracy: 0.3630 - val_loss: 1.1478 - learning_rate: 3.1250e-05\nEpoch 23/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9822 - loss: 0.0889\nEpoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9826 - loss: 0.0856 - val_accuracy: 0.3630 - val_loss: 1.1359 - learning_rate: 3.1250e-05\nEpoch 24/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9673 - loss: 0.0993 - val_accuracy: 0.3630 - val_loss: 1.1389 - learning_rate: 1.5625e-05\nEpoch 25/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9702 - loss: 0.0788 - val_accuracy: 0.3699 - val_loss: 1.1231 - learning_rate: 1.5625e-05\nEpoch 26/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9807 - loss: 0.0799\nEpoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9802 - loss: 0.0814 - val_accuracy: 0.3767 - val_loss: 1.1241 - learning_rate: 1.5625e-05\nEpoch 27/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9762 - loss: 0.0955 - val_accuracy: 0.3836 - val_loss: 1.1121 - learning_rate: 7.8125e-06\nEpoch 28/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9797 - loss: 0.0725 - val_accuracy: 0.3836 - val_loss: 1.1047 - learning_rate: 7.8125e-06\nEpoch 29/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9734 - loss: 0.0872\nEpoch 29: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9730 - loss: 0.0873 - val_accuracy: 0.4110 - val_loss: 1.0872 - learning_rate: 7.8125e-06\nEpoch 30/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9854 - loss: 0.0597 - val_accuracy: 0.4315 - val_loss: 1.0812 - learning_rate: 3.9063e-06\nEpoch 31/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9819 - loss: 0.0691 - val_accuracy: 0.4315 - val_loss: 1.0796 - learning_rate: 3.9063e-06\nEpoch 32/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9665 - loss: 0.1005\nEpoch 32: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9673 - loss: 0.0994 - val_accuracy: 0.4384 - val_loss: 1.0691 - learning_rate: 3.9063e-06\nEpoch 33/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9725 - loss: 0.0905 - val_accuracy: 0.4452 - val_loss: 1.0533 - learning_rate: 1.9531e-06\nEpoch 34/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9816 - loss: 0.0580 - val_accuracy: 0.4521 - val_loss: 1.0462 - learning_rate: 1.9531e-06\nEpoch 35/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9621 - loss: 0.0942 - val_accuracy: 0.4589 - val_loss: 1.0199 - learning_rate: 1.9531e-06\nEpoch 36/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9738 - loss: 0.0778 - val_accuracy: 0.4795 - val_loss: 1.0089 - learning_rate: 1.9531e-06\nEpoch 37/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9533 - loss: 0.1055 - val_accuracy: 0.4932 - val_loss: 0.9957 - learning_rate: 1.9531e-06\nEpoch 38/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9851 - loss: 0.0632 - val_accuracy: 0.5068 - val_loss: 0.9879 - learning_rate: 1.9531e-06\nEpoch 39/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9722 - loss: 0.0987 - val_accuracy: 0.5068 - val_loss: 0.9726 - learning_rate: 1.9531e-06\nEpoch 40/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9862 - loss: 0.0611 - val_accuracy: 0.5137 - val_loss: 0.9595 - learning_rate: 1.9531e-06\nEpoch 41/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9814 - loss: 0.0639 - val_accuracy: 0.5342 - val_loss: 0.9470 - learning_rate: 1.9531e-06\nEpoch 42/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9838 - loss: 0.0680 - val_accuracy: 0.5479 - val_loss: 0.9292 - learning_rate: 1.9531e-06\nEpoch 43/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9823 - loss: 0.0601 - val_accuracy: 0.5548 - val_loss: 0.9168 - learning_rate: 1.9531e-06\nEpoch 44/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9761 - loss: 0.0812 - val_accuracy: 0.5753 - val_loss: 0.8972 - learning_rate: 1.9531e-06\nEpoch 45/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9787 - loss: 0.0690 - val_accuracy: 0.5822 - val_loss: 0.8848 - learning_rate: 1.9531e-06\nEpoch 46/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9795 - loss: 0.0837 - val_accuracy: 0.5890 - val_loss: 0.8768 - learning_rate: 1.9531e-06\nEpoch 47/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9753 - loss: 0.0908 - val_accuracy: 0.5890 - val_loss: 0.8670 - learning_rate: 1.9531e-06\nEpoch 48/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9786 - loss: 0.0833 - val_accuracy: 0.5890 - val_loss: 0.8515 - learning_rate: 1.9531e-06\nEpoch 49/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9698 - loss: 0.0807 - val_accuracy: 0.6096 - val_loss: 0.8438 - learning_rate: 1.9531e-06\nEpoch 50/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9840 - loss: 0.0705 - val_accuracy: 0.6164 - val_loss: 0.8336 - learning_rate: 1.9531e-06\nEpoch 51/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.0749 - val_accuracy: 0.6233 - val_loss: 0.8307 - learning_rate: 1.9531e-06\nEpoch 52/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9610 - loss: 0.1214 - val_accuracy: 0.6301 - val_loss: 0.8238 - learning_rate: 1.9531e-06\nEpoch 53/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9777 - loss: 0.0737 - val_accuracy: 0.6370 - val_loss: 0.8207 - learning_rate: 1.9531e-06\nEpoch 54/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9713 - loss: 0.0832 - val_accuracy: 0.6438 - val_loss: 0.8123 - learning_rate: 1.9531e-06\nEpoch 55/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9812 - loss: 0.0676 - val_accuracy: 0.6644 - val_loss: 0.7963 - learning_rate: 1.9531e-06\nEpoch 56/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9721 - loss: 0.0884 - val_accuracy: 0.6712 - val_loss: 0.7960 - learning_rate: 1.9531e-06\nEpoch 57/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9805 - loss: 0.0717 - val_accuracy: 0.6781 - val_loss: 0.7997 - learning_rate: 1.9531e-06\nEpoch 58/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9849 - loss: 0.0741 - val_accuracy: 0.6781 - val_loss: 0.7909 - learning_rate: 1.9531e-06\nEpoch 59/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9802 - loss: 0.0695 - val_accuracy: 0.6849 - val_loss: 0.7866 - learning_rate: 1.9531e-06\nEpoch 60/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9790 - loss: 0.0716 - val_accuracy: 0.6986 - val_loss: 0.7902 - learning_rate: 1.9531e-06\nEpoch 61/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9786 - loss: 0.0642 - val_accuracy: 0.7055 - val_loss: 0.7894 - learning_rate: 1.9531e-06\nEpoch 62/100\n\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9794 - loss: 0.0614\nEpoch 62: ReduceLROnPlateau reducing learning rate to 1e-06.\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9779 - loss: 0.0640 - val_accuracy: 0.7123 - val_loss: 0.7967 - learning_rate: 1.9531e-06\nEpoch 63/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9811 - loss: 0.0747 - val_accuracy: 0.7123 - val_loss: 0.8008 - learning_rate: 1.0000e-06\nEpoch 64/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9740 - loss: 0.0857 - val_accuracy: 0.7192 - val_loss: 0.8021 - learning_rate: 1.0000e-06\nEpoch 65/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9795 - loss: 0.0595 - val_accuracy: 0.7192 - val_loss: 0.8004 - learning_rate: 1.0000e-06\nEpoch 66/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9662 - loss: 0.0880 - val_accuracy: 0.7123 - val_loss: 0.7986 - learning_rate: 1.0000e-06\nEpoch 67/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9774 - loss: 0.0796 - val_accuracy: 0.7055 - val_loss: 0.8034 - learning_rate: 1.0000e-06\nEpoch 68/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9737 - loss: 0.0817 - val_accuracy: 0.7192 - val_loss: 0.8053 - learning_rate: 1.0000e-06\nEpoch 69/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9864 - loss: 0.0619 - val_accuracy: 0.7192 - val_loss: 0.8014 - learning_rate: 1.0000e-06\nEpoch 70/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9655 - loss: 0.1032 - val_accuracy: 0.7192 - val_loss: 0.8068 - learning_rate: 1.0000e-06\nEpoch 71/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9776 - loss: 0.0724 - val_accuracy: 0.7329 - val_loss: 0.8075 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9766 - loss: 0.0732 - val_accuracy: 0.7397 - val_loss: 0.8079 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9840 - loss: 0.0647 - val_accuracy: 0.7397 - val_loss: 0.8125 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9769 - loss: 0.0714 - val_accuracy: 0.7397 - val_loss: 0.8173 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9893 - loss: 0.0550 - val_accuracy: 0.7397 - val_loss: 0.8182 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9637 - loss: 0.0931 - val_accuracy: 0.7397 - val_loss: 0.8194 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9815 - loss: 0.0780 - val_accuracy: 0.7397 - val_loss: 0.8216 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9828 - loss: 0.0777 - val_accuracy: 0.7397 - val_loss: 0.8228 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9544 - loss: 0.1031 - val_accuracy: 0.7397 - val_loss: 0.8286 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9739 - loss: 0.0788 - val_accuracy: 0.7397 - val_loss: 0.8262 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9818 - loss: 0.0580 - val_accuracy: 0.7397 - val_loss: 0.8269 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9720 - loss: 0.0756 - val_accuracy: 0.7466 - val_loss: 0.8254 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9917 - loss: 0.0598 - val_accuracy: 0.7397 - val_loss: 0.8266 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9703 - loss: 0.0917 - val_accuracy: 0.7397 - val_loss: 0.8265 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9820 - loss: 0.0714 - val_accuracy: 0.7329 - val_loss: 0.8309 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9779 - loss: 0.0900 - val_accuracy: 0.7329 - val_loss: 0.8389 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9770 - loss: 0.0672 - val_accuracy: 0.7260 - val_loss: 0.8437 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9839 - loss: 0.0640 - val_accuracy: 0.7329 - val_loss: 0.8399 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9785 - loss: 0.0755 - val_accuracy: 0.7260 - val_loss: 0.8387 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9835 - loss: 0.0631 - val_accuracy: 0.7260 - val_loss: 0.8445 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9797 - loss: 0.0851 - val_accuracy: 0.7260 - val_loss: 0.8462 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9874 - loss: 0.0637 - val_accuracy: 0.7260 - val_loss: 0.8532 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9725 - loss: 0.0846 - val_accuracy: 0.7192 - val_loss: 0.8527 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9695 - loss: 0.0877 - val_accuracy: 0.7260 - val_loss: 0.8557 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9694 - loss: 0.0887 - val_accuracy: 0.7192 - val_loss: 0.8519 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9813 - loss: 0.0636 - val_accuracy: 0.7192 - val_loss: 0.8536 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9802 - loss: 0.0639 - val_accuracy: 0.7192 - val_loss: 0.8510 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9728 - loss: 0.0845 - val_accuracy: 0.7192 - val_loss: 0.8506 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9812 - loss: 0.0749 - val_accuracy: 0.7192 - val_loss: 0.8532 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9813 - loss: 0.0686 - val_accuracy: 0.7192 - val_loss: 0.8534 - learning_rate: 1.0000e-06\nFold 5 Accuracy: 0.7192\nMean Accuracy over 5 folds: 0.7527\n","output_type":"stream"}],"execution_count":330}]}