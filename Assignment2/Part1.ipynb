{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6243656,"sourceType":"datasetVersion","datasetId":3587583}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Activation functions and their derivatives\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\ndef relu(x):\n    return np.maximum(0, x)\n\ndef relu_derivative(x):\n    return (x > 0).astype(float)\n\n# MLP model class\nclass MLP:\n    def __init__(self, input_size, hidden_size, output_size):\n        np.random.seed(42)\n        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2 / input_size)\n        self.b1 = np.zeros((1, hidden_size))\n        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2 / hidden_size)\n        self.b2 = np.zeros((1, output_size))\n\n    def forward(self, X):\n        self.z1 = np.dot(X, self.W1) + self.b1\n        self.a1 = relu(self.z1)\n        self.z2 = np.dot(self.a1, self.W2) + self.b2\n        self.a2 = sigmoid(self.z2)\n        return self.a2\n\n    def backward(self, X, y, output, lr):\n        m = X.shape[0]\n\n        # Output layer error\n        d_output = (output - y) * sigmoid_derivative(output)\n\n        # Hidden layer error\n        d_hidden = np.dot(d_output, self.W2.T) * relu_derivative(self.a1)\n\n        # Update weights and biases\n        self.W2 -= lr * np.dot(self.a1.T, d_output) / m\n        self.b2 -= lr * np.sum(d_output, axis=0, keepdims=True) / m\n\n        self.W1 -= lr * np.dot(X.T, d_hidden) / m\n        self.b1 -= lr * np.sum(d_hidden, axis=0, keepdims=True) / m\n\n    def train(self, X, y, epochs, lr):\n        for epoch in range(epochs):\n            output = self.forward(X)\n            self.backward(X, y, output, lr)\n\n    def predict(self, X):\n        output = self.forward(X)\n        return (output > 0.5).astype(int)\n\n# Load dataset\ndata = pd.read_csv('/kaggle/input/exclusive-xor-dataset/xor.csv')\n\n# Extract input features (X1, X2) and output labels\nX = data[['X1', 'X2']].values  # Shape will be (n_samples, 2)\ny = data['label'].values.reshape(-1, 1)  # Shape will be (n_samples, 1)\n\nprint(\"Input shape:\", X.shape)  # Should be (n_samples, 2)\nprint(\"Label shape:\", y.shape)  # Should be (n_samples, 1)\nprint(X.shape)\n# # K-Fold Cross Validation\nfrom sklearn.model_selection import KFold\n\nk = 5\nkf = KFold(n_splits=k, shuffle=True, random_state=42)\n\naccuracies = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n    print(f\"Training Fold {fold + 1}...\")\n\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n    # Create and train the MLP model\n    mlp = MLP(input_size=2, hidden_size=128, output_size=1)\n    mlp.train(X_train, y_train, epochs=50000, lr=0.05)\n\n    # Evaluate the model\n    y_pred = mlp.predict(X_test)\n    accuracy = np.mean(y_pred == y_test)\n    accuracies.append(accuracy)\n\n    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n\nprint(f\"Average Accuracy: {np.mean(accuracies):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:56:54.367630Z","iopub.execute_input":"2025-03-10T09:56:54.368104Z","iopub.status.idle":"2025-03-10T10:02:44.284215Z","shell.execute_reply.started":"2025-03-10T09:56:54.368060Z","shell.execute_reply":"2025-03-10T10:02:44.283267Z"}},"outputs":[{"name":"stdout","text":"Input shape: (1000, 2)\nLabel shape: (1000, 1)\n(1000, 2)\nTraining Fold 1...\nFold 1 Accuracy: 0.9750\nTraining Fold 2...\nFold 2 Accuracy: 1.0000\nTraining Fold 3...\nFold 3 Accuracy: 0.9850\nTraining Fold 4...\nFold 4 Accuracy: 0.9850\nTraining Fold 5...\nFold 5 Accuracy: 0.9800\nAverage Accuracy: 0.9850\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def k_fold_cross_validation(X, y, k=5, epochs=1000):\n    fold_size = len(X) // k\n    accuracies = []\n\n    for i in range(k):\n        X_train = np.vstack((X[:i * fold_size], X[(i + 1) * fold_size:]))\n        y_train = np.vstack((y[:i * fold_size], y[(i + 1) * fold_size:]))\n\n        X_val = X[i * fold_size: (i + 1) * fold_size]\n        y_val = y[i * fold_size: (i + 1) * fold_size]\n\n        model = MLP(input_size=2, hidden_size=4, output_size=1, learning_rate=0.1)\n        model.train(X_train, y_train, epochs=epochs)\n\n        predictions = model.predict(X_val)\n        accuracy = np.mean(predictions == y_val)\n        accuracies.append(accuracy)\n        print(f\"Fold {i + 1} Accuracy: {accuracy:.4f}\")\n\n    print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n\n# Load data and run\nfile_path = '/kaggle/input/exclusive-xor-dataset/xor.csv'\nX, y = load_data(file_path)\nk_fold_cross_validation(X, y, k=5, epochs=2000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:33:37.157291Z","iopub.execute_input":"2025-03-10T09:33:37.157612Z","iopub.status.idle":"2025-03-10T09:33:38.881353Z","shell.execute_reply.started":"2025-03-10T09:33:37.157589Z","shell.execute_reply":"2025-03-10T09:33:38.880385Z"}},"outputs":[{"name":"stdout","text":"Fold 1 Accuracy: 0.0000\nFold 2 Accuracy: 0.0000\nFold 3 Accuracy: 0.1950\nFold 4 Accuracy: 0.0050\nFold 5 Accuracy: 0.0000\nAverage Accuracy: 0.0400\n","output_type":"stream"}],"execution_count":3}]}